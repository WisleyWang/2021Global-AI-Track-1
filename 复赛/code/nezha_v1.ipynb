{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "catholic-contamination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:27:35.229440Z",
     "start_time": "2021-05-10T17:27:31.040324Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoModelForPreTraining\n",
    "from transformers import AutoTokenizer,BertTokenizerFast,AutoModel\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from itertools import repeat\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers.file_utils import add_start_docstrings, add_start_docstrings_to_model_forward\n",
    "from model.modeling_nezha import NeZhaForSequenceClassification,NeZhaPreTrainedModel,NeZhaModel,NeZhaForTokenClassification\n",
    "from model.configuration_nezha import NeZhaConfig\n",
    "import  torch.nn.functional as F\n",
    "import collections\n",
    "from transformers.models.bert.modeling_bert import (\n",
    "    BertOutput,\n",
    "    BertPooler,\n",
    "    BertSelfOutput,\n",
    "    BertIntermediate,\n",
    "    BertOnlyMLMHead,\n",
    "    BertOnlyNSPHead,\n",
    "    BertPreTrainingHeads,\n",
    "    BERT_START_DOCSTRING,\n",
    "    BERT_INPUTS_DOCSTRING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-cement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:27:35.449582Z",
     "start_time": "2021-05-10T17:27:35.231698Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeZhaForSequenceClassification(NeZhaPreTrainedModel):\n",
    "    def __init__(self, config,model_name,num_labels1,num_labels2):\n",
    "        super().__init__(config)\n",
    "        self.num_labels1 = num_labels1\n",
    "        self.num_labels2=num_labels2\n",
    "        self.bert = NeZhaModel(config).from_pretrained(model_name)\n",
    "\n",
    "        self.attn1=Attn(config.hidden_size)\n",
    "        self.attn2=Attn(config.hidden_size)\n",
    "        self.attn3=Attn(config.hidden_size)\n",
    "        self.attn4=Attn(config.hidden_size)\n",
    "        self.attn5=Attn(config.hidden_size)\n",
    "        self.attn6=Attn(config.hidden_size)\n",
    "   \n",
    "        self.dropouts=nn.ModuleList([nn.Dropout(p) for p in np.linspace(0.1,0.5,5)])\n",
    "#         self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "        self.classifier1 = nn.Linear(config.hidden_size, self.num_labels1-14)\n",
    "        self.classifier2 = nn.Linear(config.hidden_size, 7)\n",
    "        self.classifier3 = nn.Linear(config.hidden_size, 7)\n",
    "\n",
    "        \n",
    "        self.classifier4 = nn.Linear(config.hidden_size, self.num_labels2-10)\n",
    "        self.classifier5 = nn.Linear(config.hidden_size,5)\n",
    "        self.classifier6 = nn.Linear(config.hidden_size,5)\n",
    "  \n",
    "        \n",
    "        self.predict=nn.Sigmoid()\n",
    "#         self.init_weights()\n",
    "#         if True:\n",
    "#             for p in self.bert.parameters(): # 冻结所有bert层\n",
    "#                 p.requires_grad = False\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "            \n",
    "        inputs_embeds=None,\n",
    "            labels1=None,\n",
    "        labels2=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for computing the sequence classification/regression loss.\n",
    "            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n",
    "            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n",
    "            Classification (or regression if config.num_labels==1) loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n",
    "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        from transformers import BertTokenizer, BertForSequenceClassification\n",
    "        import torch\n",
    "\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "           attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            inputs_embeds=inputs_embeds\n",
    "        )\n",
    "        \n",
    "        att1=self.attn1(outputs[0])\n",
    "        att2=self.attn2(outputs[0])\n",
    "        att3=self.attn3(outputs[0])\n",
    "        att4=self.attn4(outputs[0])\n",
    "        att5=self.attn5(outputs[0])\n",
    "        att6=self.attn6(outputs[0])\n",
    "   \n",
    "\n",
    "        pooled_output1 =torch.stack([ dd(att1)for dd in self.dropouts],dim=0).mean(dim=0)\n",
    "        pooled_output2 = torch.stack([ dd(att1)for dd in self.dropouts],dim=0).mean(dim=0)\n",
    "        pooled_output3 =torch.stack([ dd(att1)for dd in self.dropouts],dim=0).mean(dim=0)\n",
    "        pooled_output4 = torch.stack([ dd(att1)for dd in self.dropouts],dim=0).mean(dim=0)\n",
    "        pooled_output5 = torch.stack([ dd(att1)for dd in self.dropouts],dim=0).mean(dim=0)\n",
    "        pooled_output6 =torch.stack([ dd(att1)for dd in self.dropouts],dim=0).mean(dim=0)\n",
    "\n",
    "        \n",
    "        logits1 = self.classifier1(pooled_output1)\n",
    "        logits2 = self.classifier2(pooled_output2)\n",
    "        logits3 = self.classifier3(pooled_output3)\n",
    "        logits4 = self.classifier4(pooled_output4)\n",
    "        logits5 = self.classifier5(pooled_output5)\n",
    "        logits6 = self.classifier6(pooled_output6)\n",
    "   \n",
    "        \n",
    "        logits1=torch.cat([logits1,logits2,logits3],dim=-1)\n",
    "        logits2=torch.cat([logits4,logits5,logits6],dim=-1)\n",
    "        predict1=self.predict(logits1)\n",
    "        predict2=self.predict(logits2)\n",
    "        outputs = (predict1,predict2) + outputs[2:]  # add hidden states and attention if they are here\n",
    "#         print('label:',labels)\n",
    "#         print('input_ids:',input_ids)\n",
    "#         print('attention_mas:',attention_mask)\n",
    "        if labels1 is not None:\n",
    "            loss_fct = nn.BCELoss()\n",
    "#                 print(logits.view(-1, self.num_labels))\n",
    "#                 print(labels.view(-1, self.num_labels))\n",
    "            loss1 = loss_fct(predict1.view(-1, self.num_labels1), labels1.view(-1, self.num_labels1))\n",
    "            loss2 = loss_fct(predict2.view(-1, self.num_labels2), labels2.view(-1, self.num_labels2))\n",
    "            loss=loss1+loss2\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), predict1,predict2, (hidden_states), (attentions)\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    空间dropout，即在指定轴方向上进行dropout，常用于Embedding层和CNN层后\n",
    "    如对于(batch, timesteps, embedding)的输入，若沿着axis=1则可对embedding的若干channel进行整体dropout\n",
    "    若沿着axis=2则可对某些token进行整体dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple, 应当与inputs的shape一致，其中值为1的即沿着drop的轴\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1])   # 默认沿着中间所有的shape\n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size,1)\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (T,B,H)\n",
    "        :param src_len:\n",
    "            used for masking. NoneType or tensor in shape (B) indicating sequence length\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''   \n",
    "        att=self.attn(x)\n",
    "        att=F.tanh(att)\n",
    "        att=F.softmax(att,1)\n",
    "        att_x=att*x\n",
    "        return att_x.sum(1)\n",
    "import torch.utils.data as Data\n",
    "class CustomDataset(Data.Dataset):\n",
    "    def __init__(self, data, maxlen,tokenizer,with_labels=True, model_name='bert-base-chinese'):\n",
    "        self.data = data  # pandas dataframe\n",
    "\n",
    "        #Initialize the tokenizer\n",
    "        self.tokenizer = tokenizer#AutoTokenizer.from_pretrained(model_name, use_fast=True)  \n",
    "        self.maxlen = maxlen\n",
    "        self.with_labels = with_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def get_label(self,x,num):\n",
    "        label=[0]*num\n",
    "       \n",
    "        x=x.strip().split(' ')\n",
    "\n",
    "        for l in x:              \n",
    "            if l and l!='nan':\n",
    "                label[int(l)]=1\n",
    "        return label\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
    "        sent = str(self.data.loc[index, 'sentence'])\n",
    "\n",
    "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
    "        encoded_pair = self.tokenizer(sent,\n",
    "                                      padding='max_length',  # Pad to max_length\n",
    "                                      truncation=True,       # Truncate to max_length\n",
    "                                      max_length=self.maxlen,  \n",
    "                                      return_tensors='pt')  # Return torch.Tensor objects\n",
    "#         print(encoded_pair['input_ids'])\n",
    "        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n",
    "#         attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
    "#         token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
    "\n",
    "        if self.with_labels:  # True if the dataset has labels\n",
    "            label1 = torch.Tensor(self.get_label(str(self.data.loc[index, 'label1']),17))\n",
    "            label2 = torch.Tensor(self.get_label(str(self.data.loc[index, 'label2']),12))\n",
    "            return token_ids,label1,label2\n",
    "        else:\n",
    "            return token_ids\n",
    "from sklearn.utils import shuffle as reset\n",
    "def train_test_split(data_df, test_size=0.2, shuffle=True, random_state=None):\n",
    "    if shuffle:\n",
    "        data_df = reset(data_df, random_state=random_state)\n",
    "\n",
    "    train = data_df[int(len(data_df)*test_size):].reset_index(drop = True)\n",
    "    test  = data_df[:int(len(data_df)*test_size)].reset_index(drop = True)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "from torch.nn.functional import cross_entropy,binary_cross_entropy\n",
    "\n",
    "\n",
    "def eval(model, optimizer, validation_dataloader,output_model = './train_class/model.pth'):\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy, nb_eval_steps = 0, 0, 0\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            predict1,predict2 = model(batch[0])\n",
    "            predict1,predict2 = predict1.detach().cpu(),predict2.detach().cpu()\n",
    "            label_ids1,label_ids2 = batch[1].cpu(),batch[2].cpu()\n",
    "            \n",
    "            tmp_eval_accuracy = binary_cross_entropy(predict1, label_ids1.float()).item()+binary_cross_entropy(predict2, label_ids2.float()).item()\n",
    "            \n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "    print(\"Validation mlogloss: {}\".format(eval_accuracy / nb_eval_steps))\n",
    "    global best_score\n",
    "    if best_score > eval_accuracy / nb_eval_steps:\n",
    "        best_score = eval_accuracy / nb_eval_steps\n",
    "        save(model, optimizer,output_model)\n",
    "        return 0\n",
    "    return 1\n",
    "def save(model, optimizer,output_model):\n",
    "    # save\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, output_model)\n",
    "    print('The best model has been saved')\n",
    "def flat_accuracy(preds, labels):\n",
    "#     print(preds,labels)\n",
    "    return -np.mean(labels*np.log(preds+1.e-7)+(1-labels)*np.log(preds+1.e-7))*10\n",
    "\n",
    "# 对抗训练\n",
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    "    def attack(self, epsilon=1., emb_name='word_emb'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "    def restore(self, emb_name='word_emb'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name: \n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        \n",
    "from collections import defaultdict\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "\n",
    "\n",
    "class Lookahead(Optimizer):\n",
    "    def __init__(self, optimizer, k=5, alpha=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = defaultdict(dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "        for group in self.param_groups:\n",
    "            group[\"counter\"] = 0\n",
    "\n",
    "    def update(self, group):\n",
    "        for fast in group[\"params\"]:\n",
    "            param_state = self.state[fast]\n",
    "            if \"slow_param\" not in param_state:\n",
    "                param_state[\"slow_param\"] = torch.zeros_like(fast.data)\n",
    "                param_state[\"slow_param\"].copy_(fast.data)\n",
    "            slow = param_state[\"slow_param\"]\n",
    "            slow += (fast.data - slow) * self.alpha\n",
    "            fast.data.copy_(slow)\n",
    "\n",
    "    def update_lookahead(self):\n",
    "        for group in self.param_groups:\n",
    "            self.update(group)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = self.optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            if group[\"counter\"] == 0:\n",
    "                self.update(group)\n",
    "            group[\"counter\"] += 1\n",
    "            if group[\"counter\"] >= self.k:\n",
    "                group[\"counter\"] = 0\n",
    "        return loss\n",
    "\n",
    "    def state_dict(self):\n",
    "        fast_state_dict = self.optimizer.state_dict()\n",
    "        slow_state = {\n",
    "            (id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict[\"state\"]\n",
    "        param_groups = fast_state_dict[\"param_groups\"]\n",
    "        return {\n",
    "            \"fast_state\": fast_state,\n",
    "            \"slow_state\": slow_state,\n",
    "            \"param_groups\": param_groups,\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        slow_state_dict = {\n",
    "            \"state\": state_dict[\"slow_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        fast_state_dict = {\n",
    "            \"state\": state_dict[\"fast_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.optimizer.load_state_dict(fast_state_dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        param_group[\"counter\"] = 0\n",
    "        self.optimizer.add_param_group(param_group)\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "class WarmupLinearSchedule(LambdaLR):\n",
    "    \"\"\" Linear warmup and then linear decay.\n",
    "        Multiplies the learning rate defined in the optimizer by a dynamic variable determined by the current step.\n",
    "        Linearly increases the multiplicative variable from 0. to 1. over `warmup_steps` training steps.\n",
    "        Linearly decreases the multiplicative variable from 1. to 0. over remaining `t_total - warmup_steps` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps, t_total, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.t_total = t_total\n",
    "        super(WarmupLinearSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return float(step) / float(max(1, self.warmup_steps))\n",
    "        return max(0.0, float(self.t_total - step) / float(max(1.0, self.t_total - self.warmup_steps)))\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.0, correct_bias=True):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n",
    "                        correct_bias=correct_bias)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "                exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1.0 - beta2, grad, grad)\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                step_size = group['lr']\n",
    "                if group['correct_bias']:  # No bias correction for Bert\n",
    "                    bias_correction1 = 1.0 - beta1 ** state['step']\n",
    "                    bias_correction2 = 1.0 - beta2 ** state['step']\n",
    "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
    "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "                if group['weight_decay'] > 0.0:\n",
    "                    p.data.add_(-group['lr'] * group['weight_decay'], p.data)\n",
    "        return loss\n",
    "def build_optimizer(model, train_steps, learning_rate):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=False, eps=1e-8)\n",
    "    optimizer = Lookahead(optimizer, 5, 1)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=train_steps * 0.1, t_total=train_steps)\n",
    "    return optimizer, scheduler\n",
    "def to_predict(model, dataloader,output_model, with_labels=False):\n",
    "    \n",
    "    # load model\n",
    "    checkpoint = torch.load(output_model, map_location='cuda')\n",
    "#     print(checkpoint)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "\n",
    "    print('-----Testing-----')\n",
    "\n",
    "    pred_label =np.zeros((len(test),29))\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            predict1,predict2 = model(batch)\n",
    "            predict1 = predict1.detach().cpu().numpy()\n",
    "            predict2 = predict2.detach().cpu().numpy()\n",
    "            predict=np.concatenate([predict1,predict2],axis=-1)\n",
    "            pred_label[i*batch_size:(i+1)*batch_size]=predict\n",
    "    return pred_label\n",
    "\n",
    "# M as ascent steps, alpha as ascent step size\n",
    "# X denotes input node features, y denotes labels\n",
    "def flag(model, X, y, optimizer, criterion, M, alpha):\n",
    "    \"\"\"\n",
    "    model：模型\n",
    "    X：输入节点特征矩阵\n",
    "    y：节点标签\n",
    "    optimizer：优化器\n",
    "    criterion：损失函数\n",
    "    M：每个epoch的step数\n",
    "    alpha：每个step的步长\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # pert初始化为和X形状相同、服从(-alpha, alpha)均匀分布的矩阵\n",
    "    pert = torch.FloatTensor(*X.shape).uniform_(-alpha, alpha)\n",
    "    # pert带有梯度\n",
    "    pert.requires_grad_()\n",
    "    # 为输入数据增加对抗性扰动pert\n",
    "    out = model(X+pert)\n",
    "    # 因为loss的梯度一直是累加的，所以每个step贡献1/M的grad值\n",
    "    loss = criterion(out, y)/M\n",
    "\n",
    "    # 每个epoch分为M个step，M个loss的grad进行累加，得到最终的loss\n",
    "    for _ in range(M-1):\n",
    "        loss.backward()\n",
    "        # 根据pert的grad来更新pert，alpha可以看作是pert的学习率\n",
    "        pert_data = pert.detach() + alpha*torch.sign(pert.grad.detach())\n",
    "        pert.data = pert_data.data\n",
    "        # pert梯度grad清零\n",
    "        pert.grad[:] = 0\n",
    "        # 重复对抗性扰动的训练过程\n",
    "        out = model(X+pert)\n",
    "        loss = criterion(out, y)/M\n",
    "\n",
    "    # 通过M个step累加的grad，更新model的参数\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "import contextlib    \n",
    "@contextlib.contextmanager\n",
    "def _disable_tracking_bn_stats(model):\n",
    "\n",
    "    def switch_attr(m):\n",
    "        if hasattr(m, 'track_running_stats'):\n",
    "            m.track_running_stats ^= True\n",
    "            \n",
    "    model.apply(switch_attr)\n",
    "    yield\n",
    "    model.apply(switch_attr)\n",
    "\n",
    "\n",
    "def _l2_normalize(d):\n",
    "    d_reshaped = d.view(d.shape[0], -1, *(1 for _ in range(d.dim() - 2)))\n",
    "    d /= torch.norm(d_reshaped, dim=1, keepdim=True) + 1e-8\n",
    "    return d\n",
    "\n",
    "\n",
    "class VATLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, xi=10.0, eps=1.0, ip=1):\n",
    "        \"\"\"VAT loss\n",
    "        :param xi: hyperparameter of VAT (default: 10.0)\n",
    "        :param eps: hyperparameter of VAT (default: 1.0)\n",
    "        :param ip: iteration times of computing adv noise (default: 1)\n",
    "        \"\"\"\n",
    "        super(VATLoss, self).__init__()\n",
    "        self.xi = xi\n",
    "        self.eps = eps\n",
    "        self.ip = ip\n",
    "\n",
    "    def forward(self, model, x):\n",
    "        with torch.no_grad():\n",
    "            pred1,pred2 = model(x)\n",
    "\n",
    "        # prepare random unit tensor\n",
    "        d = torch.rand(x.shape).sub(0.5).to(x.device)\n",
    "        d = _l2_normalize(d)\n",
    "\n",
    "        with _disable_tracking_bn_stats(model):\n",
    "            # calc adversarial direction\n",
    "            for _ in range(self.ip):\n",
    "                d.requires_grad_()\n",
    "                pred_hat1,pred_hat2 = model(x + self.xi * d)\n",
    "                adv_distance1 = F.kl_div(pred_hat1, pred1, reduction='batchmean')\n",
    "                adv_distance2 = F.kl_div(pred_hat2, pred2, reduction='batchmean')\n",
    "                adv_distance=adv_distance1+adv_distance2\n",
    "                adv_distance.backward()\n",
    "                d = _l2_normalize(d.grad)\n",
    "                model.zero_grad()\n",
    "    \n",
    "            # calc LDS\n",
    "            r_adv = d * self.eps\n",
    "            pred_hat1,pred_hat2 = model(x + r_adv)\n",
    "            lds1 = F.kl_div(pred_hat1, pred1, reduction='batchmean')\n",
    "            lds2 = F.kl_div(pred_hat12, pred2, reduction='batchmean')\n",
    "            lds = lds1+lds2\n",
    "\n",
    "        return lds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "julian-performer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:27:36.445530Z",
     "start_time": "2021-05-10T17:27:36.420967Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "# from enum import IntEnum\n",
    "\n",
    "def stable_kl(logit, target, epsilon=1e-6, reduce=True):\n",
    "    logit = logit.view(-1, logit.size(-1)).float()\n",
    "    target = target.view(-1, target.size(-1)).float()\n",
    "    bs = logit.size(0)\n",
    "    p = F.log_softmax(logit, 1).exp()\n",
    "    y = F.log_softmax(target, 1).exp()\n",
    "    rp = -(1.0/(p + epsilon) -1 + epsilon).detach().log()\n",
    "    ry = -(1.0/(y + epsilon) -1 + epsilon).detach().log()\n",
    "    if reduce:\n",
    "        return (p* (rp- ry) * 2).sum() / bs\n",
    "    else:\n",
    "        return (p* (rp- ry) * 2).sum()\n",
    "\n",
    "\n",
    "def generate_noise(embed, mask, epsilon=1e-5):\n",
    "\t#生成与embed 同尺寸方差为epsion的符合正态分布的noise\n",
    "    noise = embed.data.new(embed.size()).normal_(0, 1) *  epsilon\n",
    "    noise.detach()\n",
    "    noise.requires_grad_()\n",
    "    return noise\n",
    "\n",
    "class SmartPerturbation():\n",
    "    def __init__(self,\n",
    "                 epsilon=1e-6,\n",
    "                 multi_gpu_on=False,\n",
    "                 step_size=0.1,\n",
    "                 noise_var=1e-5,\n",
    "                 norm_p='inf',\n",
    "                 k=1, # 扰动次数\n",
    "                 fp16=False,\n",
    "                 encoder_type=1,#EncoderModelType.BERT, # 4\n",
    "                 loss_map=nn.BCELoss(), # 这个是用来与taskid 对应的，不同的任务对应不同的loss，我们可以直接固定住\n",
    "                 norm_level=0):\n",
    "        super(SmartPerturbation, self).__init__()\n",
    "        self.epsilon = epsilon \n",
    "        # eta 更新扰动后的x_i的学习率\n",
    "        self.step_size = step_size\n",
    "        self.multi_gpu_on = multi_gpu_on\n",
    "        self.fp16 = fp16\n",
    "        self.K = k\n",
    "        # sigma 生成扰动噪音的方差\n",
    "        self.noise_var = noise_var \n",
    "        self.norm_p = norm_p\n",
    "        self.encoder_type = encoder_type \n",
    "        self.loss_map = loss_map \n",
    "        self.norm_level = norm_level > 0\n",
    "#         assert len(loss_map) > 0\n",
    "\n",
    "\n",
    "    def _norm_grad(self, grad, eff_grad=None, sentence_level=False):\n",
    "    \t# 计算梯度 以及 有效梯度的 方向\n",
    "        if self.norm_p == 'l2':\n",
    "            if sentence_level:\n",
    "                direction = grad / (torch.norm(grad, dim=(-2, -1), keepdim=True) + self.epsilon)\n",
    "            else:\n",
    "                direction = grad / (torch.norm(grad, dim=-1, keepdim=True) + self.epsilon)\n",
    "        elif self.norm_p == 'l1':\n",
    "            direction = grad.sign()\n",
    "        else:\n",
    "            if sentence_level:\n",
    "                direction = grad / (grad.abs().max((-2, -1), keepdim=True)[0] + self.epsilon)\n",
    "            else:\n",
    "                direction = grad / (grad.abs().max(-1, keepdim=True)[0] + self.epsilon)\n",
    "                eff_direction = eff_grad / (grad.abs().max(-1, keepdim=True)[0] + self.epsilon)\n",
    "        return direction, eff_direction\n",
    "\n",
    "    def forward(self, model,\n",
    "                logits1, # 因为我是双任务\n",
    "                logits2,\n",
    "                inputs, # 数据的输入\n",
    "                task_id=0,\n",
    "                task_type=1,#TaskType.Classification,\n",
    "                pairwise=1):\n",
    "        # adv training\n",
    "        assert task_type in set([1,2,3,4]), 'Donot support {} yet'.format(task_type)\n",
    "        \n",
    "\n",
    "        # init delta\n",
    "        # 输出 embded \n",
    "        embed = model.embeddings(inputs['input_ids']) #得到输入矩阵\n",
    "        noise = generate_noise(embed, inputs['attention_mask'], epsilon=self.noise_var)\n",
    "        vat_args = inputs\n",
    "        vat_args.pop('input_ids',1)\n",
    "        for step in range(0, self.K):\n",
    "            vat_args.update({'inputs_embeds':embed + noise})\n",
    "            \n",
    "            # 使用加入噪音的embed 输出预测结果\n",
    "            _,adv_logits1,adv_logits2 = model(**vat_args) # 双任务\n",
    "            if task_type == 2: # 回归任务\n",
    "            \t# 回归问题使用 mse loss 评估与原始embedded输出的差异\n",
    "                adv_loss = F.mse_loss(adv_logits, logits.detach(), reduction='sum')\n",
    "            else:\n",
    "                if task_type == 3:  # 排序任务\n",
    "                    adv_logits = adv_logits.view(-1, pairwise)\n",
    "                # 排序或者分类使用kl散度衡量两者之间的差异  （其他任务）\n",
    "                adv_loss = stable_kl(adv_logits1, logits1.detach(), reduce=False)+stable_kl(adv_logits2, logits2.detach(), reduce=False)\n",
    "            #  分布损失与 扰动之间的梯度\n",
    "            delta_grad, = torch.autograd.grad(adv_loss, noise, only_inputs=True, retain_graph=False)\n",
    "            # 梯度的范数\n",
    "            norm = delta_grad.norm()\n",
    "            if (torch.isnan(norm) or torch.isinf(norm)):\n",
    "                return 0\n",
    "            # 更新到主要训练过程中的梯度 为扰动与原始输出差异损失对扰动求出的梯度 乘以 扰动的学习率\n",
    "            eff_delta_grad = delta_grad * self.step_size\n",
    "            # \n",
    "            delta_grad = noise + delta_grad * self.step_size\n",
    "            noise, eff_noise = self._norm_grad(delta_grad, eff_grad=eff_delta_grad, sentence_level=self.norm_level)\n",
    "            noise = noise.detach()\n",
    "            noise.requires_grad_()\n",
    "        vat_args.update({'inputs_embeds':embed + noise})\n",
    "        \n",
    "#         vat_args.pop('input_ids',default=1)\n",
    "#         adv_loss,_,_ = model(**vat_args)\n",
    "        _,adv_logits1,adv_logits2 = model(**vat_args) # 双任务\n",
    "        if task_type == 3: # 排序任务\n",
    "            adv_logits = adv_logits.view(-1, pairwise)\n",
    "#         adv_lc = self.loss_map\n",
    "#         adv_loss = adv_lc(logits, adv_logits, ignore_index=-1) #其实这里就是算个Loss,我的模型会自动返回loss\n",
    "        adv_loss=stable_kl(adv_logits1, logits1.detach(), reduce=False)+stable_kl(adv_logits2, logits2.detach(), reduce=False)\n",
    "        return adv_loss, embed.detach().abs().mean(), eff_noise.detach().abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "announced-mention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:32:07.401845Z",
     "start_time": "2021-05-10T17:32:07.380785Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "# def read_data(df,tokenizer,maxlen,with_labels):\n",
    "#     outputs = defaultdict(list)\n",
    "#     def get_label(x,num):\n",
    "#         label=[0]*num\n",
    "       \n",
    "#         x=x.strip().split(' ')\n",
    "\n",
    "#         for l in x:              \n",
    "#             if l and l!='nan':\n",
    "#                 label[int(l)]=1\n",
    "#         return label\n",
    "#     for index in tqdm(range(len(df))):\n",
    "#         sent=df.loc[index, 'sentence']\n",
    "#         outputs['input_ids'].append(tokenizer.encode_plus(sent,\n",
    "#                                       padding='max_length',  # Pad to max_length\n",
    "#                                       truncation=True,       # Truncate to max_length\n",
    "#                                       max_length=maxlen,return_token_type_ids=False,  \n",
    "#                                       return_tensors='pt')['input_ids'].squeeze(0)) # Return torch.Tensor objects\n",
    "  \n",
    "#         if with_labels:  # True if the dataset has labels\n",
    "#             lab1=get_label(str(df.loc[index, 'label1']),17)\n",
    "#             lab2=get_label(str(df.loc[index, 'label2']),12)\n",
    "#             outputs['labels1'].append(torch.Tensor(lab1))\n",
    "#             outputs['labels2'].append(torch.Tensor(lab2))\n",
    "            \n",
    "#     return outputs\n",
    "    \n",
    "class CustomDataset(Data.Dataset):\n",
    "    def __init__(self, data, maxlen,tokenizer,with_labels=True, model_name='bert-base-chinese'):\n",
    "        self.data = data  # pandas dataframe\n",
    "\n",
    "        #Initialize the tokenizer\n",
    "        self.tokenizer = tokenizer#AutoTokenizer.from_pretrained(model_name, use_fast=True)  \n",
    "        self.maxlen = maxlen\n",
    "        self.with_labels = with_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def get_label(self,x,num):\n",
    "        label=[0]*num\n",
    "       \n",
    "        x=x.strip().replace('|','').split(' ')\n",
    "\n",
    "        for l in x:              \n",
    "            if l and l!='nan' and l!='|':\n",
    "                label[int(l)]=1\n",
    "        return label\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
    "        sent = str(self.data.loc[index, 'sentence'])\n",
    "\n",
    "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
    "        encoded_pair = self.tokenizer(sent,\n",
    "                                      padding='max_length',  # Pad to max_length\n",
    "                                      truncation=True,       # Truncate to max_length\n",
    "                                      max_length=self.maxlen,  \n",
    "                                      return_tensors='pt')  # Return torch.Tensor objects\n",
    "#         print(encoded_pair['input_ids'])\n",
    "        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n",
    "#         attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
    "#         token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
    "\n",
    "        if self.with_labels:  # True if the dataset has labels\n",
    "            label1 = torch.Tensor(self.get_label(str(self.data.loc[index, 'label1']),17))\n",
    "            label2 = torch.Tensor(self.get_label(str(self.data.loc[index, 'label2']),12))\n",
    "            return token_ids,label1,label2\n",
    "        else:\n",
    "            return token_ids\n",
    "class PGD():\n",
    "    def __init__(self, model, emb_name='word_emb', epsilon=1., alpha=1.5):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        self.model = model\n",
    "        self.emb_name = emb_name\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.emb_backup = {}\n",
    "        self.grad_backup = {}\n",
    "    def attack(self, is_first_attack=False):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                if is_first_attack:\n",
    "                    self.emb_backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0:\n",
    "                    r_at = self.alpha * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = self.project(name, param.data, self.epsilon)\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and self.emb_name in name:\n",
    "                assert name in self.emb_backup\n",
    "                param.data = self.emb_backup[name]\n",
    "        self.emb_backup = {}\n",
    "    def project(self, param_name, param_data, epsilon):\n",
    "        r = param_data - self.emb_backup[param_name]\n",
    "        if torch.norm(r) > epsilon:\n",
    "            r = epsilon * r / torch.norm(r)\n",
    "        return self.emb_backup[param_name] + r\n",
    "    def backup_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                self.grad_backup[name] = param.grad.clone()\n",
    "    def restore_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                param.grad = self.grad_backup[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "touched-debut",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:32:08.849051Z",
     "start_time": "2021-05-10T17:32:08.736397Z"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../tcdata/train.csv',header=None)\n",
    "# test=train.iloc[-2000:].copy().reset_index(drop=True)\n",
    "# train=train.iloc[:-2000]\n",
    "test=pd.read_csv('../tcdata/track1_round1_testB.csv',header=None)\n",
    "# test=pd.read_csv('../tcdata/testA.csv',header=None)\n",
    "model_path='../model_weight/nezha/'\n",
    "output_model='../tmp/nezha.pth'\n",
    "batch_size=32\n",
    "# 合并训练集与测试集 制作特征\n",
    "for i in range(1,3):\n",
    "    train[i]=train[i].apply(lambda x:x.replace('|','').strip())\n",
    "for i in range(1,2):\n",
    "    test[i]=test[i].apply(lambda x:x.replace('|','').strip())\n",
    "train.columns=['idx','sentence','label1','label2']\n",
    "test.columns=['idx','sentence']\n",
    "# test.columns=['idx','sentence','label1','label2']\n",
    "tokenizer=BertTokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "config=NeZhaConfig.from_pretrained(model_path,num_labels=17,hidden_dropout_prob=0.3) # config.output_attentions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surface-billion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:32:14.431768Z",
     "start_time": "2021-05-10T17:32:14.413761Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(train_df,val_df,test_oof):\n",
    "    \n",
    "        ###--------------------\n",
    "    early_stop=0\n",
    "    print(\"Reading training data...\")\n",
    "    train_set = CustomDataset(train_df, maxlen=128,tokenizer=tokenizer)\n",
    "    train_loader = Data.DataLoader(train_set, batch_size=batch_size, num_workers=5, shuffle=True)\n",
    "\n",
    "    print(\"Reading validation data...\")\n",
    "    val_set = CustomDataset(val_df, maxlen=128, tokenizer=tokenizer)\n",
    "    val_loader = Data.DataLoader(val_set, batch_size=batch_size, num_workers=5, shuffle=True)\n",
    "\n",
    "\n",
    "    # 准备模型\n",
    "    model=NeZhaForSequenceClassification(config=config,model_name=model_path,num_labels1=17,num_labels2=12)\n",
    "    ### 训练\n",
    "    model.to(device)\n",
    "#     fgm = FGM(model)\n",
    "    pgd = PGD(model)\n",
    "    K = 3\n",
    "#     adv_teacher=SmartPerturbation()\n",
    "# vat\n",
    "#     vat_loss = VATLoss(xi=10.0, eps=1.0, ip=1)\n",
    "    \n",
    "    train_num = len(train_set)\n",
    "    train_steps = int(train_num * epochs / batch_size) + 1\n",
    "\n",
    "    optimizer, scheduler = build_optimizer(model, train_steps, learning_rate=6e-5)\n",
    "    print('-----Training-----')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        print('Epoch', epoch)\n",
    "        for i, batch in enumerate(tqdm(train_loader)):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs={}\n",
    "            loss, predict1,predict2 = model(input_ids=batch[0],labels1=batch[1],labels2=batch[2])    #,attention_mask=batch[1]\n",
    "            if i % 50 == 0:\n",
    "                print(i, loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             对抗训练\n",
    "#             fgm.attack()\n",
    "#             loss_adv, _,_  = model(input_ids=batch[0],labels1=batch[1],labels2=batch[2])\n",
    "#             loss_adv.backward()\n",
    "#             fgm.restore()\n",
    "#----------------------------\n",
    "            pgd.backup_grad()\n",
    "    # 对抗训练\n",
    "            for t in range(K):\n",
    "                pgd.attack(is_first_attack=(t==0)) # 在embedding上添加对抗扰动, first attack时备份param.data\n",
    "                if t != K-1:\n",
    "                    model.zero_grad()\n",
    "                else:\n",
    "                    pgd.restore_grad()\n",
    "                loss_adv, _,_ = model(input_ids=batch[0],labels1=batch[1],labels2=batch[2])\n",
    "                loss_adv.backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "            pgd.restore() # 恢复embedding参数\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        if epoch>-1:\n",
    "            early_stop+=eval(model, optimizer, val_loader, output_model=output_model)\n",
    "        if early_stop==2:\n",
    "            break\n",
    "\n",
    "    test_oof+=to_predict(model, test_loader,output_model, with_labels=False)/n_fold.n_splits\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return test_oof   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "senior-stand",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T17:32:16.137444Z",
     "start_time": "2021-05-10T17:32:16.133904Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "received-organ",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T20:10:05.254580Z",
     "start_time": "2021-05-10T17:32:17.612088Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data...\n",
      "Reading validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training-----\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lichangyv/miniconda3/envs/tf2/lib/python3.8/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.417330026626587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-1067a4a8b620>:425: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370117127/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "  9%|▉         | 50/547 [01:21<13:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.40832093358039856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:44<12:24,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.3256702423095703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:07<11:03,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.26462996006011963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:31<09:45,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.2842409014701843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [06:55<08:20,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.2054591327905655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:19<06:54,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.18637904524803162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:44<05:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.14431977272033691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:08<04:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.1379721313714981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:33<02:42,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.1354137361049652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [13:58<01:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.11666673421859741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:17<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.10920785755343453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 1\n",
      "0 0.06471119821071625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:23<13:53,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.07065312564373016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:48<12:26,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.05875231325626373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:12<11:05,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.05290141701698303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:37<09:48,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.08091193437576294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:02<08:19,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.09505254030227661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:26<06:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.07588369399309158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:51<05:32,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.06932507455348969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:15<04:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.09118164330720901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:40<02:46,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.0678623765707016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:05<01:21,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.06131937354803085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:25<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.07183658502571567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 2\n",
      "0 0.07417657971382141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:24<14:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.05592354014515877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:48<12:36,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.07808207720518112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:13<11:08,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.057013582438230515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:38<09:47,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.05073682218790054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:03<08:22,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.04204696789383888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:29<07:02,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.039236485958099365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:54<05:33,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.10778602957725525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:18<04:10,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.0429425910115242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:43<02:42,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.0760846883058548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:08<01:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.022629640996456146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:28<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.056548411353738816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 3\n",
      "0 0.06587874889373779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:24<14:02,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.037750355899333954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:49<12:36,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.04971284419298172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:14<11:13,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.0795496478676796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:38<09:50,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.0380486398935318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:04<08:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.08550478518009186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:28<06:56,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.043934497982263565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:54<05:35,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.04590887948870659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:19<04:09,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.04855327680706978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:43<02:42,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.05298909917473793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:08<01:19,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.029168616980314255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:27<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.04904661794440656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 4\n",
      "0 0.026704255491495132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:23<13:58,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.05808478593826294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:48<12:33,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.025353647768497467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:12<11:10,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.021489042788743973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:37<09:58,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.042850248515605927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:02<08:19,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.054410506039857864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:26<06:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.031646497547626495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:51<05:28,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.017249086871743202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:15<04:08,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.026776831597089767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:40<02:44,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.02631445974111557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:04<01:18,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.03475423902273178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:23<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.044056798879623035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 5\n",
      "0 0.013602087274193764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:23<13:55,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.034305766224861145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:47<12:37,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.03575950115919113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:12<11:12,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.013514560647308826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:37<09:45,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.024771912023425102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:01<08:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.020073162391781807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:25<06:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.020453548058867455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:50<05:33,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.024407682940363884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:14<04:08,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.030071256682276726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:39<02:43,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.02996644377708435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:03<01:19,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.04244965314865112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:23<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.04195014015576932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 6\n",
      "0 0.024690944701433182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:23<13:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.011360324919223785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:48<12:36,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.0168779119849205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:12<11:03,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.02469545230269432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:36<09:46,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.015019161626696587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:01<08:18,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.01906036026775837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:25<06:55,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.034787099808454514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:50<05:33,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.025589583441615105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:15<04:06,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.02153453230857849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:40<02:44,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.0254032164812088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:04<01:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.031780827790498734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:24<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.03860897693858199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 7\n",
      "0 0.013566283509135246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:23<13:53,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.014976832084357738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:48<12:30,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.014361371286213398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:12<11:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.015050695277750492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:36<09:46,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.019583871588110924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:01<08:19,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.017854850739240646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:26<06:55,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.009049098938703537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:50<05:30,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.014655505307018757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:15<04:07,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.015048854984343052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:39<02:51,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.04169425740838051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:04<01:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.014370930381119251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:23<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.037570227344249245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 8\n",
      "0 0.015273360535502434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:23<14:02,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.011275711469352245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:48<12:37,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.010300198569893837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:12<11:12,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.008412590250372887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:37<09:46,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.008446792140603065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:01<08:22,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.03235498443245888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:26<06:58,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.012661220505833626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:50<05:31,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.009705470874905586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:15<04:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.02916182391345501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:39<02:42,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.032449908554553986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:03<01:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.010830389335751534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:22<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.036785424871169786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model has been saved\n",
      "Epoch 9\n",
      "0 0.011232484132051468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 50/547 [01:24<13:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.007293162401765585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 100/547 [02:48<12:34,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.009522488340735435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 150/547 [04:13<11:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 0.010598580352962017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 200/547 [05:37<09:48,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.00769262108951807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 250/547 [07:01<08:19,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 0.008425921201705933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 300/547 [08:26<06:57,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.007476712577044964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 350/547 [09:51<06:08,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 0.0072775837033987045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 400/547 [11:15<04:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 0.014661370776593685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 450/547 [12:39<02:44,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0.01551075093448162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 500/547 [14:04<01:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.00663610827177763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [15:24<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mlogloss: 0.035624597905737146\n",
      "The best model has been saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Testing-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8f984cf8c7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest_oof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_oof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b426f5642f23>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_df, val_df, test_oof)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtest_oof\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mto_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1067a4a8b620>\u001b[0m in \u001b[0;36mto_predict\u001b[0;34m(model, dataloader, output_model, with_labels)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0mpredict1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0mpredict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mpredict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1067a4a8b620>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, labels1, labels2)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/wwaAI1/my_docker/code/model/modeling_nezha.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, head_mask, position_ids, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "n_fold=KFold(8,shuffle=True,random_state=1080)\n",
    "test_oof=0\n",
    "epochs = 10\n",
    "test_set = CustomDataset(test, maxlen=128, tokenizer=tokenizer,with_labels=False)\n",
    "test_loader = Data.DataLoader(test_set, batch_size=batch_size, num_workers=5, shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for trn_idx,val_idx in n_fold.split(train):\n",
    "    train_df=train.iloc[trn_idx].reset_index(drop=True)\n",
    "    val_df=train.iloc[val_idx].reset_index(drop=True)\n",
    "    best_score = float('inf')\n",
    "    test_oof=train_model(train_df,val_df,test_oof)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "                 weight_decay=0.05  weight_decay==0.1                                                drop=0.3    11classdrop=0.3  \n",
    "0.066  0.073     ->0.0698       ->0.073                 0.0710        0.069    0.0668      0.0647   0.0679         0.066824         0.0687\n",
    "0.0463  0.0476  -> 0.0454     ->0.051                   0.051         0.0475   0.04689     0.0496   0.0484          0.0491          0.04818\n",
    "        0.0386  ->0.03709 ->0.039                     0.042           0.0407              0.03816   0.03861          0.0398         0.040\n",
    "       0.0357  ->0.0342                         0.039                 0.0347               0.03532   0.035           0.03639\n",
    "                                                                                                    0.0343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adopted-struggle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:00:29.947549Z",
     "start_time": "2021-04-17T07:00:29.773942Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-95ede7728bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'report_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m'|'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%.12f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_oof\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# sub.to_csv('../result.csv',index=False,header=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf2/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "sub=pd.DataFrame()\n",
    "test=pd.read_csv('../tcdata/testA.csv',header=None)\n",
    "sub['report_ID']=test[0]\n",
    "sub['Prediction']=[ '|'+' '.join(['%.12f'%j for j in i]) for i in test_oof ]\n",
    "sub.to_csv('../result.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-captain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
