{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unable-israel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T02:56:44.494036Z",
     "start_time": "2021-05-10T02:56:41.199862Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import Model\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Embedding, Dense, CuDNNLSTM,CuDNNGRU, Bidirectional,SpatialDropout1D,Input,\\\n",
    "GlobalAveragePooling1D,GlobalMaxPooling1D,Conv1D,concatenate,Dropout,Activation,BatchNormalization,Concatenate,Add,\\\n",
    "MaxPooling1D,Flatten,AveragePooling1D\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "import gensim, logging\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.model_selection import KFold,StratifiedShuffleSplit,StratifiedKFold\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pregnant-ozone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T02:57:32.021302Z",
     "start_time": "2021-05-10T02:57:31.920585Z"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../../tcdata/train.csv',header=None)\n",
    "test=pd.read_csv('../../tcdata/track1_round1_testB.csv',header=None)\n",
    "# test=pd.read_csv('../tcdata/testA.csv',header=None)\n",
    "data=pd.concat([train,test],axis=0)\n",
    "data[1]=data[1].apply(lambda x:x.strip().replace('|',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noble-manhattan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T02:57:44.208007Z",
     "start_time": "2021-05-10T02:57:44.109632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncase label1: 0\n",
      "noncase label2: 8247\n"
     ]
    }
   ],
   "source": [
    "## 制作标签\n",
    "### 创建训练集标签 \n",
    "train_labels1=np.zeros((len(train),17),dtype='int8')\n",
    "noncase=0\n",
    "for cnt,i in enumerate(train[2]):\n",
    "    if i:\n",
    "        lab=[int(x.replace('|','').strip()) for x in i.split(' ') if x and x!='|']\n",
    "        for l in lab:\n",
    "            train_labels1[cnt,l]=1\n",
    "    else:\n",
    "        noncase+=1\n",
    "print('noncase label1:',noncase)\n",
    "#----------------------------------\n",
    "noncase=0\n",
    "train_labels2=np.zeros((len(train),12),dtype='int8')\n",
    "for cnt,i in enumerate(train[3]):\n",
    "    if pd.notna(i):\n",
    "        lab=[int(x.replace('|','').strip()) for x in i.split(' ') if x and x!='|']\n",
    "        for l in lab:\n",
    "            train_labels2[cnt,l]=1\n",
    "    else:\n",
    "        noncase+=1\n",
    "print('noncase label2:',noncase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "auburn-payment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T02:59:03.556794Z",
     "start_time": "2021-05-10T02:59:03.550729Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels=np.concatenate([train_labels1,train_labels2],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "after-shore",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T02:59:24.601021Z",
     "start_time": "2021-05-10T02:59:24.597077Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "framed-fleet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T03:02:05.720068Z",
     "start_time": "2021-05-10T03:02:03.752518Z"
    }
   },
   "outputs": [],
   "source": [
    "c=list()\n",
    "for i in train_labels:\n",
    "    c.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "5,12,16-1,3,6\n",
    "1,8-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cardiovascular-vitamin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T03:05:47.190385Z",
     "start_time": "2021-05-10T03:05:47.125347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]', 8236),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 585),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 480),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 474),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 293),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 293),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 281),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 256),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0]', 177),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 176),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 140),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 140),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 138),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 128),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 125),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 122),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 122),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 117),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 97),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 95),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 81),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 78),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0]', 76),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 75),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 74),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 74),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 72),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0]', 71),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 70),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 69),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 66),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 64),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 62),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 59),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 58),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 57),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 52),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 52),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 52),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 51),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 49),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 49),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 45),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 45),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 45),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 44),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 43),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]', 42),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 40),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 39),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 39),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 33),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 33),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 33),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 32),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 32),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 32),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]', 32),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 32),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 32),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 32),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0]', 31),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 31),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 31),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]', 30),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 30),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 30),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 30),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 29),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 29),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 28),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]', 28),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 28),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]', 27),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 27),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 27),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 26),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]', 26),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 25),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 24),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 23),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 23),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 22),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 22),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 22),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 22),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 21),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 21),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 21),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 21),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 21),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 21),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 21),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 20),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 20),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 20),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 20),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 20),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 20),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 20),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 19),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 19),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 19),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 19),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 19),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 18),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 18),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 18),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 17),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 17),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 17),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 17),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 17),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 17),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 17),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 17),\n",
       " ('[1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 17),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 16),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 16),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 16),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 16),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 16),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 15),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 15),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 15),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 15),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 15),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 14),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 14),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 14),\n",
       " ('[0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 14),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0]', 14),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 13),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 13),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 13),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 13),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 12),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 12),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 12),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 11),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 11),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 11),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 11),\n",
       " ('[1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 11),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 11),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 11),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 11),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 10),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 10),\n",
       " ('[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 10),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0]', 10),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 10),\n",
       " ('[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 10),\n",
       " ('[0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 10),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 10),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 10),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 10),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0]', 10),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0]', 9),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 9),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 9),\n",
       " ('[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]', 9),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 9),\n",
       " ('[1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 9),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 9),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 9),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 8),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 8),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 8),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 8),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 8),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]', 8),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 8),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 8),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]', 8),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 8),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 8),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]', 7),\n",
       " ('[1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 7),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 7),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 7),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]', 7),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 7),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 7),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 7),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 7),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 7),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 7),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 6),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]', 6),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 6),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 6),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 6),\n",
       " ('[0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 6),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 6),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 6),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0]', 6),\n",
       " ('[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1]', 6),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1]', 6),\n",
       " ('[0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 6),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 5),\n",
       " ('[0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]', 5),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0]', 5),\n",
       " ('[1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 5),\n",
       " ('[1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 5),\n",
       " ('[0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 5),\n",
       " ('[0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 5),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 5),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 5),\n",
       " ('[1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 5),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 5),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 5),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 5),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1]', 4),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 4),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 4),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 4),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 4),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]', 4),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]', 4),\n",
       " ('[0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]', 4),\n",
       " ('[0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 4),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]', 4),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]', 4),\n",
       " ('[0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 4),\n",
       " ('[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]', 4),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1]', 4),\n",
       " ('[1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 4),\n",
       " ('[0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]', 4),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 4),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]', 4),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0]', 4),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1]', 4),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 4),\n",
       " ('[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 4),\n",
       " ('[1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 4),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]', 4),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]', 4),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]', 4),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0]', 4),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 4),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]', 3),\n",
       " ('[1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 3),\n",
       " ('[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]', 3),\n",
       " ('[0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]', 3),\n",
       " ('[0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 3),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]', 3),\n",
       " ('[1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]', 3),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1]', 3),\n",
       " ('[0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 3),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0]', 3),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1]', 3),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]', 3),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1]', 3),\n",
       " ('[0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 3),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 3),\n",
       " ('[1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]', 3),\n",
       " ('[1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 3),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]', 2),\n",
       " ('[0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1]', 2),\n",
       " ('[1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0]', 2),\n",
       " ('[0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0]', 2),\n",
       " ('[0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1]', 2),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 2),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0]', 2),\n",
       " ('[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1]', 2),\n",
       " ('[1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0]', 2),\n",
       " ('[1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1]', 2),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1]', 2),\n",
       " ('[0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]', 2),\n",
       " ('[1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]', 2),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0]', 2),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0]', 2),\n",
       " ('[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]', 2),\n",
       " ('[1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]', 2),\n",
       " ('[1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]', 2),\n",
       " ('[0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0]', 2),\n",
       " ('[0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1]', 2),\n",
       " ('[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]', 2),\n",
       " ('[1 0 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]', 2),\n",
       " ('[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]', 2),\n",
       " ('[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 2),\n",
       " ('[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1]', 2),\n",
       " ('[1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1]', 2),\n",
       " ('[1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]', 2),\n",
       " ('[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]', 2),\n",
       " ('[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]', 2),\n",
       " ('[1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0]', 2),\n",
       " ('[0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]', 1),\n",
       " ('[1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 1),\n",
       " ('[1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 1),\n",
       " ('[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0]', 1),\n",
       " ('[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]', 1),\n",
       " ('[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]', 1),\n",
       " ('[0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(a.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stylish-stress",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T03:04:24.197525Z",
     "start_time": "2021-05-10T03:04:24.189101Z"
    }
   },
   "outputs": [],
   "source": [
    "a=collections.Counter(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demonstrated-musician",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:07:17.182472Z",
     "start_time": "2021-04-26T05:07:17.155490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncase label1: 0\n",
      "noncase label2: 839\n"
     ]
    }
   ],
   "source": [
    "## 制作标签\n",
    "### 创建训练集标签 \n",
    "test_labels1=np.zeros((len(test),17),dtype='int8')\n",
    "noncase=0\n",
    "for cnt,i in enumerate(test[2]):\n",
    "    if i:\n",
    "        lab=[int(x.replace('|','').strip()) for x in i.split(' ') if x and x!='|']\n",
    "        for l in lab:\n",
    "            test_labels1[cnt,l]=1\n",
    "    else:\n",
    "        noncase+=1\n",
    "print('noncase label1:',noncase)\n",
    "#----------------------------------\n",
    "noncase=0\n",
    "test_labels2=np.zeros((len(test),12),dtype='int8')\n",
    "for cnt,i in enumerate(test[3]):\n",
    "    if pd.notna(i):\n",
    "        lab=[int(x.replace('|','').strip()) for x in i.split(' ') if x and x!='|']\n",
    "        for l in lab:\n",
    "            test_labels2[cnt,l]=1\n",
    "    else:\n",
    "        noncase+=1\n",
    "print('noncase label2:',noncase)\n",
    "test_labels=np.concatenate([test_labels1,test_labels2],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "specified-hebrew",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:07:22.408672Z",
     "start_time": "2021-04-26T05:07:22.401404Z"
    }
   },
   "outputs": [],
   "source": [
    "cate_num=train_labels1.sum(1)+train_labels2.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "english-burlington",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:07:23.183109Z",
     "start_time": "2021-04-26T05:07:22.873223Z"
    }
   },
   "outputs": [],
   "source": [
    "## 生成全部的训练文本\n",
    "data1=pd.read_csv('../tcdata/track1_round1_train_20210222.csv',header=None)\n",
    "data2=pd.read_csv('../tcdata/track1_round1_testA_20210222.csv',header=None)\n",
    "data3=pd.read_csv('../tcdata/track1_round1_testB.csv',header=None)\n",
    "text_data=pd.concat([train,data1,data2,data3],axis=0)\n",
    "text_data[1]=text_data[1].apply(lambda x:x.strip().replace('|',''))\n",
    "text_data[1].to_csv('../tmp/all_data.txt',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "overhead-plenty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T06:07:16.368462Z",
     "start_time": "2021-04-15T06:07:16.288461Z"
    }
   },
   "outputs": [],
   "source": [
    "text_data=pd.read_csv('../tmp/all_data.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-afternoon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:07:32.030529Z",
     "start_time": "2021-04-26T05:07:32.026660Z"
    }
   },
   "outputs": [],
   "source": [
    "# w2v=Word2Vec(text_data[0].apply(lambda x:x.split(' ')).tolist(),size=128, window=8, iter=30, min_count=2,\n",
    "#                      sg=1, sample=0.002, workers=6 , seed=1017)\n",
    "\n",
    "# w2v.wv.save_word2vec_format('../tmp/w2v_128.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dental-thing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:07:33.392535Z",
     "start_time": "2021-04-26T05:07:32.376468Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=False, char_level=False, split=' ')\n",
    "tokenizer.fit_on_texts(data[1].tolist())\n",
    "seq = tokenizer.texts_to_sequences(data[1].tolist())\n",
    "# 分训练和测试集合\n",
    "seq = pad_sequences(seq, maxlen=128, value=0)\n",
    "train_seq=np.asarray(seq[:len(train)])\n",
    "test_seq=seq[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "governmental-netscape",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:07:33.708916Z",
     "start_time": "2021-04-26T05:07:33.568106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-26 13:07:33,571 : INFO : loading projection weights from ../tmp/w2v_128.txt\n",
      "2021-04-26 13:07:33,690 : INFO : loaded (859, 128) matrix from ../tmp/w2v_128.txt\n",
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(859, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix=np.zeros((len(tokenizer.word_index)+1,128))\n",
    "w2v=gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        '../tmp/w2v_128.txt', binary=False)\n",
    "\n",
    "for word in tokenizer.word_index:\n",
    "    if word not in w2v.wv.vocab:\n",
    "        continue\n",
    "    embedding_matrix[tokenizer.word_index[word]] = w2v[word]\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compact-bearing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:08:52.707742Z",
     "start_time": "2021-04-26T05:08:52.674743Z"
    }
   },
   "outputs": [],
   "source": [
    "def NN_huaweiv1(maxlen,embedding_matrix=None,class_num1=17,class_num2=12):    \n",
    "    emb_layer = Embedding(\n",
    "       embedding_matrix.shape[0], embedding_matrix.shape[1],input_length=maxlen,weights=[embedding_matrix],trainable=False,\n",
    "    )\n",
    "    seq1 = Input(shape=(maxlen,)) \n",
    "    \n",
    "    x1 = emb_layer(seq1)\n",
    "    sdrop=SpatialDropout1D(rate=0.2)\n",
    "    lstm_layer = Bidirectional(CuDNNGRU(128, return_sequences=True))\n",
    "    gru_layer = Bidirectional(CuDNNGRU(128, return_sequences=True))\n",
    "    cnn1d_layer=Conv1D(64, kernel_size=3, padding=\"same\", kernel_initializer=\"he_uniform\")\n",
    "    x1 = sdrop(x1)\n",
    "    lstm1 = lstm_layer(x1)\n",
    "    gru1 = gru_layer(lstm1)\n",
    "    att_1 = Attention(maxlen)(lstm1)\n",
    "    att_2 = Attention(maxlen)(gru1)\n",
    "    cnn1 = cnn1d_layer(lstm1)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()\n",
    "    max_pool = GlobalMaxPooling1D()\n",
    "\n",
    "    x1=concatenate([att_1,att_2,Attention(maxlen)(cnn1),avg_pool(cnn1),max_pool(cnn1)])\n",
    "\n",
    "    x = Dropout(0.2)(Activation(activation=\"relu\")(BatchNormalization()(Dense(128)(x1))))\n",
    "    x = Activation(activation=\"relu\")(BatchNormalization()(Dense(64)(x)))\n",
    "    pred1 = Dense(class_num1, activation='sigmoid',name='pred1')(x)\n",
    "    y=concatenate([x1,x])\n",
    "    y = Activation(activation=\"relu\")(BatchNormalization()(Dense(64)(x)))\n",
    "    pred2=Dense(class_num2, activation='sigmoid',name='pred2')(y)\n",
    "    \n",
    "    model = Model(inputs=seq1, outputs=[pred1,pred2])\n",
    "    return model\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            # 1\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "            # 2\n",
    "            hidden = LSTM(64, return_sequences=True)(words)\n",
    "            sentence = Attention()(hidden)\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "#         print('-------------',type(input_shape))\n",
    "        self.W = self.add_weight(name='{}_W'.format(self.name),\n",
    "                                 shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(name='{}_b'.format(self.name),\n",
    "                                     shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        e = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))  # e = K.dot(x, self.W)\n",
    "        if self.bias:\n",
    "            e += self.b\n",
    "        e = K.tanh(e)\n",
    "\n",
    "        a = K.exp(e)\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "\n",
    "        c = K.sum(a * x, axis=1)\n",
    "        return c\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return -K.mean(y_true*K.log(y_pred+1.e-7)+(1-y_true)*K.log(1-y_pred+1.e-7))*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accurate-butler",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:37:27.426773Z",
     "start_time": "2021-04-26T05:13:36.614778Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lichangyv/miniconda3/envs/torch13/lib/python3.6/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 14400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "14400/14400 [==============================] - 8s 576us/step - loss: 0.6509 - pred1_loss: 0.3714 - pred2_loss: 0.2794 - pred1_acc: 0.8538 - pred1_mean_pred: 3.7141 - pred2_acc: 0.9146 - pred2_mean_pred: 2.7944 - val_loss: 0.3113 - val_pred1_loss: 0.1921 - val_pred2_loss: 0.1192 - val_pred1_acc: 0.9466 - val_pred1_mean_pred: 1.9210 - val_pred2_acc: 0.9705 - val_pred2_mean_pred: 1.1923\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31132, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 2/100\n",
      "14400/14400 [==============================] - 5s 365us/step - loss: 0.2600 - pred1_loss: 0.1626 - pred2_loss: 0.0974 - pred1_acc: 0.9472 - pred1_mean_pred: 1.6259 - pred2_acc: 0.9730 - pred2_mean_pred: 0.9740 - val_loss: 0.2225 - val_pred1_loss: 0.1425 - val_pred2_loss: 0.0800 - val_pred1_acc: 0.9498 - val_pred1_mean_pred: 1.4253 - val_pred2_acc: 0.9774 - val_pred2_mean_pred: 0.7995\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31132 to 0.22249, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 3/100\n",
      "14400/14400 [==============================] - 5s 378us/step - loss: 0.1995 - pred1_loss: 0.1273 - pred2_loss: 0.0722 - pred1_acc: 0.9535 - pred1_mean_pred: 1.2731 - pred2_acc: 0.9776 - pred2_mean_pred: 0.7219 - val_loss: 0.1808 - val_pred1_loss: 0.1165 - val_pred2_loss: 0.0643 - val_pred1_acc: 0.9571 - val_pred1_mean_pred: 1.1649 - val_pred2_acc: 0.9810 - val_pred2_mean_pred: 0.6433\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22249 to 0.18082, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 4/100\n",
      "14400/14400 [==============================] - 6s 385us/step - loss: 0.1686 - pred1_loss: 0.1106 - pred2_loss: 0.0580 - pred1_acc: 0.9571 - pred1_mean_pred: 1.1060 - pred2_acc: 0.9816 - pred2_mean_pred: 0.5799 - val_loss: 0.1560 - val_pred1_loss: 0.0996 - val_pred2_loss: 0.0564 - val_pred1_acc: 0.9594 - val_pred1_mean_pred: 0.9957 - val_pred2_acc: 0.9808 - val_pred2_mean_pred: 0.5641\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18082 to 0.15599, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 5/100\n",
      "14400/14400 [==============================] - 6s 391us/step - loss: 0.1497 - pred1_loss: 0.1003 - pred2_loss: 0.0495 - pred1_acc: 0.9591 - pred1_mean_pred: 1.0025 - pred2_acc: 0.9840 - pred2_mean_pred: 0.4949 - val_loss: 0.1408 - val_pred1_loss: 0.0941 - val_pred2_loss: 0.0467 - val_pred1_acc: 0.9603 - val_pred1_mean_pred: 0.9406 - val_pred2_acc: 0.9852 - val_pred2_mean_pred: 0.4670\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15599 to 0.14076, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 6/100\n",
      "14400/14400 [==============================] - 6s 404us/step - loss: 0.1372 - pred1_loss: 0.0928 - pred2_loss: 0.0444 - pred1_acc: 0.9612 - pred1_mean_pred: 0.9281 - pred2_acc: 0.9856 - pred2_mean_pred: 0.4441 - val_loss: 0.1285 - val_pred1_loss: 0.0873 - val_pred2_loss: 0.0412 - val_pred1_acc: 0.9625 - val_pred1_mean_pred: 0.8731 - val_pred2_acc: 0.9859 - val_pred2_mean_pred: 0.4123\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14076 to 0.12854, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 7/100\n",
      "14400/14400 [==============================] - 6s 405us/step - loss: 0.1249 - pred1_loss: 0.0853 - pred2_loss: 0.0396 - pred1_acc: 0.9639 - pred1_mean_pred: 0.8531 - pred2_acc: 0.9867 - pred2_mean_pred: 0.3960 - val_loss: 0.1277 - val_pred1_loss: 0.0781 - val_pred2_loss: 0.0496 - val_pred1_acc: 0.9683 - val_pred1_mean_pred: 0.7815 - val_pred2_acc: 0.9845 - val_pred2_mean_pred: 0.4958\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12854 to 0.12772, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 8/100\n",
      "14400/14400 [==============================] - 6s 414us/step - loss: 0.1131 - pred1_loss: 0.0754 - pred2_loss: 0.0376 - pred1_acc: 0.9704 - pred1_mean_pred: 0.7543 - pred2_acc: 0.9875 - pred2_mean_pred: 0.3763 - val_loss: 0.1016 - val_pred1_loss: 0.0658 - val_pred2_loss: 0.0358 - val_pred1_acc: 0.9763 - val_pred1_mean_pred: 0.6579 - val_pred2_acc: 0.9882 - val_pred2_mean_pred: 0.3583\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12772 to 0.10161, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 9/100\n",
      "14400/14400 [==============================] - 6s 411us/step - loss: 0.0975 - pred1_loss: 0.0637 - pred2_loss: 0.0338 - pred1_acc: 0.9771 - pred1_mean_pred: 0.6370 - pred2_acc: 0.9885 - pred2_mean_pred: 0.3377 - val_loss: 0.0945 - val_pred1_loss: 0.0601 - val_pred2_loss: 0.0344 - val_pred1_acc: 0.9784 - val_pred1_mean_pred: 0.6010 - val_pred2_acc: 0.9890 - val_pred2_mean_pred: 0.3445\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10161 to 0.09455, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 10/100\n",
      "14400/14400 [==============================] - 6s 426us/step - loss: 0.0887 - pred1_loss: 0.0576 - pred2_loss: 0.0312 - pred1_acc: 0.9796 - pred1_mean_pred: 0.5757 - pred2_acc: 0.9897 - pred2_mean_pred: 0.3117 - val_loss: 0.0846 - val_pred1_loss: 0.0500 - val_pred2_loss: 0.0347 - val_pred1_acc: 0.9828 - val_pred1_mean_pred: 0.4996 - val_pred2_acc: 0.9889 - val_pred2_mean_pred: 0.3466\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09455 to 0.08461, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 11/100\n",
      "14400/14400 [==============================] - 7s 460us/step - loss: 0.0812 - pred1_loss: 0.0527 - pred2_loss: 0.0285 - pred1_acc: 0.9814 - pred1_mean_pred: 0.5269 - pred2_acc: 0.9901 - pred2_mean_pred: 0.2854 - val_loss: 0.0787 - val_pred1_loss: 0.0485 - val_pred2_loss: 0.0303 - val_pred1_acc: 0.9834 - val_pred1_mean_pred: 0.4847 - val_pred2_acc: 0.9902 - val_pred2_mean_pred: 0.3027\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08461 to 0.07874, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 12/100\n",
      "14400/14400 [==============================] - 7s 464us/step - loss: 0.0753 - pred1_loss: 0.0490 - pred2_loss: 0.0262 - pred1_acc: 0.9831 - pred1_mean_pred: 0.4905 - pred2_acc: 0.9910 - pred2_mean_pred: 0.2625 - val_loss: 0.0777 - val_pred1_loss: 0.0468 - val_pred2_loss: 0.0308 - val_pred1_acc: 0.9836 - val_pred1_mean_pred: 0.4684 - val_pred2_acc: 0.9899 - val_pred2_mean_pred: 0.3082\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07874 to 0.07766, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 13/100\n",
      "14400/14400 [==============================] - 7s 464us/step - loss: 0.0698 - pred1_loss: 0.0454 - pred2_loss: 0.0244 - pred1_acc: 0.9840 - pred1_mean_pred: 0.4540 - pred2_acc: 0.9919 - pred2_mean_pred: 0.2437 - val_loss: 0.0723 - val_pred1_loss: 0.0438 - val_pred2_loss: 0.0286 - val_pred1_acc: 0.9849 - val_pred1_mean_pred: 0.4376 - val_pred2_acc: 0.9902 - val_pred2_mean_pred: 0.2856\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07766 to 0.07232, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 14/100\n",
      "14400/14400 [==============================] - 8s 556us/step - loss: 0.0658 - pred1_loss: 0.0430 - pred2_loss: 0.0228 - pred1_acc: 0.9848 - pred1_mean_pred: 0.4304 - pred2_acc: 0.9921 - pred2_mean_pred: 0.2276 - val_loss: 0.0719 - val_pred1_loss: 0.0425 - val_pred2_loss: 0.0294 - val_pred1_acc: 0.9855 - val_pred1_mean_pred: 0.4251 - val_pred2_acc: 0.9900 - val_pred2_mean_pred: 0.2942\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07232 to 0.07192, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 15/100\n",
      "14400/14400 [==============================] - 8s 568us/step - loss: 0.0609 - pred1_loss: 0.0402 - pred2_loss: 0.0208 - pred1_acc: 0.9857 - pred1_mean_pred: 0.4017 - pred2_acc: 0.9931 - pred2_mean_pred: 0.2076 - val_loss: 0.0708 - val_pred1_loss: 0.0433 - val_pred2_loss: 0.0275 - val_pred1_acc: 0.9850 - val_pred1_mean_pred: 0.4333 - val_pred2_acc: 0.9907 - val_pred2_mean_pred: 0.2750loss: 0.0404 - pred2_loss: 0.0207 - pred1_acc: 0.9856 - pred1_mean_pred: 0.4036 - pred2_acc: 0.9932 - pred2_mean_pred:\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07192 to 0.07083, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 16/100\n",
      "14400/14400 [==============================] - 8s 567us/step - loss: 0.0580 - pred1_loss: 0.0384 - pred2_loss: 0.0196 - pred1_acc: 0.9866 - pred1_mean_pred: 0.3841 - pred2_acc: 0.9934 - pred2_mean_pred: 0.1963 - val_loss: 0.0695 - val_pred1_loss: 0.0430 - val_pred2_loss: 0.0265 - val_pred1_acc: 0.9855 - val_pred1_mean_pred: 0.4302 - val_pred2_acc: 0.9911 - val_pred2_mean_pred: 0.2650\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.07083 to 0.06952, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 17/100\n",
      "14400/14400 [==============================] - 8s 569us/step - loss: 0.0546 - pred1_loss: 0.0362 - pred2_loss: 0.0184 - pred1_acc: 0.9872 - pred1_mean_pred: 0.3616 - pred2_acc: 0.9939 - pred2_mean_pred: 0.1839 - val_loss: 0.0670 - val_pred1_loss: 0.0409 - val_pred2_loss: 0.0261 - val_pred1_acc: 0.9861 - val_pred1_mean_pred: 0.4088 - val_pred2_acc: 0.9916 - val_pred2_mean_pred: 0.2611\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.06952 to 0.06699, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 18/100\n",
      "14400/14400 [==============================] - 17s 1ms/step - loss: 0.0509 - pred1_loss: 0.0340 - pred2_loss: 0.0169 - pred1_acc: 0.9879 - pred1_mean_pred: 0.3403 - pred2_acc: 0.9943 - pred2_mean_pred: 0.1686 - val_loss: 0.0647 - val_pred1_loss: 0.0383 - val_pred2_loss: 0.0264 - val_pred1_acc: 0.9866 - val_pred1_mean_pred: 0.3826 - val_pred2_acc: 0.9916 - val_pred2_mean_pred: 0.2641\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06699 to 0.06467, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 19/100\n",
      "14400/14400 [==============================] - 18s 1ms/step - loss: 0.0485 - pred1_loss: 0.0325 - pred2_loss: 0.0160 - pred1_acc: 0.9884 - pred1_mean_pred: 0.3248 - pred2_acc: 0.9946 - pred2_mean_pred: 0.1597 - val_loss: 0.0630 - val_pred1_loss: 0.0376 - val_pred2_loss: 0.0254 - val_pred1_acc: 0.9865 - val_pred1_mean_pred: 0.3761 - val_pred2_acc: 0.9921 - val_pred2_mean_pred: 0.2541\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06467 to 0.06302, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 20/100\n",
      "14400/14400 [==============================] - 18s 1ms/step - loss: 0.0473 - pred1_loss: 0.0315 - pred2_loss: 0.0158 - pred1_acc: 0.9887 - pred1_mean_pred: 0.3152 - pred2_acc: 0.9945 - pred2_mean_pred: 0.1579 - val_loss: 0.0616 - val_pred1_loss: 0.0378 - val_pred2_loss: 0.0238 - val_pred1_acc: 0.9870 - val_pred1_mean_pred: 0.3781 - val_pred2_acc: 0.9924 - val_pred2_mean_pred: 0.2377\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06302 to 0.06159, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 21/100\n",
      "14400/14400 [==============================] - 11s 773us/step - loss: 0.0442 - pred1_loss: 0.0300 - pred2_loss: 0.0142 - pred1_acc: 0.9894 - pred1_mean_pred: 0.2997 - pred2_acc: 0.9952 - pred2_mean_pred: 0.1423 - val_loss: 0.0633 - val_pred1_loss: 0.0384 - val_pred2_loss: 0.0249 - val_pred1_acc: 0.9866 - val_pred1_mean_pred: 0.3841 - val_pred2_acc: 0.9925 - val_pred2_mean_pred: 0.2488\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06159\n",
      "Epoch 22/100\n",
      "14400/14400 [==============================] - 10s 707us/step - loss: 0.0422 - pred1_loss: 0.0284 - pred2_loss: 0.0138 - pred1_acc: 0.9899 - pred1_mean_pred: 0.2841 - pred2_acc: 0.9953 - pred2_mean_pred: 0.1380 - val_loss: 0.0623 - val_pred1_loss: 0.0392 - val_pred2_loss: 0.0231 - val_pred1_acc: 0.9867 - val_pred1_mean_pred: 0.3918 - val_pred2_acc: 0.9928 - val_pred2_mean_pred: 0.2309\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.06159\n",
      "Fold 1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 14400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "14400/14400 [==============================] - 14s 959us/step - loss: 0.6807 - pred1_loss: 0.3701 - pred2_loss: 0.3106 - pred1_acc: 0.8593 - pred1_mean_pred: 3.7010 - pred2_acc: 0.8987 - pred2_mean_pred: 3.1058 - val_loss: 0.3055 - val_pred1_loss: 0.1837 - val_pred2_loss: 0.1218 - val_pred1_acc: 0.9449 - val_pred1_mean_pred: 1.8367 - val_pred2_acc: 0.9690 - val_pred2_mean_pred: 1.2181\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30548, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 2/100\n",
      "14400/14400 [==============================] - 10s 714us/step - loss: 0.2616 - pred1_loss: 0.1618 - pred2_loss: 0.0998 - pred1_acc: 0.9472 - pred1_mean_pred: 1.6180 - pred2_acc: 0.9738 - pred2_mean_pred: 0.9984 - val_loss: 0.2196 - val_pred1_loss: 0.1407 - val_pred2_loss: 0.0789 - val_pred1_acc: 0.9535 - val_pred1_mean_pred: 1.4068 - val_pred2_acc: 0.9782 - val_pred2_mean_pred: 0.7889\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30548 to 0.21957, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 3/100\n",
      "14400/14400 [==============================] - 10s 728us/step - loss: 0.2017 - pred1_loss: 0.1300 - pred2_loss: 0.0716 - pred1_acc: 0.9523 - pred1_mean_pred: 1.3005 - pred2_acc: 0.9784 - pred2_mean_pred: 0.7160 - val_loss: 0.1786 - val_pred1_loss: 0.1179 - val_pred2_loss: 0.0607 - val_pred1_acc: 0.9552 - val_pred1_mean_pred: 1.1790 - val_pred2_acc: 0.9818 - val_pred2_mean_pred: 0.6073\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21957 to 0.17863, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 4/100\n",
      "14400/14400 [==============================] - 10s 699us/step - loss: 0.1725 - pred1_loss: 0.1135 - pred2_loss: 0.0589 - pred1_acc: 0.9561 - pred1_mean_pred: 1.1352 - pred2_acc: 0.9814 - pred2_mean_pred: 0.5893 - val_loss: 0.1668 - val_pred1_loss: 0.1084 - val_pred2_loss: 0.0584 - val_pred1_acc: 0.9585 - val_pred1_mean_pred: 1.0842 - val_pred2_acc: 0.9833 - val_pred2_mean_pred: 0.5840\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17863 to 0.16682, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 5/100\n",
      "14400/14400 [==============================] - 10s 717us/step - loss: 0.1527 - pred1_loss: 0.1025 - pred2_loss: 0.0503 - pred1_acc: 0.9587 - pred1_mean_pred: 1.0246 - pred2_acc: 0.9836 - pred2_mean_pred: 0.5027 - val_loss: 0.1352 - val_pred1_loss: 0.0918 - val_pred2_loss: 0.0434 - val_pred1_acc: 0.9611 - val_pred1_mean_pred: 0.9177 - val_pred2_acc: 0.9862 - val_pred2_mean_pred: 0.4338\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16682 to 0.13515, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 6/100\n",
      "14400/14400 [==============================] - 10s 720us/step - loss: 0.1380 - pred1_loss: 0.0943 - pred2_loss: 0.0438 - pred1_acc: 0.9600 - pred1_mean_pred: 0.9427 - pred2_acc: 0.9858 - pred2_mean_pred: 0.4375 - val_loss: 0.1269 - val_pred1_loss: 0.0866 - val_pred2_loss: 0.0403 - val_pred1_acc: 0.9622 - val_pred1_mean_pred: 0.8657 - val_pred2_acc: 0.9869 - val_pred2_mean_pred: 0.4033\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13515 to 0.12690, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 7/100\n",
      "14400/14400 [==============================] - 10s 728us/step - loss: 0.1269 - pred1_loss: 0.0880 - pred2_loss: 0.0389 - pred1_acc: 0.9625 - pred1_mean_pred: 0.8797 - pred2_acc: 0.9870 - pred2_mean_pred: 0.3891 - val_loss: 0.1168 - val_pred1_loss: 0.0798 - val_pred2_loss: 0.0370 - val_pred1_acc: 0.9650 - val_pred1_mean_pred: 0.7983 - val_pred2_acc: 0.9878 - val_pred2_mean_pred: 0.3699\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12690 to 0.11682, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 8/100\n",
      "14400/14400 [==============================] - 10s 729us/step - loss: 0.1158 - pred1_loss: 0.0795 - pred2_loss: 0.0363 - pred1_acc: 0.9674 - pred1_mean_pred: 0.7955 - pred2_acc: 0.9881 - pred2_mean_pred: 0.3625 - val_loss: 0.1081 - val_pred1_loss: 0.0708 - val_pred2_loss: 0.0372 - val_pred1_acc: 0.9732 - val_pred1_mean_pred: 0.7084 - val_pred2_acc: 0.9882 - val_pred2_mean_pred: 0.3724\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11682 to 0.10808, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 9/100\n",
      "14400/14400 [==============================] - 10s 727us/step - loss: 0.1015 - pred1_loss: 0.0674 - pred2_loss: 0.0341 - pred1_acc: 0.9753 - pred1_mean_pred: 0.6739 - pred2_acc: 0.9887 - pred2_mean_pred: 0.3411 - val_loss: 0.0964 - val_pred1_loss: 0.0618 - val_pred2_loss: 0.0346 - val_pred1_acc: 0.9787 - val_pred1_mean_pred: 0.6183 - val_pred2_acc: 0.9885 - val_pred2_mean_pred: 0.3459\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10808 to 0.09642, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 10/100\n",
      "14400/14400 [==============================] - 11s 737us/step - loss: 0.0907 - pred1_loss: 0.0593 - pred2_loss: 0.0313 - pred1_acc: 0.9789 - pred1_mean_pred: 0.5933 - pred2_acc: 0.9895 - pred2_mean_pred: 0.3135 - val_loss: 0.0841 - val_pred1_loss: 0.0515 - val_pred2_loss: 0.0325 - val_pred1_acc: 0.9819 - val_pred1_mean_pred: 0.5152 - val_pred2_acc: 0.9893 - val_pred2_mean_pred: 0.3255\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09642 to 0.08407, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 11/100\n",
      "14400/14400 [==============================] - 11s 742us/step - loss: 0.0824 - pred1_loss: 0.0540 - pred2_loss: 0.0284 - pred1_acc: 0.9809 - pred1_mean_pred: 0.5403 - pred2_acc: 0.9906 - pred2_mean_pred: 0.2839 - val_loss: 0.0803 - val_pred1_loss: 0.0493 - val_pred2_loss: 0.0311 - val_pred1_acc: 0.9834 - val_pred1_mean_pred: 0.4925 - val_pred2_acc: 0.9897 - val_pred2_mean_pred: 0.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss improved from 0.08407 to 0.08034, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 12/100\n",
      "14400/14400 [==============================] - 10s 722us/step - loss: 0.0762 - pred1_loss: 0.0496 - pred2_loss: 0.0266 - pred1_acc: 0.9824 - pred1_mean_pred: 0.4960 - pred2_acc: 0.9909 - pred2_mean_pred: 0.2656 - val_loss: 0.0776 - val_pred1_loss: 0.0482 - val_pred2_loss: 0.0294 - val_pred1_acc: 0.9827 - val_pred1_mean_pred: 0.4822 - val_pred2_acc: 0.9903 - val_pred2_mean_pred: 0.2939\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08034 to 0.07761, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 13/100\n",
      "14400/14400 [==============================] - 10s 729us/step - loss: 0.0713 - pred1_loss: 0.0471 - pred2_loss: 0.0242 - pred1_acc: 0.9830 - pred1_mean_pred: 0.4708 - pred2_acc: 0.9919 - pred2_mean_pred: 0.2424 - val_loss: 0.0746 - val_pred1_loss: 0.0462 - val_pred2_loss: 0.0284 - val_pred1_acc: 0.9837 - val_pred1_mean_pred: 0.4623 - val_pred2_acc: 0.9911 - val_pred2_mean_pred: 0.2836\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07761 to 0.07459, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 14/100\n",
      "14400/14400 [==============================] - 11s 733us/step - loss: 0.0668 - pred1_loss: 0.0434 - pred2_loss: 0.0234 - pred1_acc: 0.9845 - pred1_mean_pred: 0.4340 - pred2_acc: 0.9921 - pred2_mean_pred: 0.2339 - val_loss: 0.0731 - val_pred1_loss: 0.0451 - val_pred2_loss: 0.0280 - val_pred1_acc: 0.9842 - val_pred1_mean_pred: 0.4510 - val_pred2_acc: 0.9909 - val_pred2_mean_pred: 0.2796\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07459 to 0.07306, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 15/100\n",
      "14400/14400 [==============================] - 11s 737us/step - loss: 0.0628 - pred1_loss: 0.0415 - pred2_loss: 0.0213 - pred1_acc: 0.9850 - pred1_mean_pred: 0.4152 - pred2_acc: 0.9928 - pred2_mean_pred: 0.2129 - val_loss: 0.0733 - val_pred1_loss: 0.0445 - val_pred2_loss: 0.0287 - val_pred1_acc: 0.9848 - val_pred1_mean_pred: 0.4451 - val_pred2_acc: 0.9906 - val_pred2_mean_pred: 0.2875\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.07306\n",
      "Epoch 16/100\n",
      "14400/14400 [==============================] - 10s 728us/step - loss: 0.0586 - pred1_loss: 0.0395 - pred2_loss: 0.0192 - pred1_acc: 0.9858 - pred1_mean_pred: 0.3949 - pred2_acc: 0.9935 - pred2_mean_pred: 0.1915 - val_loss: 0.0706 - val_pred1_loss: 0.0429 - val_pred2_loss: 0.0277 - val_pred1_acc: 0.9848 - val_pred1_mean_pred: 0.4288 - val_pred2_acc: 0.9916 - val_pred2_mean_pred: 0.2770\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.07306 to 0.07058, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 17/100\n",
      "14400/14400 [==============================] - 12s 842us/step - loss: 0.0556 - pred1_loss: 0.0371 - pred2_loss: 0.0185 - pred1_acc: 0.9869 - pred1_mean_pred: 0.3715 - pred2_acc: 0.9937 - pred2_mean_pred: 0.1848 - val_loss: 0.0675 - val_pred1_loss: 0.0420 - val_pred2_loss: 0.0255 - val_pred1_acc: 0.9854 - val_pred1_mean_pred: 0.4201 - val_pred2_acc: 0.9917 - val_pred2_mean_pred: 0.2551\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.07058 to 0.06752, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 18/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0529 - pred1_loss: 0.0356 - pred2_loss: 0.0173 - pred1_acc: 0.9873 - pred1_mean_pred: 0.3556 - pred2_acc: 0.9941 - pred2_mean_pred: 0.1735 - val_loss: 0.0670 - val_pred1_loss: 0.0401 - val_pred2_loss: 0.0269 - val_pred1_acc: 0.9864 - val_pred1_mean_pred: 0.4010 - val_pred2_acc: 0.9919 - val_pred2_mean_pred: 0.2689\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06752 to 0.06700, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 19/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0484 - pred1_loss: 0.0331 - pred2_loss: 0.0153 - pred1_acc: 0.9883 - pred1_mean_pred: 0.3311 - pred2_acc: 0.9948 - pred2_mean_pred: 0.1534 - val_loss: 0.0663 - val_pred1_loss: 0.0392 - val_pred2_loss: 0.0270 - val_pred1_acc: 0.9861 - val_pred1_mean_pred: 0.3924 - val_pred2_acc: 0.9919 - val_pred2_mean_pred: 0.2701\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06700 to 0.06625, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 20/100\n",
      "14400/14400 [==============================] - 18s 1ms/step - loss: 0.0473 - pred1_loss: 0.0324 - pred2_loss: 0.0149 - pred1_acc: 0.9883 - pred1_mean_pred: 0.3240 - pred2_acc: 0.9950 - pred2_mean_pred: 0.1486 - val_loss: 0.0632 - val_pred1_loss: 0.0394 - val_pred2_loss: 0.0238 - val_pred1_acc: 0.9865 - val_pred1_mean_pred: 0.3938 - val_pred2_acc: 0.9924 - val_pred2_mean_pred: 0.2378\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06625 to 0.06316, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 21/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0439 - pred1_loss: 0.0303 - pred2_loss: 0.0136 - pred1_acc: 0.9890 - pred1_mean_pred: 0.3025 - pred2_acc: 0.9954 - pred2_mean_pred: 0.1365 - val_loss: 0.0635 - val_pred1_loss: 0.0390 - val_pred2_loss: 0.0245 - val_pred1_acc: 0.9862 - val_pred1_mean_pred: 0.3897 - val_pred2_acc: 0.9927 - val_pred2_mean_pred: 0.2448\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06316\n",
      "Epoch 22/100\n",
      "14400/14400 [==============================] - 18s 1ms/step - loss: 0.0423 - pred1_loss: 0.0288 - pred2_loss: 0.0134 - pred1_acc: 0.9896 - pred1_mean_pred: 0.2884 - pred2_acc: 0.9953 - pred2_mean_pred: 0.1345 - val_loss: 0.0628 - val_pred1_loss: 0.0390 - val_pred2_loss: 0.0238 - val_pred1_acc: 0.9867 - val_pred1_mean_pred: 0.3901 - val_pred2_acc: 0.9926 - val_pred2_mean_pred: 0.2379\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06316 to 0.06280, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 23/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0397 - pred1_loss: 0.0273 - pred2_loss: 0.0124 - pred1_acc: 0.9902 - pred1_mean_pred: 0.2733 - pred2_acc: 0.9958 - pred2_mean_pred: 0.1238 - val_loss: 0.0630 - val_pred1_loss: 0.0379 - val_pred2_loss: 0.0251 - val_pred1_acc: 0.9868 - val_pred1_mean_pred: 0.3792 - val_pred2_acc: 0.9922 - val_pred2_mean_pred: 0.2507\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06280\n",
      "Epoch 24/100\n",
      "14400/14400 [==============================] - 14s 939us/step - loss: 0.0367 - pred1_loss: 0.0258 - pred2_loss: 0.0109 - pred1_acc: 0.9905 - pred1_mean_pred: 0.2580 - pred2_acc: 0.9963 - pred2_mean_pred: 0.1087 - val_loss: 0.0626 - val_pred1_loss: 0.0378 - val_pred2_loss: 0.0248 - val_pred1_acc: 0.9875 - val_pred1_mean_pred: 0.3775 - val_pred2_acc: 0.9924 - val_pred2_mean_pred: 0.2484\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06280 to 0.06260, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 25/100\n",
      "14400/14400 [==============================] - 13s 884us/step - loss: 0.0356 - pred1_loss: 0.0250 - pred2_loss: 0.0107 - pred1_acc: 0.9908 - pred1_mean_pred: 0.2497 - pred2_acc: 0.9964 - pred2_mean_pred: 0.1065 - val_loss: 0.0625 - val_pred1_loss: 0.0381 - val_pred2_loss: 0.0244 - val_pred1_acc: 0.9862 - val_pred1_mean_pred: 0.3808 - val_pred2_acc: 0.9926 - val_pred2_mean_pred: 0.2439\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06260 to 0.06247, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 26/100\n",
      "14400/14400 [==============================] - 13s 871us/step - loss: 0.0342 - pred1_loss: 0.0239 - pred2_loss: 0.0103 - pred1_acc: 0.9913 - pred1_mean_pred: 0.2388 - pred2_acc: 0.9965 - pred2_mean_pred: 0.1033 - val_loss: 0.0640 - val_pred1_loss: 0.0387 - val_pred2_loss: 0.0253 - val_pred1_acc: 0.9870 - val_pred1_mean_pred: 0.3873 - val_pred2_acc: 0.9929 - val_pred2_mean_pred: 0.2531\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.06247\n",
      "Epoch 27/100\n",
      "14400/14400 [==============================] - 13s 878us/step - loss: 0.0333 - pred1_loss: 0.0235 - pred2_loss: 0.0098 - pred1_acc: 0.9914 - pred1_mean_pred: 0.2354 - pred2_acc: 0.9966 - pred2_mean_pred: 0.0977 - val_loss: 0.0597 - val_pred1_loss: 0.0360 - val_pred2_loss: 0.0238 - val_pred1_acc: 0.9879 - val_pred1_mean_pred: 0.3598 - val_pred2_acc: 0.9935 - val_pred2_mean_pred: 0.2376\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06247 to 0.05974, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 28/100\n",
      "14400/14400 [==============================] - 12s 865us/step - loss: 0.0313 - pred1_loss: 0.0225 - pred2_loss: 0.0088 - pred1_acc: 0.9918 - pred1_mean_pred: 0.2245 - pred2_acc: 0.9970 - pred2_mean_pred: 0.0880 - val_loss: 0.0603 - val_pred1_loss: 0.0362 - val_pred2_loss: 0.0241 - val_pred1_acc: 0.9878 - val_pred1_mean_pred: 0.3619 - val_pred2_acc: 0.9927 - val_pred2_mean_pred: 0.2414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05974\n",
      "Epoch 29/100\n",
      "14400/14400 [==============================] - 13s 873us/step - loss: 0.0303 - pred1_loss: 0.0215 - pred2_loss: 0.0088 - pred1_acc: 0.9922 - pred1_mean_pred: 0.2150 - pred2_acc: 0.9970 - pred2_mean_pred: 0.0883 - val_loss: 0.0599 - val_pred1_loss: 0.0368 - val_pred2_loss: 0.0231 - val_pred1_acc: 0.9883 - val_pred1_mean_pred: 0.3681 - val_pred2_acc: 0.9931 - val_pred2_mean_pred: 0.2313\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05974\n",
      "Fold 2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 14400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "14400/14400 [==============================] - 16s 1ms/step - loss: 0.6370 - pred1_loss: 0.3575 - pred2_loss: 0.2796 - pred1_acc: 0.8625 - pred1_mean_pred: 3.5747 - pred2_acc: 0.9156 - pred2_mean_pred: 2.7956 - val_loss: 0.2911 - val_pred1_loss: 0.1773 - val_pred2_loss: 0.1138 - val_pred1_acc: 0.9444 - val_pred1_mean_pred: 1.7732 - val_pred2_acc: 0.9691 - val_pred2_mean_pred: 1.1377\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29110, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 2/100\n",
      "14400/14400 [==============================] - 13s 869us/step - loss: 0.2537 - pred1_loss: 0.1568 - pred2_loss: 0.0969 - pred1_acc: 0.9478 - pred1_mean_pred: 1.5683 - pred2_acc: 0.9734 - pred2_mean_pred: 0.9691 - val_loss: 0.2259 - val_pred1_loss: 0.1431 - val_pred2_loss: 0.0828 - val_pred1_acc: 0.9526 - val_pred1_mean_pred: 1.4308 - val_pred2_acc: 0.9763 - val_pred2_mean_pred: 0.8280\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29110 to 0.22587, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 3/100\n",
      "14400/14400 [==============================] - 13s 871us/step - loss: 0.1943 - pred1_loss: 0.1245 - pred2_loss: 0.0698 - pred1_acc: 0.9536 - pred1_mean_pred: 1.2453 - pred2_acc: 0.9782 - pred2_mean_pred: 0.6979 - val_loss: 0.1833 - val_pred1_loss: 0.1197 - val_pred2_loss: 0.0637 - val_pred1_acc: 0.9556 - val_pred1_mean_pred: 1.1965 - val_pred2_acc: 0.9822 - val_pred2_mean_pred: 0.6366\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22587 to 0.18331, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 4/100\n",
      "14400/14400 [==============================] - 13s 878us/step - loss: 0.1663 - pred1_loss: 0.1093 - pred2_loss: 0.0570 - pred1_acc: 0.9572 - pred1_mean_pred: 1.0928 - pred2_acc: 0.9820 - pred2_mean_pred: 0.5698 - val_loss: 0.1486 - val_pred1_loss: 0.1010 - val_pred2_loss: 0.0476 - val_pred1_acc: 0.9579 - val_pred1_mean_pred: 1.0101 - val_pred2_acc: 0.9853 - val_pred2_mean_pred: 0.4763\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18331 to 0.14863, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 5/100\n",
      "14400/14400 [==============================] - 13s 885us/step - loss: 0.1467 - pred1_loss: 0.0980 - pred2_loss: 0.0487 - pred1_acc: 0.9596 - pred1_mean_pred: 0.9805 - pred2_acc: 0.9843 - pred2_mean_pred: 0.4869 - val_loss: 0.1381 - val_pred1_loss: 0.0941 - val_pred2_loss: 0.0440 - val_pred1_acc: 0.9594 - val_pred1_mean_pred: 0.9414 - val_pred2_acc: 0.9863 - val_pred2_mean_pred: 0.4398\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14863 to 0.13812, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 6/100\n",
      "14400/14400 [==============================] - 13s 882us/step - loss: 0.1342 - pred1_loss: 0.0911 - pred2_loss: 0.0431 - pred1_acc: 0.9611 - pred1_mean_pred: 0.9108 - pred2_acc: 0.9859 - pred2_mean_pred: 0.4315 - val_loss: 0.1278 - val_pred1_loss: 0.0864 - val_pred2_loss: 0.0415 - val_pred1_acc: 0.9622 - val_pred1_mean_pred: 0.8635 - val_pred2_acc: 0.9867 - val_pred2_mean_pred: 0.4147\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13812 to 0.12782, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 7/100\n",
      "14400/14400 [==============================] - 13s 876us/step - loss: 0.1235 - pred1_loss: 0.0849 - pred2_loss: 0.0386 - pred1_acc: 0.9638 - pred1_mean_pred: 0.8487 - pred2_acc: 0.9875 - pred2_mean_pred: 0.3861 - val_loss: 0.1174 - val_pred1_loss: 0.0797 - val_pred2_loss: 0.0377 - val_pred1_acc: 0.9660 - val_pred1_mean_pred: 0.7968 - val_pred2_acc: 0.9881 - val_pred2_mean_pred: 0.3770\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12782 to 0.11739, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 8/100\n",
      "14400/14400 [==============================] - 12s 865us/step - loss: 0.1113 - pred1_loss: 0.0753 - pred2_loss: 0.0360 - pred1_acc: 0.9701 - pred1_mean_pred: 0.7529 - pred2_acc: 0.9880 - pred2_mean_pred: 0.3603 - val_loss: 0.1074 - val_pred1_loss: 0.0682 - val_pred2_loss: 0.0391 - val_pred1_acc: 0.9758 - val_pred1_mean_pred: 0.6824 - val_pred2_acc: 0.9866 - val_pred2_mean_pred: 0.3912\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11739 to 0.10736, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 9/100\n",
      "14400/14400 [==============================] - 13s 874us/step - loss: 0.0971 - pred1_loss: 0.0632 - pred2_loss: 0.0339 - pred1_acc: 0.9771 - pred1_mean_pred: 0.6321 - pred2_acc: 0.9886 - pred2_mean_pred: 0.3391 - val_loss: 0.0926 - val_pred1_loss: 0.0578 - val_pred2_loss: 0.0347 - val_pred1_acc: 0.9799 - val_pred1_mean_pred: 0.5784 - val_pred2_acc: 0.9881 - val_pred2_mean_pred: 0.3474\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10736 to 0.09258, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 10/100\n",
      "14400/14400 [==============================] - 13s 876us/step - loss: 0.0881 - pred1_loss: 0.0571 - pred2_loss: 0.0309 - pred1_acc: 0.9795 - pred1_mean_pred: 0.5711 - pred2_acc: 0.9895 - pred2_mean_pred: 0.3095 - val_loss: 0.0933 - val_pred1_loss: 0.0544 - val_pred2_loss: 0.0389 - val_pred1_acc: 0.9817 - val_pred1_mean_pred: 0.5445 - val_pred2_acc: 0.9867 - val_pred2_mean_pred: 0.3886\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09258\n",
      "Epoch 11/100\n",
      "14400/14400 [==============================] - 13s 870us/step - loss: 0.0807 - pred1_loss: 0.0528 - pred2_loss: 0.0280 - pred1_acc: 0.9813 - pred1_mean_pred: 0.5277 - pred2_acc: 0.9906 - pred2_mean_pred: 0.2797 - val_loss: 0.0820 - val_pred1_loss: 0.0506 - val_pred2_loss: 0.0315 - val_pred1_acc: 0.9827 - val_pred1_mean_pred: 0.5056 - val_pred2_acc: 0.9896 - val_pred2_mean_pred: 0.3146\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09258 to 0.08202, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 12/100\n",
      "14400/14400 [==============================] - 12s 867us/step - loss: 0.0734 - pred1_loss: 0.0481 - pred2_loss: 0.0253 - pred1_acc: 0.9831 - pred1_mean_pred: 0.4806 - pred2_acc: 0.9915 - pred2_mean_pred: 0.2535 - val_loss: 0.0877 - val_pred1_loss: 0.0516 - val_pred2_loss: 0.0361 - val_pred1_acc: 0.9817 - val_pred1_mean_pred: 0.5158 - val_pred2_acc: 0.9886 - val_pred2_mean_pred: 0.3612\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.08202\n",
      "Epoch 13/100\n",
      "14400/14400 [==============================] - 13s 875us/step - loss: 0.0671 - pred1_loss: 0.0439 - pred2_loss: 0.0233 - pred1_acc: 0.9843 - pred1_mean_pred: 0.4386 - pred2_acc: 0.9923 - pred2_mean_pred: 0.2328 - val_loss: 0.0809 - val_pred1_loss: 0.0484 - val_pred2_loss: 0.0325 - val_pred1_acc: 0.9834 - val_pred1_mean_pred: 0.4839 - val_pred2_acc: 0.9894 - val_pred2_mean_pred: 0.3249\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08202 to 0.08089, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 14/100\n",
      "14400/14400 [==============================] - 13s 900us/step - loss: 0.0643 - pred1_loss: 0.0422 - pred2_loss: 0.0221 - pred1_acc: 0.9852 - pred1_mean_pred: 0.4222 - pred2_acc: 0.9927 - pred2_mean_pred: 0.2207 - val_loss: 0.0740 - val_pred1_loss: 0.0440 - val_pred2_loss: 0.0300 - val_pred1_acc: 0.9846 - val_pred1_mean_pred: 0.4404 - val_pred2_acc: 0.9902 - val_pred2_mean_pred: 0.3000\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08089 to 0.07404, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 15/100\n",
      "14400/14400 [==============================] - 13s 874us/step - loss: 0.0601 - pred1_loss: 0.0399 - pred2_loss: 0.0202 - pred1_acc: 0.9861 - pred1_mean_pred: 0.3986 - pred2_acc: 0.9932 - pred2_mean_pred: 0.2019 - val_loss: 0.0733 - val_pred1_loss: 0.0444 - val_pred2_loss: 0.0289 - val_pred1_acc: 0.9845 - val_pred1_mean_pred: 0.4440 - val_pred2_acc: 0.9912 - val_pred2_mean_pred: 0.2888\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07404 to 0.07328, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 16/100\n",
      "14400/14400 [==============================] - 13s 876us/step - loss: 0.0560 - pred1_loss: 0.0378 - pred2_loss: 0.0183 - pred1_acc: 0.9867 - pred1_mean_pred: 0.3776 - pred2_acc: 0.9938 - pred2_mean_pred: 0.1827 - val_loss: 0.0700 - val_pred1_loss: 0.0419 - val_pred2_loss: 0.0282 - val_pred1_acc: 0.9851 - val_pred1_mean_pred: 0.4187 - val_pred2_acc: 0.9916 - val_pred2_mean_pred: 0.2817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 0.07328 to 0.07004, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 17/100\n",
      "14400/14400 [==============================] - 12s 855us/step - loss: 0.0527 - pred1_loss: 0.0357 - pred2_loss: 0.0170 - pred1_acc: 0.9872 - pred1_mean_pred: 0.3567 - pred2_acc: 0.9942 - pred2_mean_pred: 0.1704 - val_loss: 0.0707 - val_pred1_loss: 0.0418 - val_pred2_loss: 0.0289 - val_pred1_acc: 0.9859 - val_pred1_mean_pred: 0.4179 - val_pred2_acc: 0.9913 - val_pred2_mean_pred: 0.2892\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07004\n",
      "Epoch 18/100\n",
      "14400/14400 [==============================] - 12s 864us/step - loss: 0.0499 - pred1_loss: 0.0336 - pred2_loss: 0.0163 - pred1_acc: 0.9881 - pred1_mean_pred: 0.3355 - pred2_acc: 0.9944 - pred2_mean_pred: 0.1634 - val_loss: 0.0708 - val_pred1_loss: 0.0409 - val_pred2_loss: 0.0299 - val_pred1_acc: 0.9860 - val_pred1_mean_pred: 0.4089 - val_pred2_acc: 0.9906 - val_pred2_mean_pred: 0.2994\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07004\n",
      "Fold 3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 14400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "14400/14400 [==============================] - 17s 1ms/step - loss: 0.7076 - pred1_loss: 0.3761 - pred2_loss: 0.3315 - pred1_acc: 0.8546 - pred1_mean_pred: 3.7606 - pred2_acc: 0.8868 - pred2_mean_pred: 3.3153 - val_loss: 0.2958 - val_pred1_loss: 0.1775 - val_pred2_loss: 0.1182 - val_pred1_acc: 0.9429 - val_pred1_mean_pred: 1.7750 - val_pred2_acc: 0.9725 - val_pred2_mean_pred: 1.1825\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29575, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 2/100\n",
      "14400/14400 [==============================] - 13s 875us/step - loss: 0.2680 - pred1_loss: 0.1638 - pred2_loss: 0.1042 - pred1_acc: 0.9473 - pred1_mean_pred: 1.6383 - pred2_acc: 0.9735 - pred2_mean_pred: 1.0417 - val_loss: 0.2223 - val_pred1_loss: 0.1391 - val_pred2_loss: 0.0832 - val_pred1_acc: 0.9515 - val_pred1_mean_pred: 1.3910 - val_pred2_acc: 0.9776 - val_pred2_mean_pred: 0.8318\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29575 to 0.22228, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 3/100\n",
      "14400/14400 [==============================] - 13s 873us/step - loss: 0.2013 - pred1_loss: 0.1291 - pred2_loss: 0.0723 - pred1_acc: 0.9532 - pred1_mean_pred: 1.2908 - pred2_acc: 0.9790 - pred2_mean_pred: 0.7227 - val_loss: 0.1772 - val_pred1_loss: 0.1190 - val_pred2_loss: 0.0582 - val_pred1_acc: 0.9553 - val_pred1_mean_pred: 1.1899 - val_pred2_acc: 0.9828 - val_pred2_mean_pred: 0.5820\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22228 to 0.17719, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 4/100\n",
      "14400/14400 [==============================] - 18s 1ms/step - loss: 0.1703 - pred1_loss: 0.1114 - pred2_loss: 0.0589 - pred1_acc: 0.9565 - pred1_mean_pred: 1.1142 - pred2_acc: 0.9819 - pred2_mean_pred: 0.5889 - val_loss: 0.1465 - val_pred1_loss: 0.0997 - val_pred2_loss: 0.0468 - val_pred1_acc: 0.9589 - val_pred1_mean_pred: 0.9966 - val_pred2_acc: 0.9854 - val_pred2_mean_pred: 0.4684\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17719 to 0.14649, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 5/100\n",
      "14400/14400 [==============================] - 22s 2ms/step - loss: 0.1499 - pred1_loss: 0.0999 - pred2_loss: 0.0500 - pred1_acc: 0.9591 - pred1_mean_pred: 0.9993 - pred2_acc: 0.9844 - pred2_mean_pred: 0.5001 - val_loss: 0.1333 - val_pred1_loss: 0.0913 - val_pred2_loss: 0.0421 - val_pred1_acc: 0.9608 - val_pred1_mean_pred: 0.9125 - val_pred2_acc: 0.9862 - val_pred2_mean_pred: 0.4208\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14649 to 0.13333, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 6/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.1347 - pred1_loss: 0.0909 - pred2_loss: 0.0438 - pred1_acc: 0.9618 - pred1_mean_pred: 0.9089 - pred2_acc: 0.9860 - pred2_mean_pred: 0.4383 - val_loss: 0.1276 - val_pred1_loss: 0.0854 - val_pred2_loss: 0.0421 - val_pred1_acc: 0.9662 - val_pred1_mean_pred: 0.8543 - val_pred2_acc: 0.9861 - val_pred2_mean_pred: 0.4214\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13333 to 0.12757, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 7/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.1195 - pred1_loss: 0.0792 - pred2_loss: 0.0403 - pred1_acc: 0.9692 - pred1_mean_pred: 0.7922 - pred2_acc: 0.9869 - pred2_mean_pred: 0.4026 - val_loss: 0.1072 - val_pred1_loss: 0.0701 - val_pred2_loss: 0.0370 - val_pred1_acc: 0.9756 - val_pred1_mean_pred: 0.7013 - val_pred2_acc: 0.9873 - val_pred2_mean_pred: 0.3703\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12757 to 0.10716, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 8/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.1033 - pred1_loss: 0.0669 - pred2_loss: 0.0364 - pred1_acc: 0.9759 - pred1_mean_pred: 0.6687 - pred2_acc: 0.9881 - pred2_mean_pred: 0.3639 - val_loss: 0.0934 - val_pred1_loss: 0.0594 - val_pred2_loss: 0.0340 - val_pred1_acc: 0.9796 - val_pred1_mean_pred: 0.5937 - val_pred2_acc: 0.9888 - val_pred2_mean_pred: 0.3398\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10716 to 0.09336, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 9/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.0938 - pred1_loss: 0.0603 - pred2_loss: 0.0334 - pred1_acc: 0.9788 - pred1_mean_pred: 0.6032 - pred2_acc: 0.9890 - pred2_mean_pred: 0.3343 - val_loss: 0.0879 - val_pred1_loss: 0.0536 - val_pred2_loss: 0.0343 - val_pred1_acc: 0.9815 - val_pred1_mean_pred: 0.5361 - val_pred2_acc: 0.9887 - val_pred2_mean_pred: 0.3430\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09336 to 0.08790, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 10/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.0857 - pred1_loss: 0.0545 - pred2_loss: 0.0312 - pred1_acc: 0.9808 - pred1_mean_pred: 0.5451 - pred2_acc: 0.9898 - pred2_mean_pred: 0.3120 - val_loss: 0.0971 - val_pred1_loss: 0.0588 - val_pred2_loss: 0.0382 - val_pred1_acc: 0.9800 - val_pred1_mean_pred: 0.5884 - val_pred2_acc: 0.9867 - val_pred2_mean_pred: 0.3823\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08790\n",
      "Epoch 11/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.0782 - pred1_loss: 0.0502 - pred2_loss: 0.0280 - pred1_acc: 0.9824 - pred1_mean_pred: 0.5023 - pred2_acc: 0.9906 - pred2_mean_pred: 0.2799 - val_loss: 0.0769 - val_pred1_loss: 0.0472 - val_pred2_loss: 0.0297 - val_pred1_acc: 0.9834 - val_pred1_mean_pred: 0.4715 - val_pred2_acc: 0.9906 - val_pred2_mean_pred: 0.2970\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08790 to 0.07685, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 12/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.0732 - pred1_loss: 0.0473 - pred2_loss: 0.0259 - pred1_acc: 0.9832 - pred1_mean_pred: 0.4726 - pred2_acc: 0.9912 - pred2_mean_pred: 0.2592 - val_loss: 0.0763 - val_pred1_loss: 0.0472 - val_pred2_loss: 0.0291 - val_pred1_acc: 0.9837 - val_pred1_mean_pred: 0.4716 - val_pred2_acc: 0.9902 - val_pred2_mean_pred: 0.2911\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07685 to 0.07628, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 13/100\n",
      "14400/14400 [==============================] - 21s 1ms/step - loss: 0.0680 - pred1_loss: 0.0437 - pred2_loss: 0.0243 - pred1_acc: 0.9847 - pred1_mean_pred: 0.4375 - pred2_acc: 0.9919 - pred2_mean_pred: 0.2430 - val_loss: 0.0739 - val_pred1_loss: 0.0454 - val_pred2_loss: 0.0285 - val_pred1_acc: 0.9841 - val_pred1_mean_pred: 0.4542 - val_pred2_acc: 0.9905 - val_pred2_mean_pred: 0.2850\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07628 to 0.07392, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 14/100\n",
      "14400/14400 [==============================] - 15s 1ms/step - loss: 0.0641 - pred1_loss: 0.0416 - pred2_loss: 0.0224 - pred1_acc: 0.9852 - pred1_mean_pred: 0.4163 - pred2_acc: 0.9924 - pred2_mean_pred: 0.2244 - val_loss: 0.0709 - val_pred1_loss: 0.0420 - val_pred2_loss: 0.0290 - val_pred1_acc: 0.9850 - val_pred1_mean_pred: 0.4196 - val_pred2_acc: 0.9907 - val_pred2_mean_pred: 0.2898\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07392 to 0.07095, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 15/100\n",
      "14400/14400 [==============================] - 10s 700us/step - loss: 0.0598 - pred1_loss: 0.0392 - pred2_loss: 0.0206 - pred1_acc: 0.9861 - pred1_mean_pred: 0.3917 - pred2_acc: 0.9929 - pred2_mean_pred: 0.2062 - val_loss: 0.0653 - val_pred1_loss: 0.0393 - val_pred2_loss: 0.0260 - val_pred1_acc: 0.9856 - val_pred1_mean_pred: 0.3926 - val_pred2_acc: 0.9908 - val_pred2_mean_pred: 0.2601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss improved from 0.07095 to 0.06527, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 16/100\n",
      "14400/14400 [==============================] - 10s 704us/step - loss: 0.0565 - pred1_loss: 0.0369 - pred2_loss: 0.0196 - pred1_acc: 0.9869 - pred1_mean_pred: 0.3690 - pred2_acc: 0.9934 - pred2_mean_pred: 0.1963 - val_loss: 0.0659 - val_pred1_loss: 0.0398 - val_pred2_loss: 0.0261 - val_pred1_acc: 0.9863 - val_pred1_mean_pred: 0.3983 - val_pred2_acc: 0.9907 - val_pred2_mean_pred: 0.2609\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06527\n",
      "Epoch 17/100\n",
      "14400/14400 [==============================] - 10s 710us/step - loss: 0.0535 - pred1_loss: 0.0353 - pred2_loss: 0.0182 - pred1_acc: 0.9874 - pred1_mean_pred: 0.3528 - pred2_acc: 0.9938 - pred2_mean_pred: 0.1825 - val_loss: 0.0654 - val_pred1_loss: 0.0382 - val_pred2_loss: 0.0272 - val_pred1_acc: 0.9862 - val_pred1_mean_pred: 0.3817 - val_pred2_acc: 0.9914 - val_pred2_mean_pred: 0.2721\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06527\n",
      "Fold 4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 14400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "14400/14400 [==============================] - 15s 1ms/step - loss: 0.6143 - pred1_loss: 0.3524 - pred2_loss: 0.2619 - pred1_acc: 0.8722 - pred1_mean_pred: 3.5241 - pred2_acc: 0.9260 - pred2_mean_pred: 2.6188 - val_loss: 0.2805 - val_pred1_loss: 0.1752 - val_pred2_loss: 0.1054 - val_pred1_acc: 0.9474 - val_pred1_mean_pred: 1.7516 - val_pred2_acc: 0.9713 - val_pred2_mean_pred: 1.0537\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28053, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 2/100\n",
      "14400/14400 [==============================] - 10s 703us/step - loss: 0.2535 - pred1_loss: 0.1603 - pred2_loss: 0.0932 - pred1_acc: 0.9482 - pred1_mean_pred: 1.6029 - pred2_acc: 0.9741 - pred2_mean_pred: 0.9317 - val_loss: 0.2180 - val_pred1_loss: 0.1379 - val_pred2_loss: 0.0801 - val_pred1_acc: 0.9520 - val_pred1_mean_pred: 1.3790 - val_pred2_acc: 0.9763 - val_pred2_mean_pred: 0.8011\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28053 to 0.21800, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 3/100\n",
      "14400/14400 [==============================] - 12s 826us/step - loss: 0.1983 - pred1_loss: 0.1285 - pred2_loss: 0.0698 - pred1_acc: 0.9531 - pred1_mean_pred: 1.2846 - pred2_acc: 0.9785 - pred2_mean_pred: 0.6984 - val_loss: 0.1755 - val_pred1_loss: 0.1132 - val_pred2_loss: 0.0623 - val_pred1_acc: 0.9564 - val_pred1_mean_pred: 1.1318 - val_pred2_acc: 0.9811 - val_pred2_mean_pred: 0.6232\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21800 to 0.17550, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 4/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.1690 - pred1_loss: 0.1114 - pred2_loss: 0.0576 - pred1_acc: 0.9569 - pred1_mean_pred: 1.1141 - pred2_acc: 0.9815 - pred2_mean_pred: 0.5755 - val_loss: 0.1622 - val_pred1_loss: 0.1036 - val_pred2_loss: 0.0586 - val_pred1_acc: 0.9586 - val_pred1_mean_pred: 1.0359 - val_pred2_acc: 0.9824 - val_pred2_mean_pred: 0.5864\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17550 to 0.16223, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 5/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.1495 - pred1_loss: 0.1005 - pred2_loss: 0.0489 - pred1_acc: 0.9592 - pred1_mean_pred: 1.0054 - pred2_acc: 0.9842 - pred2_mean_pred: 0.4894 - val_loss: 0.1559 - val_pred1_loss: 0.0952 - val_pred2_loss: 0.0608 - val_pred1_acc: 0.9607 - val_pred1_mean_pred: 0.9518 - val_pred2_acc: 0.9785 - val_pred2_mean_pred: 0.6075\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16223 to 0.15594, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 6/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.1352 - pred1_loss: 0.0919 - pred2_loss: 0.0434 - pred1_acc: 0.9618 - pred1_mean_pred: 0.9187 - pred2_acc: 0.9858 - pred2_mean_pred: 0.4337 - val_loss: 0.1342 - val_pred1_loss: 0.0872 - val_pred2_loss: 0.0469 - val_pred1_acc: 0.9650 - val_pred1_mean_pred: 0.8721 - val_pred2_acc: 0.9849 - val_pred2_mean_pred: 0.4695\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15594 to 0.13415, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 7/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.1227 - pred1_loss: 0.0836 - pred2_loss: 0.0391 - pred1_acc: 0.9661 - pred1_mean_pred: 0.8361 - pred2_acc: 0.9870 - pred2_mean_pred: 0.3906 - val_loss: 0.1187 - val_pred1_loss: 0.0769 - val_pred2_loss: 0.0418 - val_pred1_acc: 0.9728 - val_pred1_mean_pred: 0.7691 - val_pred2_acc: 0.9855 - val_pred2_mean_pred: 0.4183\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.13415 to 0.11874, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 8/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.1092 - pred1_loss: 0.0725 - pred2_loss: 0.0367 - pred1_acc: 0.9728 - pred1_mean_pred: 0.7247 - pred2_acc: 0.9876 - pred2_mean_pred: 0.3672 - val_loss: 0.1031 - val_pred1_loss: 0.0654 - val_pred2_loss: 0.0378 - val_pred1_acc: 0.9790 - val_pred1_mean_pred: 0.6536 - val_pred2_acc: 0.9881 - val_pred2_mean_pred: 0.3777\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11874 to 0.10312, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 9/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0969 - pred1_loss: 0.0632 - pred2_loss: 0.0338 - pred1_acc: 0.9774 - pred1_mean_pred: 0.6317 - pred2_acc: 0.9890 - pred2_mean_pred: 0.3377 - val_loss: 0.1001 - val_pred1_loss: 0.0625 - val_pred2_loss: 0.0376 - val_pred1_acc: 0.9784 - val_pred1_mean_pred: 0.6254 - val_pred2_acc: 0.9872 - val_pred2_mean_pred: 0.3755\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10312 to 0.10009, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 10/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0884 - pred1_loss: 0.0573 - pred2_loss: 0.0311 - pred1_acc: 0.9796 - pred1_mean_pred: 0.5725 - pred2_acc: 0.9894 - pred2_mean_pred: 0.3114 - val_loss: 0.0857 - val_pred1_loss: 0.0534 - val_pred2_loss: 0.0323 - val_pred1_acc: 0.9816 - val_pred1_mean_pred: 0.5340 - val_pred2_acc: 0.9891 - val_pred2_mean_pred: 0.3228\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.10009 to 0.08568, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 11/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0817 - pred1_loss: 0.0528 - pred2_loss: 0.0288 - pred1_acc: 0.9813 - pred1_mean_pred: 0.5284 - pred2_acc: 0.9903 - pred2_mean_pred: 0.2883 - val_loss: 0.0894 - val_pred1_loss: 0.0539 - val_pred2_loss: 0.0356 - val_pred1_acc: 0.9813 - val_pred1_mean_pred: 0.5385 - val_pred2_acc: 0.9883 - val_pred2_mean_pred: 0.3557\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.08568\n",
      "Epoch 12/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0749 - pred1_loss: 0.0487 - pred2_loss: 0.0262 - pred1_acc: 0.9825 - pred1_mean_pred: 0.4873 - pred2_acc: 0.9914 - pred2_mean_pred: 0.2617 - val_loss: 0.0809 - val_pred1_loss: 0.0463 - val_pred2_loss: 0.0346 - val_pred1_acc: 0.9845 - val_pred1_mean_pred: 0.4629 - val_pred2_acc: 0.9884 - val_pred2_mean_pred: 0.3456\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08568 to 0.08085, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 13/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0700 - pred1_loss: 0.0453 - pred2_loss: 0.0247 - pred1_acc: 0.9840 - pred1_mean_pred: 0.4527 - pred2_acc: 0.9916 - pred2_mean_pred: 0.2468 - val_loss: 0.0751 - val_pred1_loss: 0.0465 - val_pred2_loss: 0.0286 - val_pred1_acc: 0.9837 - val_pred1_mean_pred: 0.4652 - val_pred2_acc: 0.9903 - val_pred2_mean_pred: 0.2861\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08085 to 0.07513, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 14/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0646 - pred1_loss: 0.0422 - pred2_loss: 0.0223 - pred1_acc: 0.9852 - pred1_mean_pred: 0.4221 - pred2_acc: 0.9923 - pred2_mean_pred: 0.2234 - val_loss: 0.0723 - val_pred1_loss: 0.0444 - val_pred2_loss: 0.0279 - val_pred1_acc: 0.9852 - val_pred1_mean_pred: 0.4436 - val_pred2_acc: 0.9907 - val_pred2_mean_pred: 0.2792\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07513 to 0.07228, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 15/100\n",
      "14400/14400 [==============================] - 19s 1ms/step - loss: 0.0615 - pred1_loss: 0.0406 - pred2_loss: 0.0209 - pred1_acc: 0.9856 - pred1_mean_pred: 0.4063 - pred2_acc: 0.9931 - pred2_mean_pred: 0.2087 - val_loss: 0.0676 - val_pred1_loss: 0.0417 - val_pred2_loss: 0.0259 - val_pred1_acc: 0.9858 - val_pred1_mean_pred: 0.4173 - val_pred2_acc: 0.9912 - val_pred2_mean_pred: 0.2586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss improved from 0.07228 to 0.06759, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 16/100\n",
      "14400/14400 [==============================] - 18s 1ms/step - loss: 0.0585 - pred1_loss: 0.0387 - pred2_loss: 0.0198 - pred1_acc: 0.9864 - pred1_mean_pred: 0.3867 - pred2_acc: 0.9934 - pred2_mean_pred: 0.1981 - val_loss: 0.0703 - val_pred1_loss: 0.0446 - val_pred2_loss: 0.0257 - val_pred1_acc: 0.9847 - val_pred1_mean_pred: 0.4460 - val_pred2_acc: 0.9913 - val_pred2_mean_pred: 0.2571\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.06759\n",
      "Epoch 17/100\n",
      "14400/14400 [==============================] - 13s 870us/step - loss: 0.0544 - pred1_loss: 0.0363 - pred2_loss: 0.0181 - pred1_acc: 0.9871 - pred1_mean_pred: 0.3629 - pred2_acc: 0.9938 - pred2_mean_pred: 0.1811 - val_loss: 0.0676 - val_pred1_loss: 0.0416 - val_pred2_loss: 0.0260 - val_pred1_acc: 0.9860 - val_pred1_mean_pred: 0.4164 - val_pred2_acc: 0.9913 - val_pred2_mean_pred: 0.2601\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06759\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=100\n",
    "weight_name='V2'\n",
    "oof=np.zeros((len(train),29))\n",
    "tmp=0\n",
    "test_oof=[]#np.zeros((len(test),29))\n",
    "# for ii in range(17):\n",
    "#     per_labels=train_labels[:,ii]\n",
    "#     print('当前分类类别：'+str(ii))\n",
    "#     print('正样本比例:'+str(sum(per_labels)/len(per_labels)))\n",
    "# per_labels=train_labels[:,1]\n",
    "folds=StratifiedKFold(n_splits=5,shuffle=True, random_state=2018) #2018\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(folds.split(train,cate_num)):\n",
    "    print('Fold', fold_n)\n",
    "    print('Build model...')\n",
    "#     print('正样本比例:',train_labels[trn_idx].mean(0))\n",
    "    model=NN_huaweiv1(maxlen=128,embedding_matrix=embedding_matrix)\n",
    "#     model=multi_gpu_model(model,gpus=2)\n",
    "    model.compile('adam', ['binary_crossentropy','binary_crossentropy'], metrics=['accuracy',mean_pred])\n",
    "\n",
    "    print('Train...')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2,mode='min')\n",
    "    check_point=ModelCheckpoint('../model_weight/%s_%d.h5'%(weight_name,fold_n),monitor='val_loss',verbose=1, save_best_only=True,save_weights_only=True)\n",
    "\n",
    "    model.fit(train_seq[trn_idx],{'pred1':train_labels1[trn_idx],'pred2':train_labels2[trn_idx]},\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks=[early_stopping,check_point],\n",
    "              validation_data=(train_seq[val_idx],{'pred1':train_labels1[val_idx],'pred2':train_labels2[val_idx]}))\n",
    "    model.load_weights('../model_weight/%s_%d.h5'%(weight_name,fold_n))\n",
    "    oof[val_idx,:17],oof[val_idx,17:] = model.predict(train_seq[val_idx],batch_size=batch_size)\n",
    "    tmp_test_pred1,tmp_test_pred2=model.predict(test_seq,batch_size=batch_size)\n",
    "#     test_oof[:,:17]+=tmp_test_pred1/folds.n_splits\n",
    "#     test_oof[:,17:]+=tmp_test_pred2/folds.n_splits\n",
    "    test_oof.append(np.concatenate([tmp_test_pred1,tmp_test_pred2],axis=-1))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "personalized-circuit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:52:22.683388Z",
     "start_time": "2021-04-26T05:52:22.677088Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_pred(y_true, y_pred):\n",
    "    return 1-(-np.mean(y_true*np.log(y_pred+1.e-7)+(1-y_true)*np.log(1-y_pred+1.e-7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bibliographic-leonard",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:37:20.378272Z",
     "start_time": "2021-04-26T06:37:20.363360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8832540065050125\n",
      "1 0.8601763397455215\n",
      "2 0.8991888388991356\n",
      "3 0.8945850506424904\n",
      "4 0.9012257903814316\n",
      "0.9479899182915688\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_oof)):\n",
    "    print(i,mean_pred(test_labels,test_oof[i]))\n",
    "print(mean_pred(test_labels,np.mean(test_oof,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cubic-architect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:07:50.730140Z",
     "start_time": "2021-04-26T06:07:50.722288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(t_test_oof[:,j,i]>c_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "substantial-protest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:33:09.007307Z",
     "start_time": "2021-04-26T06:33:08.999927Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_n=np.exp(t_test_oof)\n",
    "exp_sum=exp_n.sum(axis=0)\n",
    "exp_n=exp_n/exp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "delayed-principle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:34:47.985152Z",
     "start_time": "2021-04-26T06:34:47.980238Z"
    }
   },
   "outputs": [],
   "source": [
    "result=(exp_n*t_test_oof).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "short-glance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:37:30.061613Z",
     "start_time": "2021-04-26T06:37:30.050884Z"
    }
   },
   "outputs": [],
   "source": [
    "t_test_oof=np.concatenate(list(map(lambda x:np.expand_dims(x,0),test_oof)),axis=0)\n",
    "# for i in range(29): # 对每一折的每一类纵向矫正\n",
    "#     for j in range(t_test_oof.shape[1]):\n",
    "#         c_max=t_test_oof[:,j,i].max()\n",
    "#         c_min=t_test_oof[:,j,i].min()\n",
    "#         c_q=(c_max+c_min)/1.1\n",
    "#         if sum(t_test_oof[:,j,i]>c_q)>t_test_oof.shape[0]/2:\n",
    "#             t_test_oof[:,j,i]=c_max\n",
    "#         else:\n",
    "#             t_test_oof[:,j,i]=c_min\n",
    "for i in range(t_test_oof.shape[0]):\n",
    "    t_test_oof[i]=t_test_oof[i]-t_test_oof[i].min(axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sudden-analyst",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T09:09:05.863876Z",
     "start_time": "2021-04-26T09:09:05.851488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=[ np.zeros((2000,29)) for  i in range(5)]\n",
    "np.mean(a,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "subjective-cameroon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T06:38:49.996571Z",
     "start_time": "2021-04-26T06:38:49.977810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8837199658155441\n",
      "1 0.8608790636062622\n",
      "2 0.899728499352932\n",
      "3 0.894889235496521\n",
      "4 0.9015856087207794\n",
      "x 0.9480565451085567\n",
      "y 0.9481441676616669\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(t_test_oof)):\n",
    "    print(i,mean_pred(test_labels,t_test_oof[i]))\n",
    "\n",
    "print('x',mean_pred(test_labels,np.mean(t_test_oof,axis=0)))\n",
    "c=np.mean(t_test_oof,axis=0)\n",
    "c=c-c.min(axis=1,keepdims=True)\n",
    "print('y',mean_pred(test_labels,c))\n",
    "# print('y',mean_pred(test_labels,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "increasing-murray",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:01:33.965806Z",
     "start_time": "2021-04-21T06:01:31.964131Z"
    }
   },
   "outputs": [],
   "source": [
    "oof[trn_idx,:17],oof[trn_idx,17:]=model.predict(train_seq[trn_idx],batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abroad-validation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:03:18.928640Z",
     "start_time": "2021-04-21T06:03:18.922860Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels=np.concatenate([train_labels1,train_labels2],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "comparable-stack",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:33:13.098062Z",
     "start_time": "2021-04-21T07:33:13.092215Z"
    }
   },
   "outputs": [],
   "source": [
    "def maths(a):\n",
    "    return a-a.min(axis=1,keepdims=True)\n",
    "# def maths(a):\n",
    "#     for i in range(len(a)):\n",
    "#         tmp=a[i]\n",
    "#         if (tmp.max()-tmp.min())>0.5:\n",
    "# #             print(tmp)\n",
    "#             tmp[np.abs(tmp-tmp.max())<0.01]=tmp.max()\n",
    "#         a[i]=tmp\n",
    "#     return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "religious-supplement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:33:15.726219Z",
     "start_time": "2021-04-21T07:33:15.625613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_train: 0.8898850812675206\n",
      "origin_val: 0.7140461160872693\n",
      "rain: 0.8899049061910052\n",
      "val: 0.7140052286553235\n"
     ]
    }
   ],
   "source": [
    "a=oof.copy()\n",
    "a=maths(a)\n",
    "print('origin_train:',1-mean_pred(train_labels[trn_idx],oof[trn_idx]))\n",
    "print('origin_val:',1-mean_pred(train_labels[val_idx],oof[val_idx]))\n",
    "\n",
    "print('rain:',1-mean_pred(train_labels[trn_idx],a[trn_idx]))\n",
    "print('val:',1-mean_pred(train_labels[val_idx],a[val_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "interstate-juvenile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:06:53.389167Z",
     "start_time": "2021-04-21T07:06:53.381938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27849999999999997"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "false-humanitarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T07:03:15.910141Z",
     "start_time": "2021-04-15T07:03:15.802681Z"
    }
   },
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['report_ID']=test[0]\n",
    "sub['Prediction']=[ '|'+' '.join(['%.12f'%j for j in i]) for i in test_oof ]\n",
    "sub.to_csv('../result.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-merchant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
