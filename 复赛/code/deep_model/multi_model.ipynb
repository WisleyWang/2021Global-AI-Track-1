{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "unable-israel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:15:10.900769Z",
     "start_time": "2021-04-21T09:15:10.888579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  tensorflow.compat.v1 import keras\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "from tensorflow.compat.v1.keras import Model\n",
    "from tensorflow.compat.v1.keras import initializers, regularizers, constraints\n",
    "from tensorflow.compat.v1.keras.layers import *\n",
    "from tensorflow.compat.v1.keras.layers import Embedding, Dense, CuDNNLSTM,CuDNNGRU, Bidirectional,SpatialDropout1D,Input,GlobalAveragePooling1D,GlobalMaxPooling1D,Conv1D,concatenate,Dropout,Activation,BatchNormalization,Concatenate,Add,MaxPooling1D,Flatten,AveragePooling1D\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.compat.v1.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.compat.v1.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.compat.v1.keras.preprocessing import text, sequence\n",
    "import gensim, logging\n",
    "from tensorflow.compat.v1.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.model_selection import KFold,StratifiedShuffleSplit,StratifiedKFold\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pregnant-ozone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:46.059202Z",
     "start_time": "2021-04-21T08:37:45.988717Z"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../tcdata/train.csv',header=None)\n",
    "test=pd.read_csv('../tcdata/track1_round1_testB.csv',header=None)\n",
    "# test=pd.read_csv('../tcdata/testA.csv',header=None)\n",
    "data=pd.concat([train,test],axis=0)\n",
    "data[1]=data[1].apply(lambda x:x.strip().replace('|',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noble-manhattan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:46.149600Z",
     "start_time": "2021-04-21T08:37:46.061268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncase label1: 0\n",
      "noncase label2: 8247\n"
     ]
    }
   ],
   "source": [
    "## 制作标签\n",
    "### 创建训练集标签 \n",
    "train_labels1=np.zeros((len(train),17),dtype='int8')\n",
    "noncase=0\n",
    "for cnt,i in enumerate(train[2]):\n",
    "    if i:\n",
    "        lab=[int(x.replace('|','').strip()) for x in i.split(' ') if x and x!='|']\n",
    "        for l in lab:\n",
    "            train_labels1[cnt,l]=1\n",
    "    else:\n",
    "        noncase+=1\n",
    "print('noncase label1:',noncase)\n",
    "#----------------------------------\n",
    "noncase=0\n",
    "train_labels2=np.zeros((len(train),12),dtype='int8')\n",
    "for cnt,i in enumerate(train[3]):\n",
    "    if pd.notna(i):\n",
    "        lab=[int(x.replace('|','').strip()) for x in i.split(' ') if x and x!='|']\n",
    "        for l in lab:\n",
    "            train_labels2[cnt,l]=1\n",
    "    else:\n",
    "        noncase+=1\n",
    "print('noncase label2:',noncase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specified-hebrew",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:46.218640Z",
     "start_time": "2021-04-21T08:37:46.152140Z"
    }
   },
   "outputs": [],
   "source": [
    "cate_num=train_labels1.sum(1)+train_labels2.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "english-burlington",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T06:02:19.297605Z",
     "start_time": "2021-04-15T06:02:19.227226Z"
    }
   },
   "outputs": [],
   "source": [
    "## 生成全部的训练文本\n",
    "data1=pd.read_csv('../tcdata/track1_round1_train_20210222.csv',header=None)\n",
    "data2=pd.read_csv('../tcdata/track1_round1_testA_20210222.csv',header=None)\n",
    "data3=pd.read_csv('../tcdata/track1_round1_testB.csv',header=None)\n",
    "text_data=pd.concat([train,data1,data2,data3],axis=0)\n",
    "text_data[1]=text_data[1].apply(lambda x:x.strip().replace('|',''))\n",
    "text_data[1].to_csv('../tmp/all_data.txt',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "overhead-plenty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T06:07:16.368462Z",
     "start_time": "2021-04-15T06:07:16.288461Z"
    }
   },
   "outputs": [],
   "source": [
    "text_data=pd.read_csv('../tmp/all_data.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certified-afternoon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T03:32:41.149995Z",
     "start_time": "2021-04-21T03:32:41.146574Z"
    }
   },
   "outputs": [],
   "source": [
    "# w2v=Word2Vec(text_data[0].apply(lambda x:x.split(' ')).tolist(),size=128, window=8, iter=30, min_count=2,\n",
    "#                      sg=1, sample=0.002, workers=6 , seed=1017)\n",
    "\n",
    "# w2v.wv.save_word2vec_format('../tmp/w2v_128.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dental-thing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:57.480121Z",
     "start_time": "2021-04-21T08:37:56.386749Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=False, char_level=False, split=' ')\n",
    "tokenizer.fit_on_texts(data[1].tolist())\n",
    "seq = tokenizer.texts_to_sequences(data[1].tolist())\n",
    "# 分训练和测试集合\n",
    "seq = pad_sequences(seq, maxlen=128, value=0)\n",
    "train_seq=np.asarray(seq[:len(train)])\n",
    "test_seq=seq[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "governmental-netscape",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:58.085125Z",
     "start_time": "2021-04-21T08:37:57.952192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-21 16:37:57,955 : INFO : loading projection weights from ../tmp/w2v_128.txt\n",
      "2021-04-21 16:37:58,068 : INFO : loaded (859, 128) matrix from ../tmp/w2v_128.txt\n",
      "<ipython-input-6-6203a5121046>:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if word not in w2v.wv.vocab:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(859, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix=np.zeros((len(tokenizer.word_index)+1,128))\n",
    "w2v=gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        '../tmp/w2v_128.txt', binary=False)\n",
    "\n",
    "for word in tokenizer.word_index:\n",
    "    if word not in w2v.wv.vocab:\n",
    "        continue\n",
    "    embedding_matrix[tokenizer.word_index[word]] = w2v[word]\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compact-bearing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:58.471375Z",
     "start_time": "2021-04-21T08:37:58.448544Z"
    }
   },
   "outputs": [],
   "source": [
    "def NN_huaweiv1(maxlen,embedding_matrix=None,class_num1=17,class_num2=12):    \n",
    "    emb_layer = Embedding(\n",
    "       embedding_matrix.shape[0], embedding_matrix.shape[1],input_length=maxlen,weights=[embedding_matrix],trainable=False,\n",
    "    )\n",
    "    seq1 = Input(shape=(maxlen,)) \n",
    "    \n",
    "    x1 = emb_layer(seq1)\n",
    "    sdrop=SpatialDropout1D(rate=0.2)\n",
    "    lstm_layer = Bidirectional(CuDNNGRU(128, return_sequences=True))\n",
    "    gru_layer = Bidirectional(CuDNNGRU(128, return_sequences=True))\n",
    "    cnn1d_layer=Conv1D(64, kernel_size=3, padding=\"same\", kernel_initializer=\"he_uniform\")\n",
    "    x1 = sdrop(x1)\n",
    "    lstm1 = lstm_layer(x1)\n",
    "    gru1 = gru_layer(lstm1)\n",
    "    att_1 = Attention(maxlen)(lstm1)\n",
    "    att_2 = Attention(maxlen)(gru1)\n",
    "    cnn1 = cnn1d_layer(lstm1)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()\n",
    "    max_pool = GlobalMaxPooling1D()\n",
    "\n",
    "    x1=concatenate([att_1,att_2,Attention(maxlen)(cnn1),avg_pool(cnn1),max_pool(cnn1)])\n",
    "\n",
    "    x = Dropout(0.2)(Activation(activation=\"relu\")(BatchNormalization()(Dense(128)(x1))))\n",
    "    x = Activation(activation=\"relu\")(BatchNormalization()(Dense(64)(x)))\n",
    "    pred1 = Dense(class_num1, activation='sigmoid',name='pred1')(x)\n",
    "    y=concatenate([x1,x])\n",
    "    y = Activation(activation=\"relu\")(BatchNormalization()(Dense(64)(x)))\n",
    "    pred2=Dense(class_num2, activation='sigmoid',name='pred2')(y)\n",
    "    \n",
    "    model = Model(inputs=seq1, outputs=[pred1,pred2])\n",
    "    return model\n",
    "\n",
    "class AttentionSelf(Layer):\n",
    "    \"\"\"\n",
    "        self attention,\n",
    "        codes from:  https://mp.weixin.qq.com/s/qmJnyFMkXVjYBwoR_AQLVA\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # W、K and V\n",
    "        self.kernel = self.add_weight(name='WKV',\n",
    "                                        shape=(3, input_shape[2], self.output_dim),\n",
    "                                        initializer='uniform',\n",
    "                                        regularizer=regularizers.L1L2(0.0000032),\n",
    "                                        trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        WQ = K.dot(x, self.kernel[0])\n",
    "        WK = K.dot(x, self.kernel[1])\n",
    "        WV = K.dot(x, self.kernel[2])\n",
    "        # print(\"WQ.shape\",WQ.shape)\n",
    "        # print(\"K.permute_dimensions(WK, [0, 2, 1]).shape\",K.permute_dimensions(WK, [0, 2, 1]).shape)\n",
    "        QK = K.batch_dot(WQ, K.permute_dimensions(WK, [0, 2, 1]))\n",
    "        QK = QK / (64**0.5)\n",
    "        QK = K.softmax(QK)\n",
    "        # print(\"QK.shape\",QK.shape)\n",
    "        V = K.batch_dot(QK, WV)\n",
    "        return V\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], self.output_dim)\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            # 1\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "            # 2\n",
    "            hidden = LSTM(64, return_sequences=True)(words)\n",
    "            sentence = Attention()(hidden)\n",
    "            # next add a Dense layer (for classification/regression) or whatever...\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "#         print('-------------',type(input_shape))\n",
    "        self.W = self.add_weight(name='{}_W'.format(self.name),\n",
    "                                 shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(name='{}_b'.format(self.name),\n",
    "                                     shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        e = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))  # e = K.dot(x, self.W)\n",
    "        if self.bias:\n",
    "            e += self.b\n",
    "        e = K.tanh(e)\n",
    "\n",
    "        a = K.exp(e)\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "\n",
    "        c = K.sum(a * x, axis=1)\n",
    "        return c\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return -K.mean(y_true*K.log(y_pred+1.e-7)+(1-y_true)*K.log(1-y_pred+1.e-7))*10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-client",
   "metadata": {},
   "source": [
    "## HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollow-likelihood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:37:59.153116Z",
     "start_time": "2021-04-21T08:37:59.144662Z"
    }
   },
   "outputs": [],
   "source": [
    "def HANGraph(maxlen,embedding_matrix,class_num1=17,class_num2=12):\n",
    "    \n",
    "    \"\"\"\n",
    "        构建神经网络\n",
    "    :param hyper_parameters:json,  hyper parameters of network\n",
    "    :return: tensor, moedl\n",
    "    \"\"\"\n",
    "\n",
    "    emb_layer = Embedding(\n",
    "    embedding_matrix.shape[0], embedding_matrix.shape[1],input_length=maxlen,weights=[embedding_matrix],trainable=False,\n",
    ")\n",
    "    seq1 = Input(shape=(maxlen,)) \n",
    "    x1 = emb_layer(seq1)\n",
    "    # char or word\n",
    "    x1=SpatialDropout1D(rate=0.2)(x1)\n",
    "    x_word = word_level(maxlen)(x1)\n",
    "    x_word_to_sen = Dropout(0.2)(x_word)\n",
    "\n",
    "    # sentence or doc\n",
    "    x_sen = sentence_level(maxlen)(x_word_to_sen)\n",
    "    x_sen = Dropout(0.2)(x_sen)\n",
    "\n",
    "    x_sen = Attention(128)(x_sen)\n",
    "    # 最后就是softmax\n",
    "    pred1 = Dense(class_num1, activation='sigmoid',name='pred1')(x_sen)\n",
    "    pred2=Dense(class_num2, activation='sigmoid',name='pred2')(x_sen)\n",
    "    output = [pred1,pred2]\n",
    "    model = Model(seq1, output)\n",
    "    return model\n",
    "\n",
    "def word_level(maxlen):\n",
    "    x_input_word = Input(shape=(maxlen,128))\n",
    "    # x = SpatialDropout1D(self.dropout_spatial)(x_input_word)\n",
    "    x = Bidirectional(CuDNNLSTM(units=128,\n",
    "                          return_sequences=True,\n",
    "                         ))(x_input_word)\n",
    "    out_sent = AttentionSelf(128*2)(x)\n",
    "    model = Model(x_input_word, out_sent)\n",
    "    return model\n",
    "\n",
    "def sentence_level(maxlen):\n",
    "    x_input_sen = Input(shape=(maxlen, 128*2))\n",
    "    # x = SpatialDropout1D(self.dropout_spatial)(x_input_sen)\n",
    "    output_doc = Bidirectional(CuDNNLSTM(units=128*2,\n",
    "                          return_sequences=True,\n",
    "                          ))(x_input_sen)\n",
    "    output_doc_att = AttentionSelf(128)(output_doc)\n",
    "    model = Model(x_input_sen, output_doc_att)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-warrant",
   "metadata": {},
   "source": [
    "##  textVDCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intimate-renaissance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:02:15.786581Z",
     "start_time": "2021-04-21T09:02:15.781963Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "micro-haven",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:26:36.840521Z",
     "start_time": "2021-04-21T09:26:36.806065Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class VDCNNGraph():\n",
    "    def __init__(self, maxlen,embedding_matrix,class_num1=17,class_num2=12):\n",
    "        \"\"\"\n",
    "            初始化\n",
    "        :param hyper_parameters: json，超参\n",
    "        \"\"\"\n",
    "        self.maxlen=maxlen\n",
    "        self.embedding_matrix=embedding_matrix\n",
    "        self.class_num1=class_num1\n",
    "        self.class_num2=class_num2\n",
    "        self.dropout=0.2\n",
    "        self.filters=[[64, 2], [128, 2], [256, 2], [512, 2]]\n",
    "        self.pool_type= 'avg' # 池化选择, 可以选\"max\"、\"avg\"、\"conv\"\n",
    "        self.l2=0\n",
    "        self.activation_conv = 'linear'\n",
    "        self.top_k=2\n",
    "    \n",
    "        self.shortcut = True\n",
    "\n",
    "    def create_model(self,):\n",
    "        \"\"\"\n",
    "            构建神经网络\n",
    "        :param hyper_parameters:json,  hyper parameters of network\n",
    "        :return: tensor, moedl\n",
    "        \"\"\"\n",
    "        emb_layer = Embedding(\n",
    "        self.embedding_matrix.shape[0], self.embedding_matrix.shape[1],input_length=self.maxlen,weights=[self.embedding_matrix],trainable=False,\n",
    ")\n",
    "        seq1 = Input(shape=(self.maxlen,)) \n",
    "        x1 = emb_layer(seq1)\n",
    "        # char or word\n",
    "        x1=SpatialDropout1D(rate=0.2)(x1)\n",
    "\n",
    "        # 首先是 region embedding 层\n",
    "        conv_1 = Conv1D(self.filters[0][0],\n",
    "                        kernel_size=1,\n",
    "                        strides=1,\n",
    "                        padding='SAME',\n",
    "                        kernel_regularizer=regularizers.l2(self.l2),\n",
    "                        bias_regularizer=regularizers.l2(self.l2),\n",
    "                        activation=self.activation_conv,\n",
    "                        )(x1)\n",
    "        block = ReLU()(conv_1)\n",
    "\n",
    "        for filters_block in self.filters:\n",
    "            for j in range(filters_block[1]-1):\n",
    "                # conv + short-cut\n",
    "                block_mid = self.convolutional_block(block, units=filters_block[0])\n",
    "                block = shortcut_conv(block, block_mid, shortcut=True)\n",
    "            # 这里是conv + max-pooling\n",
    "            block_mid = self.convolutional_block(block, units=filters_block[0])\n",
    "            block = shortcut_pool(block, block_mid, filters=filters_block[0], pool_type=self.pool_type, shortcut=True)\n",
    "\n",
    "        block = k_max_pooling(top_k=self.top_k)(block)\n",
    "        block = Flatten()(block)\n",
    "        block = Dropout(self.dropout)(block)\n",
    "        # 全连接层\n",
    "        # block_fully = Dense(2048, activation='tanh')(block)\n",
    "        # output = Dense(2048, activation='tanh')(block_fully)\n",
    "        \n",
    "        pred1 = Dense(self.class_num1, activation='sigmoid',name='pred1')(block)\n",
    "        pred2=Dense(self.class_num2, activation='sigmoid',name='pred2')(block)\n",
    "        output = [pred1,pred2]\n",
    "\n",
    "        self.model = Model(inputs=seq1, outputs=output)\n",
    "        self.model.summary(120)\n",
    "\n",
    "    def convolutional_block(self, inputs, units=256):\n",
    "        \"\"\"\n",
    "            Each convolutional block (see Figure 2) is a sequence of two convolutional layers, \n",
    "            each one followed by a temporal BatchNorm (Ioffe and Szegedy, 2015) layer and an ReLU activation. \n",
    "            The kernel size of all the temporal convolutions is 3, \n",
    "            with padding such that the temporal resolution is preserved \n",
    "            (or halved in the case of the convolutional pooling with stride 2, see below). \n",
    "        :param inputs: tensor, input\n",
    "        :param units: int, units\n",
    "        :return: tensor, result of convolutional block\n",
    "        \"\"\"\n",
    "        x = Conv1D(units,\n",
    "                    kernel_size=3,\n",
    "                    padding='SAME',\n",
    "                    strides=1,\n",
    "                    kernel_regularizer=regularizers.l2(self.l2),\n",
    "                    bias_regularizer=regularizers.l2(self.l2),\n",
    "                    activation=self.activation_conv,\n",
    "                    )(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv1D(units,\n",
    "                    kernel_size=3,\n",
    "                    strides=1,\n",
    "                    padding='SAME',\n",
    "                    kernel_regularizer=regularizers.l2(self.l2),\n",
    "                    bias_regularizer=regularizers.l2(self.l2),\n",
    "                    activation=self.activation_conv,\n",
    "                    )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def shortcut_pool(inputs, output, filters=256, pool_type='max', shortcut=True):\n",
    "    \"\"\"\n",
    "        ResNet(shortcut连接|skip连接|residual连接), \n",
    "        这里是用shortcut连接. 恒等映射, block+f(block)\n",
    "        再加上 downsampling实现\n",
    "        参考: https://github.com/zonetrooper32/VDCNN/blob/keras_version/vdcnn.py\n",
    "    :param inputs: tensor\n",
    "    :param output: tensor\n",
    "    :param filters: int\n",
    "    :param pool_type: str, 'max'、'k-max' or 'conv' or other\n",
    "    :param shortcut: boolean\n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "    if shortcut:\n",
    "        conv_2 = Conv1D(filters=filters, kernel_size=1, strides=2, padding='SAME')(inputs)\n",
    "        conv_2 = BatchNormalization()(conv_2)\n",
    "        output = downsampling(output, pool_type=pool_type)\n",
    "        out = Add()([output, conv_2])\n",
    "    else:\n",
    "        out = ReLU(inputs)\n",
    "        out = downsampling(out, pool_type=pool_type)\n",
    "    if pool_type is not None: # filters翻倍\n",
    "        out = Conv1D(filters=filters*2, kernel_size=1, strides=1, padding='SAME')(out)\n",
    "        out = BatchNormalization()(out)\n",
    "    return out\n",
    "\n",
    "def shortcut_conv(inputs, output, shortcut=True):\n",
    "    \"\"\"\n",
    "        shortcut of conv\n",
    "    :param inputs: tensor\n",
    "    :param output: tensor\n",
    "    :param shortcut: boolean\n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "    if shortcut:\n",
    "        output = Add()([output, inputs])\n",
    "    return output\n",
    "\n",
    "def downsampling(inputs, pool_type='max'):\n",
    "    \"\"\"\n",
    "        In addition, downsampling with stride 2 essentially doubles the effective coverage \n",
    "        (i.e., coverage in the original document) of the convolution kernel; \n",
    "        therefore, after going through downsampling L times, \n",
    "        associations among words within a distance in the order of 2L can be represented. \n",
    "        Thus, deep pyramid CNN is computationally efﬁcient for representing long-range associations \n",
    "        and so more global information. \n",
    "        参考: https://github.com/zonetrooper32/VDCNN/blob/keras_version/vdcnn.py\n",
    "    :param inputs: tensor,\n",
    "    :param pool_type: str, select 'max', 'k-max' or 'conv'\n",
    "    :return: tensor,\n",
    "    \"\"\"\n",
    "    if pool_type == 'max':\n",
    "        output = MaxPooling1D(pool_size=3, strides=2, padding='SAME')(inputs)\n",
    "    elif pool_type == 'k-max':\n",
    "        output = k_max_pooling(top_k=int(K.int_shape(inputs)[1]/2))(inputs)\n",
    "    elif pool_type == 'conv':\n",
    "        output = Conv1D(kernel_size=3, strides=2, padding='SAME')(inputs)\n",
    "    else:\n",
    "        output = MaxPooling1D(pool_size=3, strides=2, padding='SAME')(inputs)\n",
    "    return output\n",
    "\n",
    "class k_max_pooling(Layer):\n",
    "    \"\"\"\n",
    "        paper:        http://www.aclweb.org/anthology/P14-1062\n",
    "        paper title:  A Convolutional Neural Network for Modelling Sentences\n",
    "        Reference:    https://stackoverflow.com/questions/51299181/how-to-implement-k-max-pooling-in-tensorflow-or-keras\n",
    "        动态K-max pooling\n",
    "            k的选择为 k = max(k, s * (L-1) / L)\n",
    "            其中k为预先选定的设置的最大的K个值，s为文本最大长度，L为第几个卷积层的深度（单个卷积到连接层等）\n",
    "        github tf实现可以参考: https://github.com/lpty/classifier/blob/master/a04_dcnn/model.py\n",
    "    \"\"\"\n",
    "    def __init__(self, top_k=8, **kwargs):\n",
    "        self.top_k = top_k\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs_reshape = tf.transpose(inputs, perm=[0, 2, 1])\n",
    "        pool_top_k = tf.nn.top_k(input=inputs_reshape, k=self.top_k, sorted=False).values\n",
    "        pool_top_k_reshape = tf.transpose(pool_top_k, perm=[0, 2, 1])\n",
    "        return pool_top_k_reshape\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.top_k, input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "accurate-butler",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T10:01:51.466786Z",
     "start_time": "2021-04-21T09:26:37.354430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lichangyv/miniconda3/envs/tf2/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=8.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Build model...\n",
      "Model: \"model_10\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_16 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)               (None, 128, 128)           109952        input_16[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDropout1D (None, 128, 128)           0             embedding_12[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_11[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_63 (ReLU)                        (None, 128, 64)            0             conv1d_106[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)                    (None, 128, 64)            12352         re_lu_63[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNormaliza (None, 128, 64)            256           conv1d_107[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_64 (ReLU)                        (None, 128, 64)            0             batch_normalization_98[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)                    (None, 128, 64)            12352         re_lu_64[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNormaliza (None, 128, 64)            256           conv1d_108[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_65 (ReLU)                        (None, 128, 64)            0             batch_normalization_99[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "add_26 (Add)                           (None, 128, 64)            0             re_lu_65[0][0]                          \n",
      "                                                                                re_lu_63[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)                    (None, 128, 64)            12352         add_26[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNormaliz (None, 128, 64)            256           conv1d_109[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_66 (ReLU)                        (None, 128, 64)            0             batch_normalization_100[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)                    (None, 128, 64)            12352         re_lu_66[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNormaliz (None, 128, 64)            256           conv1d_110[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_67 (ReLU)                        (None, 128, 64)            0             batch_normalization_101[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)                    (None, 64, 64)             4160          add_26[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D)        (None, 64, 64)             0             re_lu_67[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNormaliz (None, 64, 64)             256           conv1d_111[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_27 (Add)                           (None, 64, 64)             0             max_pooling1d_20[0][0]                  \n",
      "                                                                                batch_normalization_102[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_112 (Conv1D)                    (None, 64, 128)            8320          add_27[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNormaliz (None, 64, 128)            512           conv1d_112[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_113 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_103[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNormaliz (None, 64, 128)            512           conv1d_113[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_68 (ReLU)                        (None, 64, 128)            0             batch_normalization_104[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_114 (Conv1D)                    (None, 64, 128)            49280         re_lu_68[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNormaliz (None, 64, 128)            512           conv1d_114[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_69 (ReLU)                        (None, 64, 128)            0             batch_normalization_105[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_28 (Add)                           (None, 64, 128)            0             re_lu_69[0][0]                          \n",
      "                                                                                batch_normalization_103[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_115 (Conv1D)                    (None, 64, 128)            49280         add_28[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNormaliz (None, 64, 128)            512           conv1d_115[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_70 (ReLU)                        (None, 64, 128)            0             batch_normalization_106[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_116 (Conv1D)                    (None, 64, 128)            49280         re_lu_70[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNormaliz (None, 64, 128)            512           conv1d_116[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_71 (ReLU)                        (None, 64, 128)            0             batch_normalization_107[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_117 (Conv1D)                    (None, 32, 128)            16512         add_28[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D)        (None, 32, 128)            0             re_lu_71[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNormaliz (None, 32, 128)            512           conv1d_117[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_29 (Add)                           (None, 32, 128)            0             max_pooling1d_21[0][0]                  \n",
      "                                                                                batch_normalization_108[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_118 (Conv1D)                    (None, 32, 256)            33024         add_29[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNormaliz (None, 32, 256)            1024          conv1d_118[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_119 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_109[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNormaliz (None, 32, 256)            1024          conv1d_119[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_72 (ReLU)                        (None, 32, 256)            0             batch_normalization_110[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)                    (None, 32, 256)            196864        re_lu_72[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNormaliz (None, 32, 256)            1024          conv1d_120[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_73 (ReLU)                        (None, 32, 256)            0             batch_normalization_111[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_30 (Add)                           (None, 32, 256)            0             re_lu_73[0][0]                          \n",
      "                                                                                batch_normalization_109[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)                    (None, 32, 256)            196864        add_30[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNormaliz (None, 32, 256)            1024          conv1d_121[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_74 (ReLU)                        (None, 32, 256)            0             batch_normalization_112[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)                    (None, 32, 256)            196864        re_lu_74[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNormaliz (None, 32, 256)            1024          conv1d_122[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_75 (ReLU)                        (None, 32, 256)            0             batch_normalization_113[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)                    (None, 16, 256)            65792         add_30[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D)        (None, 16, 256)            0             re_lu_75[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNormaliz (None, 16, 256)            1024          conv1d_123[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_31 (Add)                           (None, 16, 256)            0             max_pooling1d_22[0][0]                  \n",
      "                                                                                batch_normalization_114[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)                    (None, 16, 512)            131584        add_31[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNormaliz (None, 16, 512)            2048          conv1d_124[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_115[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNormaliz (None, 16, 512)            2048          conv1d_125[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_76 (ReLU)                        (None, 16, 512)            0             batch_normalization_116[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)                    (None, 16, 512)            786944        re_lu_76[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNormaliz (None, 16, 512)            2048          conv1d_126[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_77 (ReLU)                        (None, 16, 512)            0             batch_normalization_117[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_32 (Add)                           (None, 16, 512)            0             re_lu_77[0][0]                          \n",
      "                                                                                batch_normalization_115[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)                    (None, 16, 512)            786944        add_32[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNormaliz (None, 16, 512)            2048          conv1d_127[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_78 (ReLU)                        (None, 16, 512)            0             batch_normalization_118[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)                    (None, 16, 512)            786944        re_lu_78[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNormaliz (None, 16, 512)            2048          conv1d_128[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_79 (ReLU)                        (None, 16, 512)            0             batch_normalization_119[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)                    (None, 8, 512)             262656        add_32[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D)        (None, 8, 512)             0             re_lu_79[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNormaliz (None, 8, 512)             2048          conv1d_129[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_33 (Add)                           (None, 8, 512)             0             max_pooling1d_23[0][0]                  \n",
      "                                                                                batch_normalization_120[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)                    (None, 8, 1024)            525312        add_33[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNormaliz (None, 8, 1024)            4096          conv1d_130[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_5 (k_max_pooling)        (None, 2, 1024)            0             batch_normalization_121[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)                    (None, 2048)               0             k_max_pooling_5[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)                    (None, 2048)               0             flatten_4[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_8[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_8[0][0]                         \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 25s 129ms/step - loss: 0.4862 - pred1_loss: 0.2790 - pred2_loss: 0.2072 - pred1_accuracy: 0.1571 - pred1_mean_pred: 2.7895 - pred2_accuracy: 0.3578 - pred2_mean_pred: 2.0700 - val_loss: 0.3995 - val_pred1_loss: 0.2283 - val_pred2_loss: 0.1711 - val_pred1_accuracy: 0.3760 - val_pred1_mean_pred: 2.2795 - val_pred2_accuracy: 0.3044 - val_pred2_mean_pred: 1.7137\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39945, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 17s 124ms/step - loss: 0.2342 - pred1_loss: 0.1505 - pred2_loss: 0.0837 - pred1_accuracy: 0.2044 - pred1_mean_pred: 1.5047 - pred2_accuracy: 0.4764 - pred2_mean_pred: 0.8370 - val_loss: 0.2724 - val_pred1_loss: 0.1562 - val_pred2_loss: 0.1163 - val_pred1_accuracy: 0.1072 - val_pred1_mean_pred: 1.5568 - val_pred2_accuracy: 0.4664 - val_pred2_mean_pred: 1.1642\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39945 to 0.27243, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 18s 130ms/step - loss: 0.1878 - pred1_loss: 0.1264 - pred2_loss: 0.0614 - pred1_accuracy: 0.2169 - pred1_mean_pred: 1.2641 - pred2_accuracy: 0.4949 - pred2_mean_pred: 0.6136 - val_loss: 0.1996 - val_pred1_loss: 0.1227 - val_pred2_loss: 0.0769 - val_pred1_accuracy: 0.2108 - val_pred1_mean_pred: 1.2233 - val_pred2_accuracy: 0.5456 - val_pred2_mean_pred: 0.7701\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27243 to 0.19963, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 19s 139ms/step - loss: 0.1619 - pred1_loss: 0.1094 - pred2_loss: 0.0526 - pred1_accuracy: 0.2344 - pred1_mean_pred: 1.0938 - pred2_accuracy: 0.5533 - pred2_mean_pred: 0.5257 - val_loss: 0.1801 - val_pred1_loss: 0.1219 - val_pred2_loss: 0.0582 - val_pred1_accuracy: 0.2192 - val_pred1_mean_pred: 1.2190 - val_pred2_accuracy: 0.4508 - val_pred2_mean_pred: 0.5900\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19963 to 0.18008, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 20s 146ms/step - loss: 0.1485 - pred1_loss: 0.1011 - pred2_loss: 0.0474 - pred1_accuracy: 0.2566 - pred1_mean_pred: 1.0109 - pred2_accuracy: 0.5090 - pred2_mean_pred: 0.4740 - val_loss: 0.1731 - val_pred1_loss: 0.1181 - val_pred2_loss: 0.0550 - val_pred1_accuracy: 0.2112 - val_pred1_mean_pred: 1.1793 - val_pred2_accuracy: 0.5092 - val_pred2_mean_pred: 0.5548\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18008 to 0.17311, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 20s 150ms/step - loss: 0.1313 - pred1_loss: 0.0924 - pred2_loss: 0.0389 - pred1_accuracy: 0.2474 - pred1_mean_pred: 0.9241 - pred2_accuracy: 0.5309 - pred2_mean_pred: 0.3893 - val_loss: 0.1436 - val_pred1_loss: 0.0980 - val_pred2_loss: 0.0456 - val_pred1_accuracy: 0.4596 - val_pred1_mean_pred: 0.9784 - val_pred2_accuracy: 0.4920 - val_pred2_mean_pred: 0.4544\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17311 to 0.14357, saving model to ../model_weight/V2_0.h5\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 21s 150ms/step - loss: 0.1201 - pred1_loss: 0.0867 - pred2_loss: 0.0334 - pred1_accuracy: 0.2712 - pred1_mean_pred: 0.8672 - pred2_accuracy: 0.5269 - pred2_mean_pred: 0.3340 - val_loss: 0.1439 - val_pred1_loss: 0.0933 - val_pred2_loss: 0.0506 - val_pred1_accuracy: 0.2164 - val_pred1_mean_pred: 0.9289 - val_pred2_accuracy: 0.4484 - val_pred2_mean_pred: 0.5067\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.14357\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 20s 150ms/step - loss: 0.1176 - pred1_loss: 0.0860 - pred2_loss: 0.0316 - pred1_accuracy: 0.2546 - pred1_mean_pred: 0.8600 - pred2_accuracy: 0.5268 - pred2_mean_pred: 0.3158 - val_loss: 0.1439 - val_pred1_loss: 0.0949 - val_pred2_loss: 0.0489 - val_pred1_accuracy: 0.2100 - val_pred1_mean_pred: 0.9459 - val_pred2_accuracy: 0.6032 - val_pred2_mean_pred: 0.4905\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14357\n",
      "Fold 1\n",
      "Build model...\n",
      "Model: \"model_11\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_17 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)               (None, 128, 128)           109952        input_17[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDropout1D (None, 128, 128)           0             embedding_13[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_12[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_80 (ReLU)                        (None, 128, 64)            0             conv1d_131[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)                    (None, 128, 64)            12352         re_lu_80[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNormaliz (None, 128, 64)            256           conv1d_132[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_81 (ReLU)                        (None, 128, 64)            0             batch_normalization_122[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)                    (None, 128, 64)            12352         re_lu_81[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNormaliz (None, 128, 64)            256           conv1d_133[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_82 (ReLU)                        (None, 128, 64)            0             batch_normalization_123[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_34 (Add)                           (None, 128, 64)            0             re_lu_82[0][0]                          \n",
      "                                                                                re_lu_80[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)                    (None, 128, 64)            12352         add_34[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNormaliz (None, 128, 64)            256           conv1d_134[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_83 (ReLU)                        (None, 128, 64)            0             batch_normalization_124[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)                    (None, 128, 64)            12352         re_lu_83[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNormaliz (None, 128, 64)            256           conv1d_135[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_84 (ReLU)                        (None, 128, 64)            0             batch_normalization_125[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)                    (None, 64, 64)             4160          add_34[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D)        (None, 64, 64)             0             re_lu_84[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNormaliz (None, 64, 64)             256           conv1d_136[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_35 (Add)                           (None, 64, 64)             0             max_pooling1d_24[0][0]                  \n",
      "                                                                                batch_normalization_126[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)                    (None, 64, 128)            8320          add_35[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNormaliz (None, 64, 128)            512           conv1d_137[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_127[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNormaliz (None, 64, 128)            512           conv1d_138[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_85 (ReLU)                        (None, 64, 128)            0             batch_normalization_128[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)                    (None, 64, 128)            49280         re_lu_85[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNormaliz (None, 64, 128)            512           conv1d_139[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_86 (ReLU)                        (None, 64, 128)            0             batch_normalization_129[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_36 (Add)                           (None, 64, 128)            0             re_lu_86[0][0]                          \n",
      "                                                                                batch_normalization_127[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)                    (None, 64, 128)            49280         add_36[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNormaliz (None, 64, 128)            512           conv1d_140[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_87 (ReLU)                        (None, 64, 128)            0             batch_normalization_130[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)                    (None, 64, 128)            49280         re_lu_87[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNormaliz (None, 64, 128)            512           conv1d_141[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_88 (ReLU)                        (None, 64, 128)            0             batch_normalization_131[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)                    (None, 32, 128)            16512         add_36[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D)        (None, 32, 128)            0             re_lu_88[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNormaliz (None, 32, 128)            512           conv1d_142[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_37 (Add)                           (None, 32, 128)            0             max_pooling1d_25[0][0]                  \n",
      "                                                                                batch_normalization_132[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)                    (None, 32, 256)            33024         add_37[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNormaliz (None, 32, 256)            1024          conv1d_143[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_133[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNormaliz (None, 32, 256)            1024          conv1d_144[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_89 (ReLU)                        (None, 32, 256)            0             batch_normalization_134[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)                    (None, 32, 256)            196864        re_lu_89[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNormaliz (None, 32, 256)            1024          conv1d_145[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_90 (ReLU)                        (None, 32, 256)            0             batch_normalization_135[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_38 (Add)                           (None, 32, 256)            0             re_lu_90[0][0]                          \n",
      "                                                                                batch_normalization_133[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)                    (None, 32, 256)            196864        add_38[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNormaliz (None, 32, 256)            1024          conv1d_146[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_91 (ReLU)                        (None, 32, 256)            0             batch_normalization_136[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)                    (None, 32, 256)            196864        re_lu_91[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNormaliz (None, 32, 256)            1024          conv1d_147[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_92 (ReLU)                        (None, 32, 256)            0             batch_normalization_137[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)                    (None, 16, 256)            65792         add_38[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D)        (None, 16, 256)            0             re_lu_92[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNormaliz (None, 16, 256)            1024          conv1d_148[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_39 (Add)                           (None, 16, 256)            0             max_pooling1d_26[0][0]                  \n",
      "                                                                                batch_normalization_138[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)                    (None, 16, 512)            131584        add_39[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNormaliz (None, 16, 512)            2048          conv1d_149[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_139[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNormaliz (None, 16, 512)            2048          conv1d_150[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_93 (ReLU)                        (None, 16, 512)            0             batch_normalization_140[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)                    (None, 16, 512)            786944        re_lu_93[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNormaliz (None, 16, 512)            2048          conv1d_151[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_94 (ReLU)                        (None, 16, 512)            0             batch_normalization_141[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_40 (Add)                           (None, 16, 512)            0             re_lu_94[0][0]                          \n",
      "                                                                                batch_normalization_139[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)                    (None, 16, 512)            786944        add_40[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNormaliz (None, 16, 512)            2048          conv1d_152[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_95 (ReLU)                        (None, 16, 512)            0             batch_normalization_142[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)                    (None, 16, 512)            786944        re_lu_95[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNormaliz (None, 16, 512)            2048          conv1d_153[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_96 (ReLU)                        (None, 16, 512)            0             batch_normalization_143[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)                    (None, 8, 512)             262656        add_40[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D)        (None, 8, 512)             0             re_lu_96[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNormaliz (None, 8, 512)             2048          conv1d_154[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_41 (Add)                           (None, 8, 512)             0             max_pooling1d_27[0][0]                  \n",
      "                                                                                batch_normalization_144[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)                    (None, 8, 1024)            525312        add_41[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNormaliz (None, 8, 1024)            4096          conv1d_155[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_6 (k_max_pooling)        (None, 2, 1024)            0             batch_normalization_145[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)                    (None, 2048)               0             k_max_pooling_6[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)                    (None, 2048)               0             flatten_5[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_9[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_9[0][0]                         \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 29s 158ms/step - loss: 0.4663 - pred1_loss: 0.2628 - pred2_loss: 0.2036 - pred1_accuracy: 0.1507 - pred1_mean_pred: 2.6274 - pred2_accuracy: 0.3742 - pred2_mean_pred: 2.0352 - val_loss: 0.3743 - val_pred1_loss: 0.2370 - val_pred2_loss: 0.1373 - val_pred1_accuracy: 0.1116 - val_pred1_mean_pred: 2.3651 - val_pred2_accuracy: 0.4756 - val_pred2_mean_pred: 1.3729\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37427, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 21s 155ms/step - loss: 0.2259 - pred1_loss: 0.1448 - pred2_loss: 0.0811 - pred1_accuracy: 0.1924 - pred1_mean_pred: 1.4483 - pred2_accuracy: 0.4577 - pred2_mean_pred: 0.8109 - val_loss: 0.2481 - val_pred1_loss: 0.1682 - val_pred2_loss: 0.0799 - val_pred1_accuracy: 0.1344 - val_pred1_mean_pred: 1.6806 - val_pred2_accuracy: 0.4860 - val_pred2_mean_pred: 0.8020\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37427 to 0.24807, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 22s 163ms/step - loss: 0.1845 - pred1_loss: 0.1229 - pred2_loss: 0.0617 - pred1_accuracy: 0.2444 - pred1_mean_pred: 1.2285 - pred2_accuracy: 0.4994 - pred2_mean_pred: 0.6169 - val_loss: 0.2183 - val_pred1_loss: 0.1386 - val_pred2_loss: 0.0797 - val_pred1_accuracy: 0.2248 - val_pred1_mean_pred: 1.3875 - val_pred2_accuracy: 0.4508 - val_pred2_mean_pred: 0.7975\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24807 to 0.21831, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 22s 161ms/step - loss: 0.1585 - pred1_loss: 0.1076 - pred2_loss: 0.0508 - pred1_accuracy: 0.2570 - pred1_mean_pred: 1.0763 - pred2_accuracy: 0.5136 - pred2_mean_pred: 0.5085 - val_loss: 0.1638 - val_pred1_loss: 0.1076 - val_pred2_loss: 0.0562 - val_pred1_accuracy: 0.2216 - val_pred1_mean_pred: 1.0820 - val_pred2_accuracy: 0.4860 - val_pred2_mean_pred: 0.5626\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21831 to 0.16375, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 21s 153ms/step - loss: 0.1414 - pred1_loss: 0.0973 - pred2_loss: 0.0440 - pred1_accuracy: 0.2503 - pred1_mean_pred: 0.9732 - pred2_accuracy: 0.5141 - pred2_mean_pred: 0.4403 - val_loss: 0.1932 - val_pred1_loss: 0.1370 - val_pred2_loss: 0.0562 - val_pred1_accuracy: 0.2332 - val_pred1_mean_pred: 1.3744 - val_pred2_accuracy: 0.4768 - val_pred2_mean_pred: 0.5606\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16375\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 21s 155ms/step - loss: 0.1286 - pred1_loss: 0.0917 - pred2_loss: 0.0369 - pred1_accuracy: 0.2511 - pred1_mean_pred: 0.9166 - pred2_accuracy: 0.5408 - pred2_mean_pred: 0.3695 - val_loss: 0.1610 - val_pred1_loss: 0.0970 - val_pred2_loss: 0.0641 - val_pred1_accuracy: 0.2968 - val_pred1_mean_pred: 0.9743 - val_pred2_accuracy: 0.5836 - val_pred2_mean_pred: 0.6407\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16375 to 0.16104, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 24s 172ms/step - loss: 0.1211 - pred1_loss: 0.0852 - pred2_loss: 0.0358 - pred1_accuracy: 0.2766 - pred1_mean_pred: 0.8524 - pred2_accuracy: 0.5290 - pred2_mean_pred: 0.3583 - val_loss: 0.1621 - val_pred1_loss: 0.1174 - val_pred2_loss: 0.0447 - val_pred1_accuracy: 0.2068 - val_pred1_mean_pred: 1.1707 - val_pred2_accuracy: 0.4812 - val_pred2_mean_pred: 0.4439\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16104\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 23s 165ms/step - loss: 0.1121 - pred1_loss: 0.0812 - pred2_loss: 0.0309 - pred1_accuracy: 0.2564 - pred1_mean_pred: 0.8121 - pred2_accuracy: 0.5237 - pred2_mean_pred: 0.3086 - val_loss: 0.1421 - val_pred1_loss: 0.1024 - val_pred2_loss: 0.0397 - val_pred1_accuracy: 0.2064 - val_pred1_mean_pred: 1.0303 - val_pred2_accuracy: 0.5032 - val_pred2_mean_pred: 0.3985\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16104 to 0.14205, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - 22s 159ms/step - loss: 0.1038 - pred1_loss: 0.0782 - pred2_loss: 0.0256 - pred1_accuracy: 0.2668 - pred1_mean_pred: 0.7824 - pred2_accuracy: 0.5058 - pred2_mean_pred: 0.2558 - val_loss: 0.1331 - val_pred1_loss: 0.0963 - val_pred2_loss: 0.0367 - val_pred1_accuracy: 0.1948 - val_pred1_mean_pred: 0.9687 - val_pred2_accuracy: 0.4756 - val_pred2_mean_pred: 0.3673\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14205 to 0.13307, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - 22s 159ms/step - loss: 0.1007 - pred1_loss: 0.0765 - pred2_loss: 0.0242 - pred1_accuracy: 0.2896 - pred1_mean_pred: 0.7652 - pred2_accuracy: 0.5156 - pred2_mean_pred: 0.2423 - val_loss: 0.1249 - val_pred1_loss: 0.0861 - val_pred2_loss: 0.0388 - val_pred1_accuracy: 0.3260 - val_pred1_mean_pred: 0.8640 - val_pred2_accuracy: 0.4724 - val_pred2_mean_pred: 0.3866\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.13307 to 0.12488, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - 22s 160ms/step - loss: 0.0924 - pred1_loss: 0.0718 - pred2_loss: 0.0206 - pred1_accuracy: 0.2962 - pred1_mean_pred: 0.7184 - pred2_accuracy: 0.5193 - pred2_mean_pred: 0.2060 - val_loss: 0.1290 - val_pred1_loss: 0.0907 - val_pred2_loss: 0.0383 - val_pred1_accuracy: 0.2640 - val_pred1_mean_pred: 0.9094 - val_pred2_accuracy: 0.5516 - val_pred2_mean_pred: 0.3835\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12488\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - 22s 159ms/step - loss: 0.0845 - pred1_loss: 0.0646 - pred2_loss: 0.0199 - pred1_accuracy: 0.3353 - pred1_mean_pred: 0.6464 - pred2_accuracy: 0.5317 - pred2_mean_pred: 0.1991 - val_loss: 0.1132 - val_pred1_loss: 0.0712 - val_pred2_loss: 0.0419 - val_pred1_accuracy: 0.3236 - val_pred1_mean_pred: 0.7163 - val_pred2_accuracy: 0.6036 - val_pred2_mean_pred: 0.4178\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.12488 to 0.11318, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 13/100\n",
      "137/137 [==============================] - 22s 159ms/step - loss: 0.0719 - pred1_loss: 0.0515 - pred2_loss: 0.0204 - pred1_accuracy: 0.4010 - pred1_mean_pred: 0.5155 - pred2_accuracy: 0.5207 - pred2_mean_pred: 0.2035 - val_loss: 0.1125 - val_pred1_loss: 0.0735 - val_pred2_loss: 0.0389 - val_pred1_accuracy: 0.3740 - val_pred1_mean_pred: 0.7355 - val_pred2_accuracy: 0.5232 - val_pred2_mean_pred: 0.3857\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.11318 to 0.11246, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 14/100\n",
      "137/137 [==============================] - 22s 159ms/step - loss: 0.0651 - pred1_loss: 0.0470 - pred2_loss: 0.0181 - pred1_accuracy: 0.3894 - pred1_mean_pred: 0.4700 - pred2_accuracy: 0.5269 - pred2_mean_pred: 0.1811 - val_loss: 0.1394 - val_pred1_loss: 0.0758 - val_pred2_loss: 0.0636 - val_pred1_accuracy: 0.4176 - val_pred1_mean_pred: 0.7576 - val_pred2_accuracy: 0.5484 - val_pred2_mean_pred: 0.6369\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.11246\n",
      "Epoch 15/100\n",
      "137/137 [==============================] - 22s 164ms/step - loss: 0.0554 - pred1_loss: 0.0402 - pred2_loss: 0.0152 - pred1_accuracy: 0.4010 - pred1_mean_pred: 0.4017 - pred2_accuracy: 0.5259 - pred2_mean_pred: 0.1518 - val_loss: 0.1117 - val_pred1_loss: 0.0624 - val_pred2_loss: 0.0493 - val_pred1_accuracy: 0.4524 - val_pred1_mean_pred: 0.6218 - val_pred2_accuracy: 0.4620 - val_pred2_mean_pred: 0.4892\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.11246 to 0.11166, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 16/100\n",
      "137/137 [==============================] - 25s 181ms/step - loss: 0.0501 - pred1_loss: 0.0359 - pred2_loss: 0.0142 - pred1_accuracy: 0.3980 - pred1_mean_pred: 0.3592 - pred2_accuracy: 0.5942 - pred2_mean_pred: 0.1417 - val_loss: 0.0876 - val_pred1_loss: 0.0578 - val_pred2_loss: 0.0298 - val_pred1_accuracy: 0.4084 - val_pred1_mean_pred: 0.5788 - val_pred2_accuracy: 0.5248 - val_pred2_mean_pred: 0.3000\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.11166 to 0.08761, saving model to ../model_weight/V2_1.h5\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 23s 165ms/step - loss: 0.0491 - pred1_loss: 0.0339 - pred2_loss: 0.0152 - pred1_accuracy: 0.3858 - pred1_mean_pred: 0.3392 - pred2_accuracy: 0.5635 - pred2_mean_pred: 0.1518 - val_loss: 0.0977 - val_pred1_loss: 0.0598 - val_pred2_loss: 0.0379 - val_pred1_accuracy: 0.3220 - val_pred1_mean_pred: 0.5966 - val_pred2_accuracy: 0.4644 - val_pred2_mean_pred: 0.3778\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08761\n",
      "Epoch 18/100\n",
      "137/137 [==============================] - 23s 165ms/step - loss: 0.0446 - pred1_loss: 0.0319 - pred2_loss: 0.0127 - pred1_accuracy: 0.3869 - pred1_mean_pred: 0.3188 - pred2_accuracy: 0.5459 - pred2_mean_pred: 0.1269 - val_loss: 0.0928 - val_pred1_loss: 0.0548 - val_pred2_loss: 0.0380 - val_pred1_accuracy: 0.3444 - val_pred1_mean_pred: 0.5474 - val_pred2_accuracy: 0.4872 - val_pred2_mean_pred: 0.3824\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.08761\n",
      "Fold 2\n",
      "Build model...\n",
      "Model: \"model_12\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_18 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)               (None, 128, 128)           109952        input_18[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDropout1D (None, 128, 128)           0             embedding_14[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_156 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_13[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_97 (ReLU)                        (None, 128, 64)            0             conv1d_156[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_157 (Conv1D)                    (None, 128, 64)            12352         re_lu_97[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNormaliz (None, 128, 64)            256           conv1d_157[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_98 (ReLU)                        (None, 128, 64)            0             batch_normalization_146[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_158 (Conv1D)                    (None, 128, 64)            12352         re_lu_98[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNormaliz (None, 128, 64)            256           conv1d_158[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_99 (ReLU)                        (None, 128, 64)            0             batch_normalization_147[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_42 (Add)                           (None, 128, 64)            0             re_lu_99[0][0]                          \n",
      "                                                                                re_lu_97[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_159 (Conv1D)                    (None, 128, 64)            12352         add_42[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNormaliz (None, 128, 64)            256           conv1d_159[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_100 (ReLU)                       (None, 128, 64)            0             batch_normalization_148[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_160 (Conv1D)                    (None, 128, 64)            12352         re_lu_100[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNormaliz (None, 128, 64)            256           conv1d_160[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_101 (ReLU)                       (None, 128, 64)            0             batch_normalization_149[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_161 (Conv1D)                    (None, 64, 64)             4160          add_42[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D)        (None, 64, 64)             0             re_lu_101[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNormaliz (None, 64, 64)             256           conv1d_161[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_43 (Add)                           (None, 64, 64)             0             max_pooling1d_28[0][0]                  \n",
      "                                                                                batch_normalization_150[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_162 (Conv1D)                    (None, 64, 128)            8320          add_43[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNormaliz (None, 64, 128)            512           conv1d_162[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_163 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_151[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNormaliz (None, 64, 128)            512           conv1d_163[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_102 (ReLU)                       (None, 64, 128)            0             batch_normalization_152[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_164 (Conv1D)                    (None, 64, 128)            49280         re_lu_102[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNormaliz (None, 64, 128)            512           conv1d_164[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_103 (ReLU)                       (None, 64, 128)            0             batch_normalization_153[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_44 (Add)                           (None, 64, 128)            0             re_lu_103[0][0]                         \n",
      "                                                                                batch_normalization_151[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_165 (Conv1D)                    (None, 64, 128)            49280         add_44[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNormaliz (None, 64, 128)            512           conv1d_165[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_104 (ReLU)                       (None, 64, 128)            0             batch_normalization_154[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_166 (Conv1D)                    (None, 64, 128)            49280         re_lu_104[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNormaliz (None, 64, 128)            512           conv1d_166[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_105 (ReLU)                       (None, 64, 128)            0             batch_normalization_155[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_167 (Conv1D)                    (None, 32, 128)            16512         add_44[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D)        (None, 32, 128)            0             re_lu_105[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNormaliz (None, 32, 128)            512           conv1d_167[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_45 (Add)                           (None, 32, 128)            0             max_pooling1d_29[0][0]                  \n",
      "                                                                                batch_normalization_156[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_168 (Conv1D)                    (None, 32, 256)            33024         add_45[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNormaliz (None, 32, 256)            1024          conv1d_168[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_169 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_157[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNormaliz (None, 32, 256)            1024          conv1d_169[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_106 (ReLU)                       (None, 32, 256)            0             batch_normalization_158[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_170 (Conv1D)                    (None, 32, 256)            196864        re_lu_106[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNormaliz (None, 32, 256)            1024          conv1d_170[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_107 (ReLU)                       (None, 32, 256)            0             batch_normalization_159[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_46 (Add)                           (None, 32, 256)            0             re_lu_107[0][0]                         \n",
      "                                                                                batch_normalization_157[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_171 (Conv1D)                    (None, 32, 256)            196864        add_46[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNormaliz (None, 32, 256)            1024          conv1d_171[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_108 (ReLU)                       (None, 32, 256)            0             batch_normalization_160[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_172 (Conv1D)                    (None, 32, 256)            196864        re_lu_108[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNormaliz (None, 32, 256)            1024          conv1d_172[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_109 (ReLU)                       (None, 32, 256)            0             batch_normalization_161[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_173 (Conv1D)                    (None, 16, 256)            65792         add_46[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D)        (None, 16, 256)            0             re_lu_109[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNormaliz (None, 16, 256)            1024          conv1d_173[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_47 (Add)                           (None, 16, 256)            0             max_pooling1d_30[0][0]                  \n",
      "                                                                                batch_normalization_162[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_174 (Conv1D)                    (None, 16, 512)            131584        add_47[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNormaliz (None, 16, 512)            2048          conv1d_174[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_175 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_163[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNormaliz (None, 16, 512)            2048          conv1d_175[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_110 (ReLU)                       (None, 16, 512)            0             batch_normalization_164[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_176 (Conv1D)                    (None, 16, 512)            786944        re_lu_110[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNormaliz (None, 16, 512)            2048          conv1d_176[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_111 (ReLU)                       (None, 16, 512)            0             batch_normalization_165[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_48 (Add)                           (None, 16, 512)            0             re_lu_111[0][0]                         \n",
      "                                                                                batch_normalization_163[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_177 (Conv1D)                    (None, 16, 512)            786944        add_48[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNormaliz (None, 16, 512)            2048          conv1d_177[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_112 (ReLU)                       (None, 16, 512)            0             batch_normalization_166[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_178 (Conv1D)                    (None, 16, 512)            786944        re_lu_112[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNormaliz (None, 16, 512)            2048          conv1d_178[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_113 (ReLU)                       (None, 16, 512)            0             batch_normalization_167[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_179 (Conv1D)                    (None, 8, 512)             262656        add_48[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D)        (None, 8, 512)             0             re_lu_113[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNormaliz (None, 8, 512)             2048          conv1d_179[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_49 (Add)                           (None, 8, 512)             0             max_pooling1d_31[0][0]                  \n",
      "                                                                                batch_normalization_168[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_180 (Conv1D)                    (None, 8, 1024)            525312        add_49[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNormaliz (None, 8, 1024)            4096          conv1d_180[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_7 (k_max_pooling)        (None, 2, 1024)            0             batch_normalization_169[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)                    (None, 2048)               0             k_max_pooling_7[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)                   (None, 2048)               0             flatten_6[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_10[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_10[0][0]                        \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 29s 160ms/step - loss: 0.4588 - pred1_loss: 0.2640 - pred2_loss: 0.1948 - pred1_accuracy: 0.1577 - pred1_mean_pred: 2.6394 - pred2_accuracy: 0.3500 - pred2_mean_pred: 1.9474 - val_loss: 0.3719 - val_pred1_loss: 0.2462 - val_pred2_loss: 0.1257 - val_pred1_accuracy: 0.0624 - val_pred1_mean_pred: 2.4564 - val_pred2_accuracy: 0.3452 - val_pred2_mean_pred: 1.2622\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37186, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 22s 160ms/step - loss: 0.2338 - pred1_loss: 0.1453 - pred2_loss: 0.0885 - pred1_accuracy: 0.2018 - pred1_mean_pred: 1.4529 - pred2_accuracy: 0.4683 - pred2_mean_pred: 0.8852 - val_loss: 0.2788 - val_pred1_loss: 0.1740 - val_pred2_loss: 0.1048 - val_pred1_accuracy: 0.0904 - val_pred1_mean_pred: 1.7387 - val_pred2_accuracy: 0.4068 - val_pred2_mean_pred: 1.0521\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37186 to 0.27879, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 22s 163ms/step - loss: 0.1847 - pred1_loss: 0.1216 - pred2_loss: 0.0631 - pred1_accuracy: 0.2400 - pred1_mean_pred: 1.2163 - pred2_accuracy: 0.4942 - pred2_mean_pred: 0.6308 - val_loss: 0.1942 - val_pred1_loss: 0.1259 - val_pred2_loss: 0.0683 - val_pred1_accuracy: 0.1460 - val_pred1_mean_pred: 1.2598 - val_pred2_accuracy: 0.4520 - val_pred2_mean_pred: 0.6882\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27879 to 0.19423, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 25s 185ms/step - loss: 0.1579 - pred1_loss: 0.1056 - pred2_loss: 0.0523 - pred1_accuracy: 0.2322 - pred1_mean_pred: 1.0561 - pred2_accuracy: 0.5263 - pred2_mean_pred: 0.5230 - val_loss: 0.1706 - val_pred1_loss: 0.1049 - val_pred2_loss: 0.0656 - val_pred1_accuracy: 0.2148 - val_pred1_mean_pred: 1.0472 - val_pred2_accuracy: 0.4900 - val_pred2_mean_pred: 0.6558\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19423 to 0.17055, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 26s 187ms/step - loss: 0.1415 - pred1_loss: 0.0971 - pred2_loss: 0.0444 - pred1_accuracy: 0.2591 - pred1_mean_pred: 0.9712 - pred2_accuracy: 0.5142 - pred2_mean_pred: 0.4438 - val_loss: 0.1642 - val_pred1_loss: 0.1130 - val_pred2_loss: 0.0513 - val_pred1_accuracy: 0.2700 - val_pred1_mean_pred: 1.1276 - val_pred2_accuracy: 0.4820 - val_pred2_mean_pred: 0.5127\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17055 to 0.16423, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 23s 167ms/step - loss: 0.1261 - pred1_loss: 0.0903 - pred2_loss: 0.0358 - pred1_accuracy: 0.2639 - pred1_mean_pred: 0.9028 - pred2_accuracy: 0.5154 - pred2_mean_pred: 0.3580 - val_loss: 0.1768 - val_pred1_loss: 0.1259 - val_pred2_loss: 0.0509 - val_pred1_accuracy: 0.3884 - val_pred1_mean_pred: 1.2575 - val_pred2_accuracy: 0.4964 - val_pred2_mean_pred: 0.5109\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16423\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 22s 164ms/step - loss: 0.1184 - pred1_loss: 0.0852 - pred2_loss: 0.0332 - pred1_accuracy: 0.2788 - pred1_mean_pred: 0.8518 - pred2_accuracy: 0.5118 - pred2_mean_pred: 0.3318 - val_loss: 0.1472 - val_pred1_loss: 0.1065 - val_pred2_loss: 0.0408 - val_pred1_accuracy: 0.3308 - val_pred1_mean_pred: 1.0641 - val_pred2_accuracy: 0.4980 - val_pred2_mean_pred: 0.4083\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16423 to 0.14723, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 22s 164ms/step - loss: 0.1070 - pred1_loss: 0.0793 - pred2_loss: 0.0278 - pred1_accuracy: 0.2940 - pred1_mean_pred: 0.7926 - pred2_accuracy: 0.5128 - pred2_mean_pred: 0.2777 - val_loss: 0.1461 - val_pred1_loss: 0.1018 - val_pred2_loss: 0.0443 - val_pred1_accuracy: 0.2416 - val_pred1_mean_pred: 1.0143 - val_pred2_accuracy: 0.4936 - val_pred2_mean_pred: 0.4453\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14723 to 0.14614, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - 23s 164ms/step - loss: 0.1057 - pred1_loss: 0.0795 - pred2_loss: 0.0262 - pred1_accuracy: 0.2613 - pred1_mean_pred: 0.7952 - pred2_accuracy: 0.5317 - pred2_mean_pred: 0.2620 - val_loss: 0.1463 - val_pred1_loss: 0.0945 - val_pred2_loss: 0.0518 - val_pred1_accuracy: 0.2828 - val_pred1_mean_pred: 0.9441 - val_pred2_accuracy: 0.5024 - val_pred2_mean_pred: 0.5233\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14614\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - 23s 168ms/step - loss: 0.0991 - pred1_loss: 0.0754 - pred2_loss: 0.0237 - pred1_accuracy: 0.2673 - pred1_mean_pred: 0.7541 - pred2_accuracy: 0.5436 - pred2_mean_pred: 0.2372 - val_loss: 0.1349 - val_pred1_loss: 0.0980 - val_pred2_loss: 0.0369 - val_pred1_accuracy: 0.2540 - val_pred1_mean_pred: 0.9807 - val_pred2_accuracy: 0.4808 - val_pred2_mean_pred: 0.3692\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14614 to 0.13490, saving model to ../model_weight/V2_2.h5\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - 27s 194ms/step - loss: 0.0913 - pred1_loss: 0.0721 - pred2_loss: 0.0192 - pred1_accuracy: 0.3563 - pred1_mean_pred: 0.7207 - pred2_accuracy: 0.5536 - pred2_mean_pred: 0.1921 - val_loss: 0.1406 - val_pred1_loss: 0.0952 - val_pred2_loss: 0.0454 - val_pred1_accuracy: 0.3320 - val_pred1_mean_pred: 0.9499 - val_pred2_accuracy: 0.6028 - val_pred2_mean_pred: 0.4543\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.13490\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - 25s 186ms/step - loss: 0.0873 - pred1_loss: 0.0683 - pred2_loss: 0.0189 - pred1_accuracy: 0.2976 - pred1_mean_pred: 0.6834 - pred2_accuracy: 0.5630 - pred2_mean_pred: 0.1893 - val_loss: 0.1355 - val_pred1_loss: 0.0898 - val_pred2_loss: 0.0457 - val_pred1_accuracy: 0.2820 - val_pred1_mean_pred: 0.8946 - val_pred2_accuracy: 0.4944 - val_pred2_mean_pred: 0.4523\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.13490\n",
      "Fold 3\n",
      "Build model...\n",
      "Model: \"model_13\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_19 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)               (None, 128, 128)           109952        input_19[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDropout1D (None, 128, 128)           0             embedding_15[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_181 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_14[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_114 (ReLU)                       (None, 128, 64)            0             conv1d_181[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_182 (Conv1D)                    (None, 128, 64)            12352         re_lu_114[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNormaliz (None, 128, 64)            256           conv1d_182[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_115 (ReLU)                       (None, 128, 64)            0             batch_normalization_170[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_183 (Conv1D)                    (None, 128, 64)            12352         re_lu_115[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNormaliz (None, 128, 64)            256           conv1d_183[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_116 (ReLU)                       (None, 128, 64)            0             batch_normalization_171[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_50 (Add)                           (None, 128, 64)            0             re_lu_116[0][0]                         \n",
      "                                                                                re_lu_114[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_184 (Conv1D)                    (None, 128, 64)            12352         add_50[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNormaliz (None, 128, 64)            256           conv1d_184[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_117 (ReLU)                       (None, 128, 64)            0             batch_normalization_172[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_185 (Conv1D)                    (None, 128, 64)            12352         re_lu_117[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNormaliz (None, 128, 64)            256           conv1d_185[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_118 (ReLU)                       (None, 128, 64)            0             batch_normalization_173[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_186 (Conv1D)                    (None, 64, 64)             4160          add_50[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D)        (None, 64, 64)             0             re_lu_118[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNormaliz (None, 64, 64)             256           conv1d_186[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_51 (Add)                           (None, 64, 64)             0             max_pooling1d_32[0][0]                  \n",
      "                                                                                batch_normalization_174[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_187 (Conv1D)                    (None, 64, 128)            8320          add_51[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNormaliz (None, 64, 128)            512           conv1d_187[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_188 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_175[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNormaliz (None, 64, 128)            512           conv1d_188[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_119 (ReLU)                       (None, 64, 128)            0             batch_normalization_176[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_189 (Conv1D)                    (None, 64, 128)            49280         re_lu_119[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNormaliz (None, 64, 128)            512           conv1d_189[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_120 (ReLU)                       (None, 64, 128)            0             batch_normalization_177[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_52 (Add)                           (None, 64, 128)            0             re_lu_120[0][0]                         \n",
      "                                                                                batch_normalization_175[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_190 (Conv1D)                    (None, 64, 128)            49280         add_52[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNormaliz (None, 64, 128)            512           conv1d_190[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_121 (ReLU)                       (None, 64, 128)            0             batch_normalization_178[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_191 (Conv1D)                    (None, 64, 128)            49280         re_lu_121[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNormaliz (None, 64, 128)            512           conv1d_191[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_122 (ReLU)                       (None, 64, 128)            0             batch_normalization_179[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_192 (Conv1D)                    (None, 32, 128)            16512         add_52[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D)        (None, 32, 128)            0             re_lu_122[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNormaliz (None, 32, 128)            512           conv1d_192[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_53 (Add)                           (None, 32, 128)            0             max_pooling1d_33[0][0]                  \n",
      "                                                                                batch_normalization_180[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_193 (Conv1D)                    (None, 32, 256)            33024         add_53[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNormaliz (None, 32, 256)            1024          conv1d_193[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_194 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_181[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNormaliz (None, 32, 256)            1024          conv1d_194[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_123 (ReLU)                       (None, 32, 256)            0             batch_normalization_182[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_195 (Conv1D)                    (None, 32, 256)            196864        re_lu_123[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNormaliz (None, 32, 256)            1024          conv1d_195[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_124 (ReLU)                       (None, 32, 256)            0             batch_normalization_183[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_54 (Add)                           (None, 32, 256)            0             re_lu_124[0][0]                         \n",
      "                                                                                batch_normalization_181[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_196 (Conv1D)                    (None, 32, 256)            196864        add_54[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNormaliz (None, 32, 256)            1024          conv1d_196[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_125 (ReLU)                       (None, 32, 256)            0             batch_normalization_184[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_197 (Conv1D)                    (None, 32, 256)            196864        re_lu_125[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNormaliz (None, 32, 256)            1024          conv1d_197[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_126 (ReLU)                       (None, 32, 256)            0             batch_normalization_185[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_198 (Conv1D)                    (None, 16, 256)            65792         add_54[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D)        (None, 16, 256)            0             re_lu_126[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNormaliz (None, 16, 256)            1024          conv1d_198[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_55 (Add)                           (None, 16, 256)            0             max_pooling1d_34[0][0]                  \n",
      "                                                                                batch_normalization_186[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_199 (Conv1D)                    (None, 16, 512)            131584        add_55[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNormaliz (None, 16, 512)            2048          conv1d_199[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_200 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_187[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNormaliz (None, 16, 512)            2048          conv1d_200[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_127 (ReLU)                       (None, 16, 512)            0             batch_normalization_188[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_201 (Conv1D)                    (None, 16, 512)            786944        re_lu_127[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchNormaliz (None, 16, 512)            2048          conv1d_201[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_128 (ReLU)                       (None, 16, 512)            0             batch_normalization_189[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_56 (Add)                           (None, 16, 512)            0             re_lu_128[0][0]                         \n",
      "                                                                                batch_normalization_187[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_202 (Conv1D)                    (None, 16, 512)            786944        add_56[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchNormaliz (None, 16, 512)            2048          conv1d_202[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_129 (ReLU)                       (None, 16, 512)            0             batch_normalization_190[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_203 (Conv1D)                    (None, 16, 512)            786944        re_lu_129[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchNormaliz (None, 16, 512)            2048          conv1d_203[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_130 (ReLU)                       (None, 16, 512)            0             batch_normalization_191[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_204 (Conv1D)                    (None, 8, 512)             262656        add_56[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D)        (None, 8, 512)             0             re_lu_130[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchNormaliz (None, 8, 512)             2048          conv1d_204[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_57 (Add)                           (None, 8, 512)             0             max_pooling1d_35[0][0]                  \n",
      "                                                                                batch_normalization_192[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_205 (Conv1D)                    (None, 8, 1024)            525312        add_57[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchNormaliz (None, 8, 1024)            4096          conv1d_205[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_8 (k_max_pooling)        (None, 2, 1024)            0             batch_normalization_193[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)                    (None, 2048)               0             k_max_pooling_8[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)                   (None, 2048)               0             flatten_7[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_11[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_11[0][0]                        \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 29s 161ms/step - loss: 0.4645 - pred1_loss: 0.2651 - pred2_loss: 0.1994 - pred1_accuracy: 0.1467 - pred1_mean_pred: 2.6506 - pred2_accuracy: 0.3692 - pred2_mean_pred: 1.9937 - val_loss: 0.3347 - val_pred1_loss: 0.1994 - val_pred2_loss: 0.1352 - val_pred1_accuracy: 0.1784 - val_pred1_mean_pred: 1.9905 - val_pred2_accuracy: 0.3120 - val_pred2_mean_pred: 1.3637\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33465, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 22s 163ms/step - loss: 0.2354 - pred1_loss: 0.1499 - pred2_loss: 0.0854 - pred1_accuracy: 0.2053 - pred1_mean_pred: 1.4995 - pred2_accuracy: 0.4697 - pred2_mean_pred: 0.8545 - val_loss: 0.3458 - val_pred1_loss: 0.1901 - val_pred2_loss: 0.1557 - val_pred1_accuracy: 0.0996 - val_pred1_mean_pred: 1.8990 - val_pred2_accuracy: 0.3888 - val_pred2_mean_pred: 1.5678\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.33465\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 23s 168ms/step - loss: 0.1880 - pred1_loss: 0.1238 - pred2_loss: 0.0642 - pred1_accuracy: 0.2180 - pred1_mean_pred: 1.2378 - pred2_accuracy: 0.5076 - pred2_mean_pred: 0.6421 - val_loss: 0.2189 - val_pred1_loss: 0.1303 - val_pred2_loss: 0.0886 - val_pred1_accuracy: 0.2236 - val_pred1_mean_pred: 1.3055 - val_pred2_accuracy: 0.4628 - val_pred2_mean_pred: 0.8939\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33465 to 0.21891, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 23s 168ms/step - loss: 0.1632 - pred1_loss: 0.1122 - pred2_loss: 0.0511 - pred1_accuracy: 0.2474 - pred1_mean_pred: 1.1218 - pred2_accuracy: 0.5028 - pred2_mean_pred: 0.5107 - val_loss: 0.1727 - val_pred1_loss: 0.1157 - val_pred2_loss: 0.0569 - val_pred1_accuracy: 0.2120 - val_pred1_mean_pred: 1.1592 - val_pred2_accuracy: 0.6112 - val_pred2_mean_pred: 0.5795\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21891 to 0.17266, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 23s 168ms/step - loss: 0.1437 - pred1_loss: 0.1005 - pred2_loss: 0.0433 - pred1_accuracy: 0.2514 - pred1_mean_pred: 1.0049 - pred2_accuracy: 0.5264 - pred2_mean_pred: 0.4326 - val_loss: 0.1668 - val_pred1_loss: 0.1038 - val_pred2_loss: 0.0630 - val_pred1_accuracy: 0.2608 - val_pred1_mean_pred: 1.0413 - val_pred2_accuracy: 0.4736 - val_pred2_mean_pred: 0.6379\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17266 to 0.16681, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 23s 168ms/step - loss: 0.1343 - pred1_loss: 0.0941 - pred2_loss: 0.0402 - pred1_accuracy: 0.2453 - pred1_mean_pred: 0.9405 - pred2_accuracy: 0.4961 - pred2_mean_pred: 0.4024 - val_loss: 0.1670 - val_pred1_loss: 0.1031 - val_pred2_loss: 0.0639 - val_pred1_accuracy: 0.2216 - val_pred1_mean_pred: 1.0330 - val_pred2_accuracy: 0.5896 - val_pred2_mean_pred: 0.6423\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16681\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 26s 190ms/step - loss: 0.1216 - pred1_loss: 0.0879 - pred2_loss: 0.0337 - pred1_accuracy: 0.2623 - pred1_mean_pred: 0.8790 - pred2_accuracy: 0.5361 - pred2_mean_pred: 0.3366 - val_loss: 0.1512 - val_pred1_loss: 0.0970 - val_pred2_loss: 0.0541 - val_pred1_accuracy: 0.2504 - val_pred1_mean_pred: 0.9731 - val_pred2_accuracy: 0.4628 - val_pred2_mean_pred: 0.5442\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16681 to 0.15119, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 26s 189ms/step - loss: 0.1112 - pred1_loss: 0.0808 - pred2_loss: 0.0303 - pred1_accuracy: 0.3292 - pred1_mean_pred: 0.8082 - pred2_accuracy: 0.5201 - pred2_mean_pred: 0.3034 - val_loss: 0.1454 - val_pred1_loss: 0.0937 - val_pred2_loss: 0.0517 - val_pred1_accuracy: 0.2448 - val_pred1_mean_pred: 0.9403 - val_pred2_accuracy: 0.4988 - val_pred2_mean_pred: 0.5321\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.15119 to 0.14543, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - 23s 169ms/step - loss: 0.1042 - pred1_loss: 0.0783 - pred2_loss: 0.0259 - pred1_accuracy: 0.2563 - pred1_mean_pred: 0.7835 - pred2_accuracy: 0.5898 - pred2_mean_pred: 0.2587 - val_loss: 0.1679 - val_pred1_loss: 0.1181 - val_pred2_loss: 0.0499 - val_pred1_accuracy: 0.2968 - val_pred1_mean_pred: 1.1810 - val_pred2_accuracy: 0.6944 - val_pred2_mean_pred: 0.5081\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.14543\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - 23s 170ms/step - loss: 0.1010 - pred1_loss: 0.0769 - pred2_loss: 0.0240 - pred1_accuracy: 0.2767 - pred1_mean_pred: 0.7694 - pred2_accuracy: 0.5729 - pred2_mean_pred: 0.2405 - val_loss: 0.1299 - val_pred1_loss: 0.0923 - val_pred2_loss: 0.0375 - val_pred1_accuracy: 0.2664 - val_pred1_mean_pred: 0.9282 - val_pred2_accuracy: 0.5140 - val_pred2_mean_pred: 0.3801\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14543 to 0.12989, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - 23s 167ms/step - loss: 0.0918 - pred1_loss: 0.0706 - pred2_loss: 0.0212 - pred1_accuracy: 0.3069 - pred1_mean_pred: 0.7060 - pred2_accuracy: 0.5263 - pred2_mean_pred: 0.2119 - val_loss: 0.1205 - val_pred1_loss: 0.0821 - val_pred2_loss: 0.0385 - val_pred1_accuracy: 0.4000 - val_pred1_mean_pred: 0.8213 - val_pred2_accuracy: 0.4704 - val_pred2_mean_pred: 0.3909\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.12989 to 0.12053, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 12/100\n",
      "137/137 [==============================] - 29s 210ms/step - loss: 0.0807 - pred1_loss: 0.0600 - pred2_loss: 0.0207 - pred1_accuracy: 0.3585 - pred1_mean_pred: 0.5995 - pred2_accuracy: 0.5398 - pred2_mean_pred: 0.2072 - val_loss: 0.1120 - val_pred1_loss: 0.0715 - val_pred2_loss: 0.0405 - val_pred1_accuracy: 0.3564 - val_pred1_mean_pred: 0.7186 - val_pred2_accuracy: 0.5120 - val_pred2_mean_pred: 0.4163\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.12053 to 0.11199, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 13/100\n",
      "137/137 [==============================] - 23s 165ms/step - loss: 0.0684 - pred1_loss: 0.0495 - pred2_loss: 0.0188 - pred1_accuracy: 0.3659 - pred1_mean_pred: 0.4954 - pred2_accuracy: 0.5327 - pred2_mean_pred: 0.1883 - val_loss: 0.1116 - val_pred1_loss: 0.0722 - val_pred2_loss: 0.0393 - val_pred1_accuracy: 0.3564 - val_pred1_mean_pred: 0.7270 - val_pred2_accuracy: 0.4824 - val_pred2_mean_pred: 0.4037\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.11199 to 0.11158, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 14/100\n",
      "137/137 [==============================] - 23s 170ms/step - loss: 0.0583 - pred1_loss: 0.0426 - pred2_loss: 0.0158 - pred1_accuracy: 0.3677 - pred1_mean_pred: 0.4256 - pred2_accuracy: 0.5577 - pred2_mean_pred: 0.1578 - val_loss: 0.1170 - val_pred1_loss: 0.0667 - val_pred2_loss: 0.0503 - val_pred1_accuracy: 0.3500 - val_pred1_mean_pred: 0.6692 - val_pred2_accuracy: 0.5448 - val_pred2_mean_pred: 0.5121\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.11158\n",
      "Epoch 15/100\n",
      "137/137 [==============================] - 23s 170ms/step - loss: 0.0581 - pred1_loss: 0.0405 - pred2_loss: 0.0175 - pred1_accuracy: 0.3794 - pred1_mean_pred: 0.4052 - pred2_accuracy: 0.5673 - pred2_mean_pred: 0.1754 - val_loss: 0.0996 - val_pred1_loss: 0.0601 - val_pred2_loss: 0.0395 - val_pred1_accuracy: 0.4028 - val_pred1_mean_pred: 0.6013 - val_pred2_accuracy: 0.4920 - val_pred2_mean_pred: 0.4003\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.11158 to 0.09960, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 16/100\n",
      "137/137 [==============================] - 23s 171ms/step - loss: 0.0529 - pred1_loss: 0.0371 - pred2_loss: 0.0159 - pred1_accuracy: 0.3734 - pred1_mean_pred: 0.3706 - pred2_accuracy: 0.5395 - pred2_mean_pred: 0.1587 - val_loss: 0.0916 - val_pred1_loss: 0.0565 - val_pred2_loss: 0.0351 - val_pred1_accuracy: 0.4284 - val_pred1_mean_pred: 0.5645 - val_pred2_accuracy: 0.5028 - val_pred2_mean_pred: 0.3607\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09960 to 0.09160, saving model to ../model_weight/V2_3.h5\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 23s 170ms/step - loss: 0.0426 - pred1_loss: 0.0311 - pred2_loss: 0.0115 - pred1_accuracy: 0.3699 - pred1_mean_pred: 0.3114 - pred2_accuracy: 0.5361 - pred2_mean_pred: 0.1148 - val_loss: 0.1088 - val_pred1_loss: 0.0647 - val_pred2_loss: 0.0441 - val_pred1_accuracy: 0.3728 - val_pred1_mean_pred: 0.6546 - val_pred2_accuracy: 0.4744 - val_pred2_mean_pred: 0.4496\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09160\n",
      "Epoch 18/100\n",
      "137/137 [==============================] - 23s 171ms/step - loss: 0.0425 - pred1_loss: 0.0300 - pred2_loss: 0.0126 - pred1_accuracy: 0.3769 - pred1_mean_pred: 0.2997 - pred2_accuracy: 0.5278 - pred2_mean_pred: 0.1257 - val_loss: 0.0921 - val_pred1_loss: 0.0548 - val_pred2_loss: 0.0373 - val_pred1_accuracy: 0.3380 - val_pred1_mean_pred: 0.5556 - val_pred2_accuracy: 0.6448 - val_pred2_mean_pred: 0.3835\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.09160\n",
      "Fold 4\n",
      "Build model...\n",
      "Model: \"model_14\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_20 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)               (None, 128, 128)           109952        input_20[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDropout1D (None, 128, 128)           0             embedding_16[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_206 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_15[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_131 (ReLU)                       (None, 128, 64)            0             conv1d_206[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_207 (Conv1D)                    (None, 128, 64)            12352         re_lu_131[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchNormaliz (None, 128, 64)            256           conv1d_207[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_132 (ReLU)                       (None, 128, 64)            0             batch_normalization_194[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_208 (Conv1D)                    (None, 128, 64)            12352         re_lu_132[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchNormaliz (None, 128, 64)            256           conv1d_208[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_133 (ReLU)                       (None, 128, 64)            0             batch_normalization_195[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_58 (Add)                           (None, 128, 64)            0             re_lu_133[0][0]                         \n",
      "                                                                                re_lu_131[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_209 (Conv1D)                    (None, 128, 64)            12352         add_58[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchNormaliz (None, 128, 64)            256           conv1d_209[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_134 (ReLU)                       (None, 128, 64)            0             batch_normalization_196[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_210 (Conv1D)                    (None, 128, 64)            12352         re_lu_134[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchNormaliz (None, 128, 64)            256           conv1d_210[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_135 (ReLU)                       (None, 128, 64)            0             batch_normalization_197[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_211 (Conv1D)                    (None, 64, 64)             4160          add_58[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D)        (None, 64, 64)             0             re_lu_135[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchNormaliz (None, 64, 64)             256           conv1d_211[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_59 (Add)                           (None, 64, 64)             0             max_pooling1d_36[0][0]                  \n",
      "                                                                                batch_normalization_198[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_212 (Conv1D)                    (None, 64, 128)            8320          add_59[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchNormaliz (None, 64, 128)            512           conv1d_212[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_213 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_199[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchNormaliz (None, 64, 128)            512           conv1d_213[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_136 (ReLU)                       (None, 64, 128)            0             batch_normalization_200[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_214 (Conv1D)                    (None, 64, 128)            49280         re_lu_136[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchNormaliz (None, 64, 128)            512           conv1d_214[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_137 (ReLU)                       (None, 64, 128)            0             batch_normalization_201[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_60 (Add)                           (None, 64, 128)            0             re_lu_137[0][0]                         \n",
      "                                                                                batch_normalization_199[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_215 (Conv1D)                    (None, 64, 128)            49280         add_60[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchNormaliz (None, 64, 128)            512           conv1d_215[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_138 (ReLU)                       (None, 64, 128)            0             batch_normalization_202[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_216 (Conv1D)                    (None, 64, 128)            49280         re_lu_138[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchNormaliz (None, 64, 128)            512           conv1d_216[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_139 (ReLU)                       (None, 64, 128)            0             batch_normalization_203[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_217 (Conv1D)                    (None, 32, 128)            16512         add_60[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D)        (None, 32, 128)            0             re_lu_139[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchNormaliz (None, 32, 128)            512           conv1d_217[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_61 (Add)                           (None, 32, 128)            0             max_pooling1d_37[0][0]                  \n",
      "                                                                                batch_normalization_204[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_218 (Conv1D)                    (None, 32, 256)            33024         add_61[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchNormaliz (None, 32, 256)            1024          conv1d_218[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_219 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_205[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchNormaliz (None, 32, 256)            1024          conv1d_219[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_140 (ReLU)                       (None, 32, 256)            0             batch_normalization_206[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_220 (Conv1D)                    (None, 32, 256)            196864        re_lu_140[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchNormaliz (None, 32, 256)            1024          conv1d_220[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_141 (ReLU)                       (None, 32, 256)            0             batch_normalization_207[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_62 (Add)                           (None, 32, 256)            0             re_lu_141[0][0]                         \n",
      "                                                                                batch_normalization_205[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_221 (Conv1D)                    (None, 32, 256)            196864        add_62[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchNormaliz (None, 32, 256)            1024          conv1d_221[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_142 (ReLU)                       (None, 32, 256)            0             batch_normalization_208[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_222 (Conv1D)                    (None, 32, 256)            196864        re_lu_142[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchNormaliz (None, 32, 256)            1024          conv1d_222[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_143 (ReLU)                       (None, 32, 256)            0             batch_normalization_209[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_223 (Conv1D)                    (None, 16, 256)            65792         add_62[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D)        (None, 16, 256)            0             re_lu_143[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchNormaliz (None, 16, 256)            1024          conv1d_223[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_63 (Add)                           (None, 16, 256)            0             max_pooling1d_38[0][0]                  \n",
      "                                                                                batch_normalization_210[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_224 (Conv1D)                    (None, 16, 512)            131584        add_63[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchNormaliz (None, 16, 512)            2048          conv1d_224[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_225 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_211[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchNormaliz (None, 16, 512)            2048          conv1d_225[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_144 (ReLU)                       (None, 16, 512)            0             batch_normalization_212[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_226 (Conv1D)                    (None, 16, 512)            786944        re_lu_144[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchNormaliz (None, 16, 512)            2048          conv1d_226[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_145 (ReLU)                       (None, 16, 512)            0             batch_normalization_213[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_64 (Add)                           (None, 16, 512)            0             re_lu_145[0][0]                         \n",
      "                                                                                batch_normalization_211[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_227 (Conv1D)                    (None, 16, 512)            786944        add_64[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchNormaliz (None, 16, 512)            2048          conv1d_227[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_146 (ReLU)                       (None, 16, 512)            0             batch_normalization_214[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_228 (Conv1D)                    (None, 16, 512)            786944        re_lu_146[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchNormaliz (None, 16, 512)            2048          conv1d_228[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_147 (ReLU)                       (None, 16, 512)            0             batch_normalization_215[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_229 (Conv1D)                    (None, 8, 512)             262656        add_64[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D)        (None, 8, 512)             0             re_lu_147[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchNormaliz (None, 8, 512)             2048          conv1d_229[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_65 (Add)                           (None, 8, 512)             0             max_pooling1d_39[0][0]                  \n",
      "                                                                                batch_normalization_216[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_230 (Conv1D)                    (None, 8, 1024)            525312        add_65[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchNormaliz (None, 8, 1024)            4096          conv1d_230[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_9 (k_max_pooling)        (None, 2, 1024)            0             batch_normalization_217[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)                    (None, 2048)               0             k_max_pooling_9[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)                   (None, 2048)               0             flatten_8[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_12[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_12[0][0]                        \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 30s 164ms/step - loss: 0.4514 - pred1_loss: 0.2562 - pred2_loss: 0.1952 - pred1_accuracy: 0.1613 - pred1_mean_pred: 2.5621 - pred2_accuracy: 0.3502 - pred2_mean_pred: 1.9510 - val_loss: 0.3844 - val_pred1_loss: 0.2444 - val_pred2_loss: 0.1399 - val_pred1_accuracy: 0.2392 - val_pred1_mean_pred: 2.4496 - val_pred2_accuracy: 0.4952 - val_pred2_mean_pred: 1.4006\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38437, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 23s 167ms/step - loss: 0.2294 - pred1_loss: 0.1455 - pred2_loss: 0.0839 - pred1_accuracy: 0.2090 - pred1_mean_pred: 1.4551 - pred2_accuracy: 0.4664 - pred2_mean_pred: 0.8388 - val_loss: 0.2731 - val_pred1_loss: 0.1549 - val_pred2_loss: 0.1182 - val_pred1_accuracy: 0.1800 - val_pred1_mean_pred: 1.5536 - val_pred2_accuracy: 0.3616 - val_pred2_mean_pred: 1.1809\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38437 to 0.27309, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 23s 170ms/step - loss: 0.1879 - pred1_loss: 0.1232 - pred2_loss: 0.0647 - pred1_accuracy: 0.2492 - pred1_mean_pred: 1.2320 - pred2_accuracy: 0.4999 - pred2_mean_pred: 0.6468 - val_loss: 0.1700 - val_pred1_loss: 0.1184 - val_pred2_loss: 0.0516 - val_pred1_accuracy: 0.4540 - val_pred1_mean_pred: 1.1877 - val_pred2_accuracy: 0.4656 - val_pred2_mean_pred: 0.5168\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27309 to 0.17003, saving model to ../model_weight/V2_4.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 23s 169ms/step - loss: 0.1582 - pred1_loss: 0.1078 - pred2_loss: 0.0505 - pred1_accuracy: 0.2867 - pred1_mean_pred: 1.0776 - pred2_accuracy: 0.4971 - pred2_mean_pred: 0.5047 - val_loss: 0.2400 - val_pred1_loss: 0.1349 - val_pred2_loss: 0.1051 - val_pred1_accuracy: 0.5280 - val_pred1_mean_pred: 1.3547 - val_pred2_accuracy: 0.5476 - val_pred2_mean_pred: 1.0559\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17003\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 26s 190ms/step - loss: 0.1465 - pred1_loss: 0.1008 - pred2_loss: 0.0457 - pred1_accuracy: 0.3556 - pred1_mean_pred: 1.0076 - pred2_accuracy: 0.5047 - pred2_mean_pred: 0.4572 - val_loss: 0.1756 - val_pred1_loss: 0.1167 - val_pred2_loss: 0.0590 - val_pred1_accuracy: 0.3916 - val_pred1_mean_pred: 1.1749 - val_pred2_accuracy: 0.5072 - val_pred2_mean_pred: 0.5921\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17003\n",
      "Fold 5\n",
      "Build model...\n",
      "Model: \"model_15\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_21 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)               (None, 128, 128)           109952        input_21[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDropout1D (None, 128, 128)           0             embedding_17[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_231 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_16[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_148 (ReLU)                       (None, 128, 64)            0             conv1d_231[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_232 (Conv1D)                    (None, 128, 64)            12352         re_lu_148[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchNormaliz (None, 128, 64)            256           conv1d_232[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_149 (ReLU)                       (None, 128, 64)            0             batch_normalization_218[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_233 (Conv1D)                    (None, 128, 64)            12352         re_lu_149[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchNormaliz (None, 128, 64)            256           conv1d_233[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_150 (ReLU)                       (None, 128, 64)            0             batch_normalization_219[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_66 (Add)                           (None, 128, 64)            0             re_lu_150[0][0]                         \n",
      "                                                                                re_lu_148[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_234 (Conv1D)                    (None, 128, 64)            12352         add_66[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchNormaliz (None, 128, 64)            256           conv1d_234[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_151 (ReLU)                       (None, 128, 64)            0             batch_normalization_220[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_235 (Conv1D)                    (None, 128, 64)            12352         re_lu_151[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchNormaliz (None, 128, 64)            256           conv1d_235[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_152 (ReLU)                       (None, 128, 64)            0             batch_normalization_221[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_236 (Conv1D)                    (None, 64, 64)             4160          add_66[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D)        (None, 64, 64)             0             re_lu_152[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchNormaliz (None, 64, 64)             256           conv1d_236[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_67 (Add)                           (None, 64, 64)             0             max_pooling1d_40[0][0]                  \n",
      "                                                                                batch_normalization_222[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_237 (Conv1D)                    (None, 64, 128)            8320          add_67[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchNormaliz (None, 64, 128)            512           conv1d_237[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_238 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_223[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchNormaliz (None, 64, 128)            512           conv1d_238[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_153 (ReLU)                       (None, 64, 128)            0             batch_normalization_224[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_239 (Conv1D)                    (None, 64, 128)            49280         re_lu_153[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchNormaliz (None, 64, 128)            512           conv1d_239[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_154 (ReLU)                       (None, 64, 128)            0             batch_normalization_225[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_68 (Add)                           (None, 64, 128)            0             re_lu_154[0][0]                         \n",
      "                                                                                batch_normalization_223[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_240 (Conv1D)                    (None, 64, 128)            49280         add_68[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchNormaliz (None, 64, 128)            512           conv1d_240[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_155 (ReLU)                       (None, 64, 128)            0             batch_normalization_226[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_241 (Conv1D)                    (None, 64, 128)            49280         re_lu_155[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchNormaliz (None, 64, 128)            512           conv1d_241[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_156 (ReLU)                       (None, 64, 128)            0             batch_normalization_227[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_242 (Conv1D)                    (None, 32, 128)            16512         add_68[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D)        (None, 32, 128)            0             re_lu_156[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchNormaliz (None, 32, 128)            512           conv1d_242[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_69 (Add)                           (None, 32, 128)            0             max_pooling1d_41[0][0]                  \n",
      "                                                                                batch_normalization_228[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_243 (Conv1D)                    (None, 32, 256)            33024         add_69[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchNormaliz (None, 32, 256)            1024          conv1d_243[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_244 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_229[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchNormaliz (None, 32, 256)            1024          conv1d_244[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_157 (ReLU)                       (None, 32, 256)            0             batch_normalization_230[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_245 (Conv1D)                    (None, 32, 256)            196864        re_lu_157[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchNormaliz (None, 32, 256)            1024          conv1d_245[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_158 (ReLU)                       (None, 32, 256)            0             batch_normalization_231[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_70 (Add)                           (None, 32, 256)            0             re_lu_158[0][0]                         \n",
      "                                                                                batch_normalization_229[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_246 (Conv1D)                    (None, 32, 256)            196864        add_70[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchNormaliz (None, 32, 256)            1024          conv1d_246[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_159 (ReLU)                       (None, 32, 256)            0             batch_normalization_232[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_247 (Conv1D)                    (None, 32, 256)            196864        re_lu_159[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchNormaliz (None, 32, 256)            1024          conv1d_247[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_160 (ReLU)                       (None, 32, 256)            0             batch_normalization_233[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_248 (Conv1D)                    (None, 16, 256)            65792         add_70[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D)        (None, 16, 256)            0             re_lu_160[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchNormaliz (None, 16, 256)            1024          conv1d_248[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_71 (Add)                           (None, 16, 256)            0             max_pooling1d_42[0][0]                  \n",
      "                                                                                batch_normalization_234[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_249 (Conv1D)                    (None, 16, 512)            131584        add_71[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchNormaliz (None, 16, 512)            2048          conv1d_249[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_250 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_235[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchNormaliz (None, 16, 512)            2048          conv1d_250[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_161 (ReLU)                       (None, 16, 512)            0             batch_normalization_236[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_251 (Conv1D)                    (None, 16, 512)            786944        re_lu_161[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchNormaliz (None, 16, 512)            2048          conv1d_251[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_162 (ReLU)                       (None, 16, 512)            0             batch_normalization_237[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_72 (Add)                           (None, 16, 512)            0             re_lu_162[0][0]                         \n",
      "                                                                                batch_normalization_235[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_252 (Conv1D)                    (None, 16, 512)            786944        add_72[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchNormaliz (None, 16, 512)            2048          conv1d_252[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_163 (ReLU)                       (None, 16, 512)            0             batch_normalization_238[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_253 (Conv1D)                    (None, 16, 512)            786944        re_lu_163[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchNormaliz (None, 16, 512)            2048          conv1d_253[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_164 (ReLU)                       (None, 16, 512)            0             batch_normalization_239[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_254 (Conv1D)                    (None, 8, 512)             262656        add_72[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D)        (None, 8, 512)             0             re_lu_164[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchNormaliz (None, 8, 512)             2048          conv1d_254[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_73 (Add)                           (None, 8, 512)             0             max_pooling1d_43[0][0]                  \n",
      "                                                                                batch_normalization_240[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_255 (Conv1D)                    (None, 8, 1024)            525312        add_73[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchNormaliz (None, 8, 1024)            4096          conv1d_255[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_10 (k_max_pooling)       (None, 2, 1024)            0             batch_normalization_241[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)                    (None, 2048)               0             k_max_pooling_10[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)                   (None, 2048)               0             flatten_9[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_13[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_13[0][0]                        \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 30s 162ms/step - loss: 0.4901 - pred1_loss: 0.2919 - pred2_loss: 0.1982 - pred1_accuracy: 0.1320 - pred1_mean_pred: 2.9185 - pred2_accuracy: 0.3556 - pred2_mean_pred: 1.9820 - val_loss: 0.3388 - val_pred1_loss: 0.2039 - val_pred2_loss: 0.1349 - val_pred1_accuracy: 0.0968 - val_pred1_mean_pred: 2.0296 - val_pred2_accuracy: 0.4376 - val_pred2_mean_pred: 1.3452\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33878, saving model to ../model_weight/V2_5.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 23s 165ms/step - loss: 0.2358 - pred1_loss: 0.1495 - pred2_loss: 0.0864 - pred1_accuracy: 0.1948 - pred1_mean_pred: 1.4945 - pred2_accuracy: 0.4750 - pred2_mean_pred: 0.8635 - val_loss: 0.2553 - val_pred1_loss: 0.1582 - val_pred2_loss: 0.0972 - val_pred1_accuracy: 0.1572 - val_pred1_mean_pred: 1.5725 - val_pred2_accuracy: 0.4784 - val_pred2_mean_pred: 0.9680\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33878 to 0.25533, saving model to ../model_weight/V2_5.h5\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 27s 194ms/step - loss: 0.1898 - pred1_loss: 0.1238 - pred2_loss: 0.0661 - pred1_accuracy: 0.2187 - pred1_mean_pred: 1.2377 - pred2_accuracy: 0.4888 - pred2_mean_pred: 0.6606 - val_loss: 0.2041 - val_pred1_loss: 0.1318 - val_pred2_loss: 0.0723 - val_pred1_accuracy: 0.2760 - val_pred1_mean_pred: 1.3095 - val_pred2_accuracy: 0.5556 - val_pred2_mean_pred: 0.7165\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25533 to 0.20408, saving model to ../model_weight/V2_5.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 24s 172ms/step - loss: 0.1655 - pred1_loss: 0.1118 - pred2_loss: 0.0536 - pred1_accuracy: 0.2428 - pred1_mean_pred: 1.1184 - pred2_accuracy: 0.5058 - pred2_mean_pred: 0.5361 - val_loss: 0.1738 - val_pred1_loss: 0.1203 - val_pred2_loss: 0.0535 - val_pred1_accuracy: 0.3236 - val_pred1_mean_pred: 1.1944 - val_pred2_accuracy: 0.5452 - val_pred2_mean_pred: 0.5295\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20408 to 0.17376, saving model to ../model_weight/V2_5.h5\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 24s 173ms/step - loss: 0.1418 - pred1_loss: 0.0983 - pred2_loss: 0.0435 - pred1_accuracy: 0.2757 - pred1_mean_pred: 0.9829 - pred2_accuracy: 0.5561 - pred2_mean_pred: 0.4347 - val_loss: 0.1581 - val_pred1_loss: 0.1094 - val_pred2_loss: 0.0487 - val_pred1_accuracy: 0.1976 - val_pred1_mean_pred: 1.0884 - val_pred2_accuracy: 0.4980 - val_pred2_mean_pred: 0.4809\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17376 to 0.15810, saving model to ../model_weight/V2_5.h5\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 24s 173ms/step - loss: 0.1299 - pred1_loss: 0.0912 - pred2_loss: 0.0387 - pred1_accuracy: 0.2611 - pred1_mean_pred: 0.9122 - pred2_accuracy: 0.5202 - pred2_mean_pred: 0.3868 - val_loss: 0.1341 - val_pred1_loss: 0.0947 - val_pred2_loss: 0.0394 - val_pred1_accuracy: 0.3048 - val_pred1_mean_pred: 0.9421 - val_pred2_accuracy: 0.5244 - val_pred2_mean_pred: 0.3929\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15810 to 0.13407, saving model to ../model_weight/V2_5.h5\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 23s 171ms/step - loss: 0.1211 - pred1_loss: 0.0880 - pred2_loss: 0.0331 - pred1_accuracy: 0.2846 - pred1_mean_pred: 0.8803 - pred2_accuracy: 0.5603 - pred2_mean_pred: 0.3308 - val_loss: 0.1549 - val_pred1_loss: 0.1048 - val_pred2_loss: 0.0501 - val_pred1_accuracy: 0.2288 - val_pred1_mean_pred: 1.0423 - val_pred2_accuracy: 0.5040 - val_pred2_mean_pred: 0.4991\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13407\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 22s 163ms/step - loss: 0.1123 - pred1_loss: 0.0819 - pred2_loss: 0.0303 - pred1_accuracy: 0.2712 - pred1_mean_pred: 0.8193 - pred2_accuracy: 0.5592 - pred2_mean_pred: 0.3033 - val_loss: 0.1627 - val_pred1_loss: 0.1156 - val_pred2_loss: 0.0470 - val_pred1_accuracy: 0.2452 - val_pred1_mean_pred: 1.1501 - val_pred2_accuracy: 0.4900 - val_pred2_mean_pred: 0.4652\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13407\n",
      "Fold 6\n",
      "Build model...\n",
      "Model: \"model_16\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_22 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)               (None, 128, 128)           109952        input_22[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDropout1D (None, 128, 128)           0             embedding_18[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_256 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_17[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_165 (ReLU)                       (None, 128, 64)            0             conv1d_256[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_257 (Conv1D)                    (None, 128, 64)            12352         re_lu_165[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchNormaliz (None, 128, 64)            256           conv1d_257[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_166 (ReLU)                       (None, 128, 64)            0             batch_normalization_242[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_258 (Conv1D)                    (None, 128, 64)            12352         re_lu_166[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchNormaliz (None, 128, 64)            256           conv1d_258[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_167 (ReLU)                       (None, 128, 64)            0             batch_normalization_243[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_74 (Add)                           (None, 128, 64)            0             re_lu_167[0][0]                         \n",
      "                                                                                re_lu_165[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_259 (Conv1D)                    (None, 128, 64)            12352         add_74[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchNormaliz (None, 128, 64)            256           conv1d_259[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_168 (ReLU)                       (None, 128, 64)            0             batch_normalization_244[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_260 (Conv1D)                    (None, 128, 64)            12352         re_lu_168[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchNormaliz (None, 128, 64)            256           conv1d_260[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_169 (ReLU)                       (None, 128, 64)            0             batch_normalization_245[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_261 (Conv1D)                    (None, 64, 64)             4160          add_74[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D)        (None, 64, 64)             0             re_lu_169[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchNormaliz (None, 64, 64)             256           conv1d_261[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_75 (Add)                           (None, 64, 64)             0             max_pooling1d_44[0][0]                  \n",
      "                                                                                batch_normalization_246[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_262 (Conv1D)                    (None, 64, 128)            8320          add_75[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchNormaliz (None, 64, 128)            512           conv1d_262[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_263 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_247[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchNormaliz (None, 64, 128)            512           conv1d_263[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_170 (ReLU)                       (None, 64, 128)            0             batch_normalization_248[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_264 (Conv1D)                    (None, 64, 128)            49280         re_lu_170[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchNormaliz (None, 64, 128)            512           conv1d_264[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_171 (ReLU)                       (None, 64, 128)            0             batch_normalization_249[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_76 (Add)                           (None, 64, 128)            0             re_lu_171[0][0]                         \n",
      "                                                                                batch_normalization_247[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_265 (Conv1D)                    (None, 64, 128)            49280         add_76[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchNormaliz (None, 64, 128)            512           conv1d_265[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_172 (ReLU)                       (None, 64, 128)            0             batch_normalization_250[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_266 (Conv1D)                    (None, 64, 128)            49280         re_lu_172[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchNormaliz (None, 64, 128)            512           conv1d_266[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_173 (ReLU)                       (None, 64, 128)            0             batch_normalization_251[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_267 (Conv1D)                    (None, 32, 128)            16512         add_76[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D)        (None, 32, 128)            0             re_lu_173[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchNormaliz (None, 32, 128)            512           conv1d_267[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_77 (Add)                           (None, 32, 128)            0             max_pooling1d_45[0][0]                  \n",
      "                                                                                batch_normalization_252[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_268 (Conv1D)                    (None, 32, 256)            33024         add_77[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchNormaliz (None, 32, 256)            1024          conv1d_268[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_269 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_253[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchNormaliz (None, 32, 256)            1024          conv1d_269[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_174 (ReLU)                       (None, 32, 256)            0             batch_normalization_254[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_270 (Conv1D)                    (None, 32, 256)            196864        re_lu_174[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchNormaliz (None, 32, 256)            1024          conv1d_270[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_175 (ReLU)                       (None, 32, 256)            0             batch_normalization_255[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_78 (Add)                           (None, 32, 256)            0             re_lu_175[0][0]                         \n",
      "                                                                                batch_normalization_253[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_271 (Conv1D)                    (None, 32, 256)            196864        add_78[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchNormaliz (None, 32, 256)            1024          conv1d_271[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_176 (ReLU)                       (None, 32, 256)            0             batch_normalization_256[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_272 (Conv1D)                    (None, 32, 256)            196864        re_lu_176[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchNormaliz (None, 32, 256)            1024          conv1d_272[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_177 (ReLU)                       (None, 32, 256)            0             batch_normalization_257[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_273 (Conv1D)                    (None, 16, 256)            65792         add_78[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D)        (None, 16, 256)            0             re_lu_177[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchNormaliz (None, 16, 256)            1024          conv1d_273[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_79 (Add)                           (None, 16, 256)            0             max_pooling1d_46[0][0]                  \n",
      "                                                                                batch_normalization_258[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_274 (Conv1D)                    (None, 16, 512)            131584        add_79[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchNormaliz (None, 16, 512)            2048          conv1d_274[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_275 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_259[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchNormaliz (None, 16, 512)            2048          conv1d_275[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_178 (ReLU)                       (None, 16, 512)            0             batch_normalization_260[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_276 (Conv1D)                    (None, 16, 512)            786944        re_lu_178[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchNormaliz (None, 16, 512)            2048          conv1d_276[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_179 (ReLU)                       (None, 16, 512)            0             batch_normalization_261[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_80 (Add)                           (None, 16, 512)            0             re_lu_179[0][0]                         \n",
      "                                                                                batch_normalization_259[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_277 (Conv1D)                    (None, 16, 512)            786944        add_80[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchNormaliz (None, 16, 512)            2048          conv1d_277[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_180 (ReLU)                       (None, 16, 512)            0             batch_normalization_262[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_278 (Conv1D)                    (None, 16, 512)            786944        re_lu_180[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchNormaliz (None, 16, 512)            2048          conv1d_278[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_181 (ReLU)                       (None, 16, 512)            0             batch_normalization_263[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_279 (Conv1D)                    (None, 8, 512)             262656        add_80[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D)        (None, 8, 512)             0             re_lu_181[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchNormaliz (None, 8, 512)             2048          conv1d_279[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_81 (Add)                           (None, 8, 512)             0             max_pooling1d_47[0][0]                  \n",
      "                                                                                batch_normalization_264[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_280 (Conv1D)                    (None, 8, 1024)            525312        add_81[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchNormaliz (None, 8, 1024)            4096          conv1d_280[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_11 (k_max_pooling)       (None, 2, 1024)            0             batch_normalization_265[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)                   (None, 2048)               0             k_max_pooling_11[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)                   (None, 2048)               0             flatten_10[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_14[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_14[0][0]                        \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 35s 197ms/step - loss: 0.4633 - pred1_loss: 0.2679 - pred2_loss: 0.1954 - pred1_accuracy: 0.1718 - pred1_mean_pred: 2.6760 - pred2_accuracy: 0.3593 - pred2_mean_pred: 1.9524 - val_loss: 0.4349 - val_pred1_loss: 0.2814 - val_pred2_loss: 0.1535 - val_pred1_accuracy: 0.5632 - val_pred1_mean_pred: 2.8203 - val_pred2_accuracy: 0.3692 - val_pred2_mean_pred: 1.5354\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43491, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 23s 169ms/step - loss: 0.2521 - pred1_loss: 0.1566 - pred2_loss: 0.0955 - pred1_accuracy: 0.1882 - pred1_mean_pred: 1.5657 - pred2_accuracy: 0.4572 - pred2_mean_pred: 0.9553 - val_loss: 0.2668 - val_pred1_loss: 0.1608 - val_pred2_loss: 0.1061 - val_pred1_accuracy: 0.2148 - val_pred1_mean_pred: 1.6092 - val_pred2_accuracy: 0.4436 - val_pred2_mean_pred: 1.0587\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43491 to 0.26684, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 25s 180ms/step - loss: 0.1983 - pred1_loss: 0.1315 - pred2_loss: 0.0669 - pred1_accuracy: 0.2207 - pred1_mean_pred: 1.3145 - pred2_accuracy: 0.4879 - pred2_mean_pred: 0.6686 - val_loss: 0.1760 - val_pred1_loss: 0.1225 - val_pred2_loss: 0.0535 - val_pred1_accuracy: 0.3268 - val_pred1_mean_pred: 1.2277 - val_pred2_accuracy: 0.4924 - val_pred2_mean_pred: 0.5366\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26684 to 0.17604, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 25s 180ms/step - loss: 0.1676 - pred1_loss: 0.1150 - pred2_loss: 0.0526 - pred1_accuracy: 0.2353 - pred1_mean_pred: 1.1503 - pred2_accuracy: 0.4953 - pred2_mean_pred: 0.5261 - val_loss: 0.1603 - val_pred1_loss: 0.1093 - val_pred2_loss: 0.0509 - val_pred1_accuracy: 0.2492 - val_pred1_mean_pred: 1.0968 - val_pred2_accuracy: 0.5100 - val_pred2_mean_pred: 0.5093\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17604 to 0.16028, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 22s 164ms/step - loss: 0.1466 - pred1_loss: 0.1027 - pred2_loss: 0.0439 - pred1_accuracy: 0.2883 - pred1_mean_pred: 1.0272 - pred2_accuracy: 0.5200 - pred2_mean_pred: 0.4387 - val_loss: 0.1595 - val_pred1_loss: 0.1083 - val_pred2_loss: 0.0513 - val_pred1_accuracy: 0.2736 - val_pred1_mean_pred: 1.0871 - val_pred2_accuracy: 0.4812 - val_pred2_mean_pred: 0.5112\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16028 to 0.15953, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 23s 164ms/step - loss: 0.1370 - pred1_loss: 0.0959 - pred2_loss: 0.0411 - pred1_accuracy: 0.2738 - pred1_mean_pred: 0.9590 - pred2_accuracy: 0.5015 - pred2_mean_pred: 0.4109 - val_loss: 0.1970 - val_pred1_loss: 0.1343 - val_pred2_loss: 0.0626 - val_pred1_accuracy: 0.2928 - val_pred1_mean_pred: 1.3505 - val_pred2_accuracy: 0.4792 - val_pred2_mean_pred: 0.6223\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.15953\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 23s 164ms/step - loss: 0.1247 - pred1_loss: 0.0891 - pred2_loss: 0.0356 - pred1_accuracy: 0.2869 - pred1_mean_pred: 0.8908 - pred2_accuracy: 0.5232 - pred2_mean_pred: 0.3562 - val_loss: 0.1269 - val_pred1_loss: 0.0849 - val_pred2_loss: 0.0419 - val_pred1_accuracy: 0.2576 - val_pred1_mean_pred: 0.8482 - val_pred2_accuracy: 0.4892 - val_pred2_mean_pred: 0.4198\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15953 to 0.12686, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 8/100\n",
      "137/137 [==============================] - 23s 165ms/step - loss: 0.1036 - pred1_loss: 0.0703 - pred2_loss: 0.0333 - pred1_accuracy: 0.3546 - pred1_mean_pred: 0.7032 - pred2_accuracy: 0.5207 - pred2_mean_pred: 0.3325 - val_loss: 0.1127 - val_pred1_loss: 0.0709 - val_pred2_loss: 0.0418 - val_pred1_accuracy: 0.3656 - val_pred1_mean_pred: 0.7048 - val_pred2_accuracy: 0.4952 - val_pred2_mean_pred: 0.4167\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12686 to 0.11272, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 9/100\n",
      "137/137 [==============================] - 23s 170ms/step - loss: 0.0880 - pred1_loss: 0.0591 - pred2_loss: 0.0289 - pred1_accuracy: 0.3677 - pred1_mean_pred: 0.5910 - pred2_accuracy: 0.5498 - pred2_mean_pred: 0.2893 - val_loss: 0.1025 - val_pred1_loss: 0.0615 - val_pred2_loss: 0.0411 - val_pred1_accuracy: 0.3296 - val_pred1_mean_pred: 0.6104 - val_pred2_accuracy: 0.4964 - val_pred2_mean_pred: 0.4100\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11272 to 0.10252, saving model to ../model_weight/V2_6.h5\n",
      "Epoch 10/100\n",
      "137/137 [==============================] - 23s 168ms/step - loss: 0.0827 - pred1_loss: 0.0539 - pred2_loss: 0.0288 - pred1_accuracy: 0.3783 - pred1_mean_pred: 0.5393 - pred2_accuracy: 0.5223 - pred2_mean_pred: 0.2876 - val_loss: 0.1137 - val_pred1_loss: 0.0655 - val_pred2_loss: 0.0482 - val_pred1_accuracy: 0.3904 - val_pred1_mean_pred: 0.6537 - val_pred2_accuracy: 0.4544 - val_pred2_mean_pred: 0.4754\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10252\n",
      "Epoch 11/100\n",
      "137/137 [==============================] - 28s 206ms/step - loss: 0.0705 - pred1_loss: 0.0484 - pred2_loss: 0.0222 - pred1_accuracy: 0.3821 - pred1_mean_pred: 0.4836 - pred2_accuracy: 0.5233 - pred2_mean_pred: 0.2215 - val_loss: 0.1086 - val_pred1_loss: 0.0712 - val_pred2_loss: 0.0375 - val_pred1_accuracy: 0.3400 - val_pred1_mean_pred: 0.7091 - val_pred2_accuracy: 0.5120 - val_pred2_mean_pred: 0.3710\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10252\n",
      "Fold 7\n",
      "Build model...\n",
      "Model: \"model_17\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_23 (InputLayer)                  [(None, 128)]              0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)               (None, 128, 128)           109952        input_23[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDropout1D (None, 128, 128)           0             embedding_19[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_281 (Conv1D)                    (None, 128, 64)            8256          spatial_dropout1d_18[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_182 (ReLU)                       (None, 128, 64)            0             conv1d_281[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_282 (Conv1D)                    (None, 128, 64)            12352         re_lu_182[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchNormaliz (None, 128, 64)            256           conv1d_282[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_183 (ReLU)                       (None, 128, 64)            0             batch_normalization_266[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_283 (Conv1D)                    (None, 128, 64)            12352         re_lu_183[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchNormaliz (None, 128, 64)            256           conv1d_283[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_184 (ReLU)                       (None, 128, 64)            0             batch_normalization_267[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_82 (Add)                           (None, 128, 64)            0             re_lu_184[0][0]                         \n",
      "                                                                                re_lu_182[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_284 (Conv1D)                    (None, 128, 64)            12352         add_82[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchNormaliz (None, 128, 64)            256           conv1d_284[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_185 (ReLU)                       (None, 128, 64)            0             batch_normalization_268[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_285 (Conv1D)                    (None, 128, 64)            12352         re_lu_185[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchNormaliz (None, 128, 64)            256           conv1d_285[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_186 (ReLU)                       (None, 128, 64)            0             batch_normalization_269[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_286 (Conv1D)                    (None, 64, 64)             4160          add_82[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D)        (None, 64, 64)             0             re_lu_186[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchNormaliz (None, 64, 64)             256           conv1d_286[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_83 (Add)                           (None, 64, 64)             0             max_pooling1d_48[0][0]                  \n",
      "                                                                                batch_normalization_270[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_287 (Conv1D)                    (None, 64, 128)            8320          add_83[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchNormaliz (None, 64, 128)            512           conv1d_287[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_288 (Conv1D)                    (None, 64, 128)            49280         batch_normalization_271[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchNormaliz (None, 64, 128)            512           conv1d_288[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_187 (ReLU)                       (None, 64, 128)            0             batch_normalization_272[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_289 (Conv1D)                    (None, 64, 128)            49280         re_lu_187[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchNormaliz (None, 64, 128)            512           conv1d_289[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_188 (ReLU)                       (None, 64, 128)            0             batch_normalization_273[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_84 (Add)                           (None, 64, 128)            0             re_lu_188[0][0]                         \n",
      "                                                                                batch_normalization_271[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_290 (Conv1D)                    (None, 64, 128)            49280         add_84[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchNormaliz (None, 64, 128)            512           conv1d_290[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_189 (ReLU)                       (None, 64, 128)            0             batch_normalization_274[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_291 (Conv1D)                    (None, 64, 128)            49280         re_lu_189[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchNormaliz (None, 64, 128)            512           conv1d_291[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_190 (ReLU)                       (None, 64, 128)            0             batch_normalization_275[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_292 (Conv1D)                    (None, 32, 128)            16512         add_84[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D)        (None, 32, 128)            0             re_lu_190[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchNormaliz (None, 32, 128)            512           conv1d_292[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_85 (Add)                           (None, 32, 128)            0             max_pooling1d_49[0][0]                  \n",
      "                                                                                batch_normalization_276[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_293 (Conv1D)                    (None, 32, 256)            33024         add_85[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchNormaliz (None, 32, 256)            1024          conv1d_293[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_294 (Conv1D)                    (None, 32, 256)            196864        batch_normalization_277[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchNormaliz (None, 32, 256)            1024          conv1d_294[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_191 (ReLU)                       (None, 32, 256)            0             batch_normalization_278[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_295 (Conv1D)                    (None, 32, 256)            196864        re_lu_191[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchNormaliz (None, 32, 256)            1024          conv1d_295[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_192 (ReLU)                       (None, 32, 256)            0             batch_normalization_279[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_86 (Add)                           (None, 32, 256)            0             re_lu_192[0][0]                         \n",
      "                                                                                batch_normalization_277[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_296 (Conv1D)                    (None, 32, 256)            196864        add_86[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchNormaliz (None, 32, 256)            1024          conv1d_296[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_193 (ReLU)                       (None, 32, 256)            0             batch_normalization_280[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_297 (Conv1D)                    (None, 32, 256)            196864        re_lu_193[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchNormaliz (None, 32, 256)            1024          conv1d_297[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_194 (ReLU)                       (None, 32, 256)            0             batch_normalization_281[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_298 (Conv1D)                    (None, 16, 256)            65792         add_86[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D)        (None, 16, 256)            0             re_lu_194[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchNormaliz (None, 16, 256)            1024          conv1d_298[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_87 (Add)                           (None, 16, 256)            0             max_pooling1d_50[0][0]                  \n",
      "                                                                                batch_normalization_282[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_299 (Conv1D)                    (None, 16, 512)            131584        add_87[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchNormaliz (None, 16, 512)            2048          conv1d_299[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_300 (Conv1D)                    (None, 16, 512)            786944        batch_normalization_283[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchNormaliz (None, 16, 512)            2048          conv1d_300[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_195 (ReLU)                       (None, 16, 512)            0             batch_normalization_284[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_301 (Conv1D)                    (None, 16, 512)            786944        re_lu_195[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchNormaliz (None, 16, 512)            2048          conv1d_301[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_196 (ReLU)                       (None, 16, 512)            0             batch_normalization_285[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_88 (Add)                           (None, 16, 512)            0             re_lu_196[0][0]                         \n",
      "                                                                                batch_normalization_283[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_302 (Conv1D)                    (None, 16, 512)            786944        add_88[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchNormaliz (None, 16, 512)            2048          conv1d_302[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_197 (ReLU)                       (None, 16, 512)            0             batch_normalization_286[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_303 (Conv1D)                    (None, 16, 512)            786944        re_lu_197[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchNormaliz (None, 16, 512)            2048          conv1d_303[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_198 (ReLU)                       (None, 16, 512)            0             batch_normalization_287[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_304 (Conv1D)                    (None, 8, 512)             262656        add_88[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D)        (None, 8, 512)             0             re_lu_198[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchNormaliz (None, 8, 512)             2048          conv1d_304[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "add_89 (Add)                           (None, 8, 512)             0             max_pooling1d_51[0][0]                  \n",
      "                                                                                batch_normalization_288[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1d_305 (Conv1D)                    (None, 8, 1024)            525312        add_89[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchNormaliz (None, 8, 1024)            4096          conv1d_305[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "k_max_pooling_12 (k_max_pooling)       (None, 2, 1024)            0             batch_normalization_289[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)                   (None, 2048)               0             k_max_pooling_12[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)                   (None, 2048)               0             flatten_11[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred1 (Dense)                          (None, 17)                 34833         dropout_15[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "pred2 (Dense)                          (None, 12)                 24588         dropout_15[0][0]                        \n",
      "========================================================================================================================\n",
      "Total params: 5,433,629\n",
      "Trainable params: 5,310,237\n",
      "Non-trainable params: 123,392\n",
      "________________________________________________________________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 30s 161ms/step - loss: 0.4694 - pred1_loss: 0.2757 - pred2_loss: 0.1937 - pred1_accuracy: 0.1564 - pred1_mean_pred: 2.7572 - pred2_accuracy: 0.3450 - pred2_mean_pred: 1.9353 - val_loss: 0.4313 - val_pred1_loss: 0.2477 - val_pred2_loss: 0.1836 - val_pred1_accuracy: 0.0788 - val_pred1_mean_pred: 2.4772 - val_pred2_accuracy: 0.2792 - val_pred2_mean_pred: 1.8339\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.43125, saving model to ../model_weight/V2_7.h5\n",
      "Epoch 2/100\n",
      "137/137 [==============================] - 24s 173ms/step - loss: 0.2275 - pred1_loss: 0.1451 - pred2_loss: 0.0824 - pred1_accuracy: 0.2137 - pred1_mean_pred: 1.4512 - pred2_accuracy: 0.4773 - pred2_mean_pred: 0.8240 - val_loss: 0.2828 - val_pred1_loss: 0.1751 - val_pred2_loss: 0.1077 - val_pred1_accuracy: 0.1428 - val_pred1_mean_pred: 1.7522 - val_pred2_accuracy: 0.4736 - val_pred2_mean_pred: 1.0781\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.43125 to 0.28284, saving model to ../model_weight/V2_7.h5\n",
      "Epoch 3/100\n",
      "137/137 [==============================] - 26s 193ms/step - loss: 0.1834 - pred1_loss: 0.1222 - pred2_loss: 0.0612 - pred1_accuracy: 0.2191 - pred1_mean_pred: 1.2220 - pred2_accuracy: 0.5070 - pred2_mean_pred: 0.6119 - val_loss: 0.1732 - val_pred1_loss: 0.1159 - val_pred2_loss: 0.0573 - val_pred1_accuracy: 0.1856 - val_pred1_mean_pred: 1.1571 - val_pred2_accuracy: 0.5660 - val_pred2_mean_pred: 0.5716\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28284 to 0.17323, saving model to ../model_weight/V2_7.h5\n",
      "Epoch 4/100\n",
      "137/137 [==============================] - 22s 164ms/step - loss: 0.1581 - pred1_loss: 0.1086 - pred2_loss: 0.0495 - pred1_accuracy: 0.2469 - pred1_mean_pred: 1.0862 - pred2_accuracy: 0.5571 - pred2_mean_pred: 0.4949 - val_loss: 0.1838 - val_pred1_loss: 0.1294 - val_pred2_loss: 0.0544 - val_pred1_accuracy: 0.2168 - val_pred1_mean_pred: 1.2926 - val_pred2_accuracy: 0.6440 - val_pred2_mean_pred: 0.5426\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.17323\n",
      "Epoch 5/100\n",
      "137/137 [==============================] - 22s 163ms/step - loss: 0.1406 - pred1_loss: 0.0978 - pred2_loss: 0.0428 - pred1_accuracy: 0.2674 - pred1_mean_pred: 0.9778 - pred2_accuracy: 0.5469 - pred2_mean_pred: 0.4277 - val_loss: 0.1629 - val_pred1_loss: 0.1094 - val_pred2_loss: 0.0534 - val_pred1_accuracy: 0.2284 - val_pred1_mean_pred: 1.0922 - val_pred2_accuracy: 0.4804 - val_pred2_mean_pred: 0.5291\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17323 to 0.16287, saving model to ../model_weight/V2_7.h5\n",
      "Epoch 6/100\n",
      "137/137 [==============================] - 22s 164ms/step - loss: 0.1300 - pred1_loss: 0.0907 - pred2_loss: 0.0393 - pred1_accuracy: 0.2637 - pred1_mean_pred: 0.9067 - pred2_accuracy: 0.5535 - pred2_mean_pred: 0.3929 - val_loss: 0.1670 - val_pred1_loss: 0.1100 - val_pred2_loss: 0.0571 - val_pred1_accuracy: 0.2540 - val_pred1_mean_pred: 1.0966 - val_pred2_accuracy: 0.4800 - val_pred2_mean_pred: 0.5648\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16287\n",
      "Epoch 7/100\n",
      "137/137 [==============================] - 25s 181ms/step - loss: 0.1184 - pred1_loss: 0.0851 - pred2_loss: 0.0333 - pred1_accuracy: 0.2713 - pred1_mean_pred: 0.8505 - pred2_accuracy: 0.5242 - pred2_mean_pred: 0.3331 - val_loss: 0.1705 - val_pred1_loss: 0.1010 - val_pred2_loss: 0.0695 - val_pred1_accuracy: 0.2836 - val_pred1_mean_pred: 1.0089 - val_pred2_accuracy: 0.5660 - val_pred2_mean_pred: 0.6903\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16287\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=100\n",
    "weight_name='V2'\n",
    "oof=np.zeros((len(train),29))\n",
    "tmp=0\n",
    "test_oof=np.zeros((len(test),29))\n",
    "# for ii in range(17):\n",
    "#     per_labels=train_labels[:,ii]\n",
    "#     print('当前分类类别：'+str(ii))\n",
    "#     print('正样本比例:'+str(sum(per_labels)/len(per_labels)))\n",
    "# per_labels=train_labels[:,1]\n",
    "folds=StratifiedKFold(n_splits=8,shuffle=True, random_state=2018) #2018\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(folds.split(train,cate_num)):\n",
    "    print('Fold', fold_n)\n",
    "    print('Build model...')\n",
    "#     print('正样本比例:',train_labels[trn_idx].mean(0))\n",
    "#     model=NN_huaweiv1(maxlen=128,embedding_matrix=embedding_matrix)\n",
    "#     model=HANGraph(128,embedding_matrix=embedding_matrix)\n",
    "    vdcnn=VDCNNGraph(maxlen=128,embedding_matrix=embedding_matrix)\n",
    "    vdcnn.create_model()\n",
    "    model=vdcnn.model\n",
    "#     model=multi_gpu_model(model,gpus=2)\n",
    "    model.compile('adam', ['binary_crossentropy','binary_crossentropy'], metrics=['accuracy',mean_pred])\n",
    "\n",
    "    print('Train...')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=2,mode='min')\n",
    "    check_point=ModelCheckpoint('../model_weight/%s_%d.h5'%(weight_name,fold_n),monitor='val_loss',verbose=1, save_best_only=True,save_weights_only=True)\n",
    "\n",
    "    model.fit(train_seq[trn_idx],{'pred1':train_labels1[trn_idx],'pred2':train_labels2[trn_idx]},\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks=[early_stopping,check_point],\n",
    "              validation_data=(train_seq[val_idx],{'pred1':train_labels1[val_idx],'pred2':train_labels2[val_idx]}))\n",
    "    model.load_weights('../model_weight/%s_%d.h5'%(weight_name,fold_n))\n",
    "    oof[val_idx,:17],oof[val_idx,17:] = model.predict(train_seq[val_idx],batch_size=batch_size)\n",
    "    tmp_test_pred1,tmp_test_pred2=model.predict(test_seq,batch_size=batch_size)\n",
    "    test_oof[:,:17]+=tmp_test_pred1/folds.n_splits\n",
    "    test_oof[:,17:]+=tmp_test_pred2/folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "false-humanitarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T07:03:15.910141Z",
     "start_time": "2021-04-15T07:03:15.802681Z"
    }
   },
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['report_ID']=test[0]\n",
    "sub['Prediction']=[ '|'+' '.join(['%.12f'%j for j in i]) for i in test_oof ]\n",
    "sub.to_csv('../result.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-merchant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
